<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>End-to-End Google Earth Engine (Full Course) | ExampleSite</title>
<meta name=keywords content="clippings"><meta name=description content="
Introduction
Sign-up for Google Earth Engine
Complete the Class Pre-Work
Get the Course Videos
YouTube
Vimeo
Get the Course Materials
Module 1: Earth Engine Basics
01. Hello World
Exercise
Saving Your Work
02. Working with Image Collections
Exercise
03. Filtering Image Collections
Exercise
04. Creating Mosaics and Composites from ImageCollections
Exercise
05. Working with Feature Collections
Exercise
06. Importing Data
Exercise
07. Clipping Images
Exercise
08. Exporting Data
Exercise
Assignment 1
Module 2: Earth Engine Intermediate
01. Earth Engine Objects
Exercise
02. Calculating Indices
Exercise
03. Computation on ImageCollections
Exercise
04. Cloud Masking
Exercise
05. Reducers
Exercise
06. Time-Series Charts
Exercise
Assignment 2
Module 3: Supervised Classification
Introduction to Machine Learning and Supervised Classification
01. Basic Supervised Classification
Exercise
02. Accuracy Assessment
Exercise
03. Improving the Classification
Exercise
04. Exporting Classification Results
Exercise
05. Calculating Area
Exercise
Assignment 3
Module 4: Change Detection
Introduction to Change Detection
01. Spectral Index Change
Exercise
02. Spectral Distance Change
Exercise
03. Direct Classification of Change
Exercise
04. Post-classification Comparison
Exercise
Module 5: Earth Engine Apps
01. Client vs. Server
Exercise
02. Using UI Elements
Exercise
03. Building and Publishing an App
Exercise
04. Publishing the App
Exercise
05. Create a Split Panel App
Exercise
Module 6: Google Earth Engine Python API
Introduction to the Python API
Google Colab
Local Development Environment
01. Python API Syntax
Exercise
02. Automatic Conversion of Javascript Code to Python
Exercise
03. Batch Exports
Exercise
04. Using Earth Engine with XArray
Exercise
05. Automating Downloads
06. Automating Exports
07. Using the Google Earth Engine QGIS Plugin
Supplement
Guided Projects
Get the Code
Project 1: Calculating Rainfall Deviation
Project 2: Flood Mapping
Project 3: Extracting Time-Series
Project 4: LandCover Analysis
Project 5: Extracting Nighttime Lights Statistics
Learning Resources
Useful Public Repositories
Debugging Errors and Scaling Your Analysis
Data Credits
References
Composites
Supervised Classification
License
Citing and Referencing


"><meta name=author content="[[Ujaval Gandhi]]"><link rel=canonical href=http://localhost:1313/blog/end-to-end-google-earth-engine-full-course/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.d72444526d7ecbdb0015438a7fa89054a658bf759d0542e2e5df81ce94b493ee.css integrity="sha256-1yREUm1+y9sAFUOKf6iQVKZYv3WdBULi5d+BzpS0k+4=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/blog/end-to-end-google-earth-engine-full-course/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/blog/end-to-end-google-earth-engine-full-course/"><meta property="og:site_name" content="ExampleSite"><meta property="og:title" content="End-to-End Google Earth Engine (Full Course)"><meta property="og:description" content=" Introduction Sign-up for Google Earth Engine Complete the Class Pre-Work Get the Course Videos YouTube Vimeo Get the Course Materials Module 1: Earth Engine Basics 01. Hello World Exercise Saving Your Work 02. Working with Image Collections Exercise 03. Filtering Image Collections Exercise 04. Creating Mosaics and Composites from ImageCollections Exercise 05. Working with Feature Collections Exercise 06. Importing Data Exercise 07. Clipping Images Exercise 08. Exporting Data Exercise Assignment 1 Module 2: Earth Engine Intermediate 01. Earth Engine Objects Exercise 02. Calculating Indices Exercise 03. Computation on ImageCollections Exercise 04. Cloud Masking Exercise 05. Reducers Exercise 06. Time-Series Charts Exercise Assignment 2 Module 3: Supervised Classification Introduction to Machine Learning and Supervised Classification 01. Basic Supervised Classification Exercise 02. Accuracy Assessment Exercise 03. Improving the Classification Exercise 04. Exporting Classification Results Exercise 05. Calculating Area Exercise Assignment 3 Module 4: Change Detection Introduction to Change Detection 01. Spectral Index Change Exercise 02. Spectral Distance Change Exercise 03. Direct Classification of Change Exercise 04. Post-classification Comparison Exercise Module 5: Earth Engine Apps 01. Client vs. Server Exercise 02. Using UI Elements Exercise 03. Building and Publishing an App Exercise 04. Publishing the App Exercise 05. Create a Split Panel App Exercise Module 6: Google Earth Engine Python API Introduction to the Python API Google Colab Local Development Environment 01. Python API Syntax Exercise 02. Automatic Conversion of Javascript Code to Python Exercise 03. Batch Exports Exercise 04. Using Earth Engine with XArray Exercise 05. Automating Downloads 06. Automating Exports 07. Using the Google Earth Engine QGIS Plugin Supplement Guided Projects Get the Code Project 1: Calculating Rainfall Deviation Project 2: Flood Mapping Project 3: Extracting Time-Series Project 4: LandCover Analysis Project 5: Extracting Nighttime Lights Statistics Learning Resources Useful Public Repositories Debugging Errors and Scaling Your Analysis Data Credits References Composites Supervised Classification License Citing and Referencing "><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:tag" content="Clippings"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="End-to-End Google Earth Engine (Full Course)"><meta name=twitter:description content="
Introduction
Sign-up for Google Earth Engine
Complete the Class Pre-Work
Get the Course Videos
YouTube
Vimeo
Get the Course Materials
Module 1: Earth Engine Basics
01. Hello World
Exercise
Saving Your Work
02. Working with Image Collections
Exercise
03. Filtering Image Collections
Exercise
04. Creating Mosaics and Composites from ImageCollections
Exercise
05. Working with Feature Collections
Exercise
06. Importing Data
Exercise
07. Clipping Images
Exercise
08. Exporting Data
Exercise
Assignment 1
Module 2: Earth Engine Intermediate
01. Earth Engine Objects
Exercise
02. Calculating Indices
Exercise
03. Computation on ImageCollections
Exercise
04. Cloud Masking
Exercise
05. Reducers
Exercise
06. Time-Series Charts
Exercise
Assignment 2
Module 3: Supervised Classification
Introduction to Machine Learning and Supervised Classification
01. Basic Supervised Classification
Exercise
02. Accuracy Assessment
Exercise
03. Improving the Classification
Exercise
04. Exporting Classification Results
Exercise
05. Calculating Area
Exercise
Assignment 3
Module 4: Change Detection
Introduction to Change Detection
01. Spectral Index Change
Exercise
02. Spectral Distance Change
Exercise
03. Direct Classification of Change
Exercise
04. Post-classification Comparison
Exercise
Module 5: Earth Engine Apps
01. Client vs. Server
Exercise
02. Using UI Elements
Exercise
03. Building and Publishing an App
Exercise
04. Publishing the App
Exercise
05. Create a Split Panel App
Exercise
Module 6: Google Earth Engine Python API
Introduction to the Python API
Google Colab
Local Development Environment
01. Python API Syntax
Exercise
02. Automatic Conversion of Javascript Code to Python
Exercise
03. Batch Exports
Exercise
04. Using Earth Engine with XArray
Exercise
05. Automating Downloads
06. Automating Exports
07. Using the Google Earth Engine QGIS Plugin
Supplement
Guided Projects
Get the Code
Project 1: Calculating Rainfall Deviation
Project 2: Flood Mapping
Project 3: Extracting Time-Series
Project 4: LandCover Analysis
Project 5: Extracting Nighttime Lights Statistics
Learning Resources
Useful Public Repositories
Debugging Errors and Scaling Your Analysis
Data Credits
References
Composites
Supervised Classification
License
Citing and Referencing


"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"http://localhost:1313/blog/"},{"@type":"ListItem","position":2,"name":"End-to-End Google Earth Engine (Full Course)","item":"http://localhost:1313/blog/end-to-end-google-earth-engine-full-course/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"End-to-End Google Earth Engine (Full Course)","name":"End-to-End Google Earth Engine (Full Course)","description":" Introduction Sign-up for Google Earth Engine Complete the Class Pre-Work Get the Course Videos YouTube Vimeo Get the Course Materials Module 1: Earth Engine Basics 01. Hello World Exercise Saving Your Work 02. Working with Image Collections Exercise 03. Filtering Image Collections Exercise 04. Creating Mosaics and Composites from ImageCollections Exercise 05. Working with Feature Collections Exercise 06. Importing Data Exercise 07. Clipping Images Exercise 08. Exporting Data Exercise Assignment 1 Module 2: Earth Engine Intermediate 01. Earth Engine Objects Exercise 02. Calculating Indices Exercise 03. Computation on ImageCollections Exercise 04. Cloud Masking Exercise 05. Reducers Exercise 06. Time-Series Charts Exercise Assignment 2 Module 3: Supervised Classification Introduction to Machine Learning and Supervised Classification 01. Basic Supervised Classification Exercise 02. Accuracy Assessment Exercise 03. Improving the Classification Exercise 04. Exporting Classification Results Exercise 05. Calculating Area Exercise Assignment 3 Module 4: Change Detection Introduction to Change Detection 01. Spectral Index Change Exercise 02. Spectral Distance Change Exercise 03. Direct Classification of Change Exercise 04. Post-classification Comparison Exercise Module 5: Earth Engine Apps 01. Client vs. Server Exercise 02. Using UI Elements Exercise 03. Building and Publishing an App Exercise 04. Publishing the App Exercise 05. Create a Split Panel App Exercise Module 6: Google Earth Engine Python API Introduction to the Python API Google Colab Local Development Environment 01. Python API Syntax Exercise 02. Automatic Conversion of Javascript Code to Python Exercise 03. Batch Exports Exercise 04. Using Earth Engine with XArray Exercise 05. Automating Downloads 06. Automating Exports 07. Using the Google Earth Engine QGIS Plugin Supplement Guided Projects Get the Code Project 1: Calculating Rainfall Deviation Project 2: Flood Mapping Project 3: Extracting Time-Series Project 4: LandCover Analysis Project 5: Extracting Nighttime Lights Statistics Learning Resources Useful Public Repositories Debugging Errors and Scaling Your Analysis Data Credits References Composites Supervised Classification License Citing and Referencing ","keywords":["clippings"],"articleBody":" Introduction Sign-up for Google Earth Engine Complete the Class Pre-Work Get the Course Videos YouTube Vimeo Get the Course Materials Module 1: Earth Engine Basics 01. Hello World Exercise Saving Your Work 02. Working with Image Collections Exercise 03. Filtering Image Collections Exercise 04. Creating Mosaics and Composites from ImageCollections Exercise 05. Working with Feature Collections Exercise 06. Importing Data Exercise 07. Clipping Images Exercise 08. Exporting Data Exercise Assignment 1 Module 2: Earth Engine Intermediate 01. Earth Engine Objects Exercise 02. Calculating Indices Exercise 03. Computation on ImageCollections Exercise 04. Cloud Masking Exercise 05. Reducers Exercise 06. Time-Series Charts Exercise Assignment 2 Module 3: Supervised Classification Introduction to Machine Learning and Supervised Classification 01. Basic Supervised Classification Exercise 02. Accuracy Assessment Exercise 03. Improving the Classification Exercise 04. Exporting Classification Results Exercise 05. Calculating Area Exercise Assignment 3 Module 4: Change Detection Introduction to Change Detection 01. Spectral Index Change Exercise 02. Spectral Distance Change Exercise 03. Direct Classification of Change Exercise 04. Post-classification Comparison Exercise Module 5: Earth Engine Apps 01. Client vs. Server Exercise 02. Using UI Elements Exercise 03. Building and Publishing an App Exercise 04. Publishing the App Exercise 05. Create a Split Panel App Exercise Module 6: Google Earth Engine Python API Introduction to the Python API Google Colab Local Development Environment 01. Python API Syntax Exercise 02. Automatic Conversion of Javascript Code to Python Exercise 03. Batch Exports Exercise 04. Using Earth Engine with XArray Exercise 05. Automating Downloads 06. Automating Exports 07. Using the Google Earth Engine QGIS Plugin Supplement Guided Projects Get the Code Project 1: Calculating Rainfall Deviation Project 2: Flood Mapping Project 3: Extracting Time-Series Project 4: LandCover Analysis Project 5: Extracting Nighttime Lights Statistics Learning Resources Useful Public Repositories Debugging Errors and Scaling Your Analysis Data Credits References Composites Supervised Classification License Citing and Referencing Introduction Google Earth Engine is a cloud-based platform that enables large-scale processing of satellite imagery to detect changes, map trends, and quantify differences on the Earth’s surface. This course covers the full range of topics in Earth Engine to give the participants practical skills to master the platform and implement their remote sensing projects.\nWatch the Video ↗\nAccess the Presentation ↗\nSign-up for Google Earth Engine If you already have a Google Earth Engine account, you can skip this step.\nVisit our GEE Sign-Up Guide for step-by-step instructions.\nComplete the Class Pre-Work This class needs about 2-hours of pre-work. Please watch the following videos to get a good understanding of remote sensing and how Earth Engine works.\nIntroduction to Remote Sensing: This video introduces the remote sensing concepts, terminology and techniques. Introduction to Google Earth Engine: This video gives a broad overview of Google Earth Engine with selected case studies and application. The video also covers the Earth Engine architecture and how it is different than traditional remote sensing software. Get the Course Videos The course is accompanied by a set of videos covering the all the modules. These videos are recorded from our live instructor-led classes and are edited to make them easier to consume for self-study. We have 2 versions of the videos:\nYouTube We have created a YouTube Playlist with separate videos for each module to enable effective online-learning. Access the YouTube Playlist ↗\nVimeo We are also making the module videos available on Vimeo. These videos can be downloaded for offline learning. Access the Vimeo Playlist ↗\nGet the Course Materials The course material and exercises are in the form of Earth Engine scripts shared via a code repository.\nClick this link to open Google Earth Engine code editor and add the repository to your account. If successful, you will have a new repository named users/ujavalgandhi/End-to-End-GEE in the Scripts tab in the Reader section. Verify that your code editor looks like below Code Editor After Adding the Class Repository\nIf you do not see the repository in the Reader section, click Refresh repository cache button in your Scripts tab and it will show up.\nRefresh repository cache\nThere are several slide decks containing useful information and references. You can access all the presentations used in the course from the links below.\nIntroduction and course overview [Presentation ↗] Map/Reduce Programming Concepts [Presentation ↗] Introduction to Machine Learning \u0026 Supervised Classification [Presentation ↗] Introduction to Change Detection [Presentation ↗] Introduction to Earth Engine Apps [Presentation ↗] Introduction to Google Earth Engine Python API [Presentation ↗] Module 1: Earth Engine Basics Module 1 is designed to give you basic skills to be able to find datasets you need for your project, filter them to your region of interest, apply basic processing and export the results. Mastering this will allow you to start using Earth Engine for your project quickly and save a lot of time pre-processing the data.\nWatch the Video ↗\n01. Hello World This script introduces the basic Javascript syntax and the video covers the programming concepts you need to learn when using Earth Engine. To learn more, visit Introduction to JavaScript for Earth Engine section of the Earth Engine User Guide.\nThe Code Editor is an Integrated Development Environment (IDE) for Earth Engine Javascript API.. It offers an easy way to type, debug, run and manage code. Type the code below and click Run to execute it and see the output in the Console tab.\nTip: You can use the keyboard shortcut Ctrl+Enter to run the code in the Code Editor\nHello World\nOpen in Code Editor ↗\nprint('Hello World'); // Variables var city = 'Bengaluru'; var country = 'India'; print(city, country); var population = 8400000; print(population); // List var majorCities = ['Mumbai', 'Delhi', 'Chennai', 'Kolkata']; print(majorCities); // Dictionary var cityData = { 'city': city, 'population': 8400000, 'elevation': 930 }; print(cityData); // Function var greet = function(name) { return 'Hello ' + name; }; print(greet('World')); // This is a comment Exercise Try in Code Editor ↗\n// These are the 5 largest cities in the world: // Tokyo, Delhi, Shanghai, Mexico City, Sao Paulo // Create a list named 'largeCities' // The list should have names of all the above cities // Print the list Saving Your Work When you modify any script for the course repository, you may want to save a copy for yourself. If you try to click the Save button, you will get an error message like below\nThis is because the shared class repository is a Read-only repository. You can click Yes to save a copy in your repository. If this is the first time you are using Earth Engine, you will be prompted to choose a Earth Engine username. Choose the name carefully, as it cannot be changed once created.\nAfter entering your username, your home folder will be created. After that, you will be prompted to enter a new repository. A repository can help you organize and share code. Your account can have multiple repositories and each repository can have multiple scripts inside it. To get started, you can create a repository named default. Finally, you will be able to save the script.\n02. Working with Image Collections Most datasets in Earth Engine come as a ImageCollection. An ImageCollection is a dataset that consists of images takes at different time and locations - usually from the same satellite or data provider. You can load a collection by searching the Earth Engine Data Catalog for the ImageCollection ID. Search for the Sentinel-2 Level 1C dataset and you will find its id COPERNICUS/S2_SR. Visit the Sentinel-2, Level 1C page and see Explore in Earth Engine section to find the code snippet to load and visualize the collection. This snippet is a great starting point for your work with this dataset. Click the Copy Code Sample button and paste the code into the code editor. Click Run and you will see the image tiles load in the map.\nIn the code snippet, You will see a function Map.setCenter() which sets the viewport to a specific location and zoom level. The function takes the X coordinate (longitude), Y coordinate (latitude) and Zoom Level parameters. Replace the X and Y coordinates with the coordinates of your city and click Run to see the images of your city.\nExercise Try in Code Editor ↗\n// Find the 'Sentinel-2 Level-1C' dataset page // https://developers.google.com/earth-engine/datasets // Copy/paste the code snippet // Change the code to display images for your home city 03. Filtering Image Collections The collection contains all imagery ever collected by the sensor. The entire collections are not very useful. Most applications require a subset of the images. We use filters to select the appropriate images. There are many types of filter functions, look at ee.Filter... module to see all available filters. Select a filter and then run the filter() function with the filter parameters.\nWe will learn about 3 main types of filtering techniques\nFilter by metadata: You can apply a filter on the image metadata using filters such as ee.Filter.eq(), ee.Filter.lt() etc. You can filter by PATH/ROW values, Orbit number, Cloud cover etc. Filter by date: You can select images in a particular date range using filters such as ee.Filter.date(). Filter by location: You can select the subset of images with a bounding box, location or geometry using the ee.Filter.bounds(). You can also use the drawing tools to draw a geometry for filtering. After applying the filters, you can use the size() function to check how many images match the filters.\nOpen in Code Editor ↗\nvar geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241]) Map.centerObject(geometry, 10) var s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED'); // Filter by metadata var filtered = s2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)); // Filter by date var filtered = s2.filter(ee.Filter.date('2019-01-01', '2020-01-01')); // Filter by location var filtered = s2.filter(ee.Filter.bounds(geometry)); // Let's apply all the 3 filters together on the collection // First apply metadata fileter var filtered1 = s2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)); // Apply date filter on the results var filtered2 = filtered1.filter( ee.Filter.date('2019-01-01', '2020-01-01')); // Lastly apply the location filter var filtered3 = filtered2.filter(ee.Filter.bounds(geometry)); // Instead of applying filters one after the other, we can 'chain' them // Use the . notation to apply all the filters together var filtered = s2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)); print(filtered.size()); Exercise Try in Code Editor ↗\nvar geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241]); var s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED'); var filtered = s2 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)); print(filtered.size()); // Exercise // Delete the 'geometry' variable // Add a point at your chosen location // Change the filter to find images from January 2023 // Note: If you are in a very cloudy region, // make sure to adjust the CLOUDY_PIXEL_PERCENTAGE 04. Creating Mosaics and Composites from ImageCollections The default order of the collection is by date. So when you display the collection, it implicitly creates a mosaic with the latest pixels on top. You can call .mosaic() on a ImageCollection to create a mosaic image from the pixels at the top.\nWe can also create a composite image by applying selection criteria to each pixel from all pixels in the stack. Here we use the median() function to create a composite where each pixel value is the median of all pixels from the stack.\nTip: If you need to create a mosaic where the images are in a specific order, you can use the .sort() function to sort your collection by a property first.\nMosaic vs. Composite\nOpen in Code Editor ↗\nvar geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241]); var s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED'); var filtered = s2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)); var mosaic = filtered.mosaic(); var medianComposite = filtered.median(); Map.centerObject(geometry, 10); var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; Map.addLayer(filtered, rgbVis, 'Filtered Collection'); Map.addLayer(mosaic, rgbVis, 'Mosaic'); Map.addLayer(medianComposite, rgbVis, 'Median Composite'); Exercise Try in Code Editor ↗\n// Create a median composite for the year 2020 and load it to the map // Compare both the composites to see the changes in your city 05. Working with Feature Collections Feature Collections are similar to Image Collections - but they contain Features, not images. They are equivalent to Vector Layers in a GIS. We can load, filter and display Feature Collections using similar techniques that we have learned so far.\nSearch for GAUL Second Level Administrative Boundaries and load the collection. This is a global collection that contains all Admin2 boundaries. We can apply a filter using the ADM1_NAME property to get all Admin2 boundaries (i.e. Districts) from a state.\nOpen in Code Editor ↗\nvar admin2 = ee.FeatureCollection('FAO/GAUL_SIMPLIFIED_500m/2015/level2'); var karnataka = admin2.filter(ee.Filter.eq('ADM1_NAME', 'Karnataka')); var visParams = {'color': 'red'}; Map.addLayer(karnataka, visParams, 'Karnataka Districts'); Exercise Try in Code Editor ↗\nvar admin2 = ee.FeatureCollection('FAO/GAUL_SIMPLIFIED_500m/2015/level2'); Map.addLayer(admin2, {color: 'grey'}, 'All Admin2 Polygons'); // Exercise // Apply filters to select your chosen Admin2 region // Display the results in 'red' color // Hint1: Switch to the 'Inspector' tab and click on any // polygon to know its properties and their values // Hint2: Many countries do not have unique names for // Admin2 regions. Make sure to apply a filter to select // the Admin1 region that contains your chosen Admin2 region 06. Importing Data You can import vector or raster data into Earth Engine. We will now import a shapefile of Urban Centres from JRC’s GHS Urban Centre Database (GHS-UCDB). Unzip the ghs_urban_centers.zip into a folder on your computer. In the Code Editor, go to Assets → New → Table Upload → Shape Files. Select the .shp, .shx, .dbf and .prj files. Enter ghs_urban_centers as the Asset Name and click Upload. Once the upload and ingest finishes, you will have a new asset in the Assets tab. The shapefile is imported as a Feature Collection in Earth Engine. Select the ghs_urban_centers asset and click Import. You can then visualize the imported data.\nImporting a Shapefile\nOpen in Code Editor ↗\n// Let's import some data to Earth Engine // Upload the 'GHS Urban Centers' database from JRC // https://ghsl.jrc.ec.europa.eu/ghs_stat_ucdb2015mt_r2019a.php // Download the shapefile from https://bit.ly/ghs-ucdb-shapefile // Unzip and upload // Import the collection var urban = ee.FeatureCollection('users/ujavalgandhi/e2e/ghs_urban_centers'); // Visualize the collection Map.addLayer(urban, {color: 'blue'}, 'Urban Areas'); Exercise Try in Code Editor ↗\nvar urban = ee.FeatureCollection('users/ujavalgandhi/e2e/ghs_urban_centers'); print(urban.first()); // Exercise // Apply a filter to select only large urban centers // in your country and display it on the map. // Select all urban centers in your country with // a population greater than 1000000 // Hint1: Use the property 'CTR_MN_NM' containing country names // Hint2: Use the property 'P15' containing 2015 Population 07. Clipping Images It is often desirable to clip the images to your area of interest. You can use the clip() function to mask out an image using a geometry.\nWhile in a Desktop software, clipping is desirable to remove unnecessary portion of a large image and save computation time, in Earth Engine clipping can actually increase the computation time. As described in the Earth Engine Coding Best Practices guide, avoid clipping the images or do it at the end of your script.\nOriginal vs. Clipped Image\nOpen in Code Editor ↗\nvar s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED'); var urban = ee.FeatureCollection('users/ujavalgandhi/e2e/ghs_urban_centers'); // Find the name of the urban centre // by adding the layer to the map and using Inspector. var filtered = urban .filter(ee.Filter.eq('UC_NM_MN', 'Bengaluru')) .filter(ee.Filter.eq('CTR_MN_NM', 'India')); var geometry = filtered.geometry(); var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; var filtered = s2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)); var image = filtered.median(); var clipped = image.clip(geometry); Map.centerObject(geometry); Map.addLayer(clipped, rgbVis, 'Clipped'); Exercise Try in Code Editor ↗\n// Add the imported table to the Map // Use the Inspector to find the id of your home city or any urban area of your choice // Change the filter to use the id of the selected feature 08. Exporting Data Earth Engine allows for exporting both vector and raster data to be used in an external program. Vector data can be exported as a CSV or a Shapefile, while Rasters can be exported as GeoTIFF files. We will now export the Sentinel-2 Composite as a GeoTIFF file.\nTip: Code Editor supports autocompletion of API functions using the combination Ctrl+Space. Type a few characters of a function and press Ctrl+Space to see autocomplete suggestions. You can also use the same key combination to fill all parameters of the function automatically.\nOnce you run this script, the Tasks tab will be highlighted. Switch to the tab and you will see the tasks waiting. Click Run next to each task to start the process.\nOn clicking the Run button, you will be prompted for a confirmation dialog. Verify the settings and click Run to start the export.\nOnce the Export finishes, a GeoTiff file for each export task will be added to your Google Drive in the specified folder. You can download them and use it in a GIS software.\nVisualized vs. Raw Composite\nOpen in Code Editor ↗\nvar s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED'); var urban = ee.FeatureCollection('users/ujavalgandhi/e2e/ghs_urban_centers'); var filtered = urban .filter(ee.Filter.eq('UC_NM_MN', 'Bengaluru')) .filter(ee.Filter.eq('CTR_MN_NM', 'India')); var geometry = filtered.geometry(); var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; var filtered = s2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)); var image = filtered.median(); var clipped = image.clip(geometry); Map.centerObject(geometry); Map.addLayer(clipped, rgbVis, 'Clipped'); var exportImage = clipped.select('B.*'); // Export raw image with original pixel values Export.image.toDrive({ image: exportImage, description: 'Bangalore_Composite_Raw', folder: 'earthengine', fileNamePrefix: 'bangalore_composite_raw', region: geometry, scale: 10, maxPixels: 1e9 }); // Export visualized image as colorized RGB image // Rather than exporting raw bands, we can apply a rendered image // visualize() function allows you to apply the same parameters // that are used in earth engine which exports a 3-band RGB image // Note: Visualized images are not suitable for analysis var visualized = clipped.visualize(rgbVis); Export.image.toDrive({ image: visualized, description: 'Bangalore_Composite_Visualized', folder: 'earthengine', fileNamePrefix: 'bangalore_composite_visualized', region: geometry, scale: 10, maxPixels: 1e9 }); Exercise Try in Code Editor ↗\n// Write the export function to export the results for your chosen urban area Assignment 1 Load the Night Lights Data for May 2015 and May 2020. Compare the imagery for your region and find the changes in the city due to COVID-19 effect.\nAssignment1 Expected Output\nTry in Code Editor ↗\n// Assignment // Export the Night Lights images for May,2015 and May,2020 // Workflow: // Load the VIIRS Nighttime Day/Night Band Composites collection // Filter the collection to the date range // Extract the 'avg_rad' band which represents the nighttime lights // Clip the image to the geometry of your city // Export the resulting image as a GeoTIFF file. // Hint1: // There are 2 VIIRS Nighttime Day/Night collections // Use the one that corrects for stray light // Hint2: // The collection contains 1 global image per month // After filtering for the month, there will be only 1 image in the collection // You can use the following technique to extract that image // var image = ee.Image(filtered.first()) Module 3: Supervised Classification Introduction to Machine Learning and Supervised Classification Supervised classification is arguably the most important classical machine learning techniques in remote sensing. Applications range from generating Land Use/Land Cover maps to change detection. Google Earth Engine is unique suited to do supervised classification at scale. The interactive nature of Earth Engine development allows for iterative development of supervised classification workflows by combining many different datasets into the model. This module covers basic supervised classification workflow, accuracy assessment, hyperparameter tuning and change detection.\nWatch the Video ↗\n01. Basic Supervised Classification We will learn how to do a basic land cover classification using training samples collected from the Code Editor using the High Resolution basemap imagery provided by Google Maps. This method requires no prior training data and is quite effective to generate high quality classification samples anywhere in the world. The goal is to classify each source pixel into one of the following classes - urban, bare, water or vegetation. Using the drawing tools in the code editor, you create 4 new feature collection with points representing pixels of that class. Each feature collection has a property called landcover with values of 0, 1, 2 or 3 indicating whether the feature collection represents urban, bare, water or vegetation respectively. We then train a Random Forest classifier using these training set to build a model and apply it to all the pixels of the image to create a 4 class image.\nFun fact: The classifiers in Earth Engine API have names starting with smile - such as ee.Classifier.smileRandomForest(). The smile part refers to the Statistical Machine Intelligence and Learning Engine (SMILE) JAVA library which is used by Google Earth Engine to implement these algorithms.\nSupervised Classification Output\nOpen in Code Editor ↗\nvar bangalore = ee.FeatureCollection('users/ujavalgandhi/public/bangalore_boundary'); var geometry = bangalore.geometry(); var s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED'); // The following collections were created using the // Drawing Tools in the code editor var urban = ee.FeatureCollection('users/ujavalgandhi/e2e/urban_gcps'); var bare = ee.FeatureCollection('users/ujavalgandhi/e2e/bare_gcps'); var water = ee.FeatureCollection('users/ujavalgandhi/e2e/water_gcps'); var vegetation = ee.FeatureCollection('users/ujavalgandhi/e2e/vegetation_gcps'); var filtered = s2 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)) .select('B.*'); var composite = filtered.median(); // Display the input composite. var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; Map.addLayer(composite.clip(geometry), rgbVis, 'image'); var gcps = urban.merge(bare).merge(water).merge(vegetation); // Overlay the point on the image to get training data. var training = composite.sampleRegions({ collection: gcps, properties: ['landcover'], scale: 10 }); // Train a classifier. var classifier = ee.Classifier.smileRandomForest(50).train({ features: training, classProperty: 'landcover', inputProperties: composite.bandNames() }); // // Classify the image. var classified = composite.classify(classifier); // Choose a 4-color palette // Assign a color for each class in the following order // Urban, Bare, Water, Vegetation var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ]; Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019'); // Display the GCPs // We use the style() function to style the GCPs var palette = ee.List(palette); var landcover = ee.List([0, 1, 2, 3]); var gcpsStyled = ee.FeatureCollection( landcover.map(function(lc){ var color = palette.get(landcover.indexOf(lc)); var markerStyle = { color: 'white', pointShape: 'diamond', pointSize: 4, width: 1, fillColor: color}; return gcps.filter(ee.Filter.eq('landcover', lc)) .map(function(point){ return point.set('style', markerStyle) }) })).flatten(); Map.addLayer(gcpsStyled.style({styleProperty:\"style\"}), {}, 'GCPs') Map.centerObject(gcpsStyled) Exercise Try in Code Editor ↗\nvar s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED'); // Perform supervised classification for your city // Delete the geometry below and draw a polygon // over your chosen city var geometry = ee.Geometry.Polygon([[ [77.4149, 13.1203], [77.4149, 12.7308], [77.8090, 12.7308], [77.8090, 13.1203] ]]); Map.centerObject(geometry); var filtered = s2 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)) .select('B.*'); var composite = filtered.median(); // Display the input composite. var rgbVis = {min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2']}; Map.addLayer(composite.clip(geometry), rgbVis, 'image'); // Exercise // Add training points for 4 classes // Assign the 'landcover' property as follows // urban: 0 // bare: 1 // water: 2 // vegetation: 3 // After adding points, uncomments lines below // var gcps = urban.merge(bare).merge(water).merge(vegetation); // // Overlay the point on the image to get training data. // var training = composite.sampleRegions({ // collection: gcps, // properties: ['landcover'], // scale: 10, // tileScale: 16 // }); // print(training); // // Train a classifier. // var classifier = ee.Classifier.smileRandomForest(50).train({ // features: training, // classProperty: 'landcover', // inputProperties: composite.bandNames() // }); // // // Classify the image. // var classified = composite.classify(classifier); // // Choose a 4-color palette // // Assign a color for each class in the following order // // Urban, Bare, Water, Vegetation // var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ]; // Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019'); 02. Accuracy Assessment It is important to get a quantitative estimate of the accuracy of the classification. To do this, a common strategy is to divide your training samples into 2 random fractions - one used for training the model and the other for validation of the predictions. Once a classifier is trained, it can be used to classify the entire image. We can then compare the classified values with the ones in the validation fraction. We can use the ee.Classifier.confusionMatrix() method to calculate a Confusion Matrix representing expected accuracy.\nClassification results are evaluated based on the following metrics\nOverall Accuracy: How many samples were classified correctly. Producer’s Accuracy: How well did the classification predict each class. Consumer’s Accuracy (Reliability): How reliable is the prediction in each class. Kappa Coefficient: How well the classification performed as compared to random assignment. Accuracy Assessment\nDon’t get carried away tweaking your model to give you the highest validation accuracy. You must use both qualitative measures (such as visual inspection of results) along with quantitative measures to assess the results.\nOpen in Code Editor ↗\nvar s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED'); var basin = ee.FeatureCollection(\"WWF/HydroSHEDS/v1/Basins/hybas_7\"); var gcp = ee.FeatureCollection(\"users/ujavalgandhi/e2e/arkavathy_gcps\"); var arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640)); var geometry = arkavathy.geometry(); Map.centerObject(geometry); var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; var filtered = s2 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)) .select('B.*'); var composite = filtered.median(); // Display the input composite. Map.addLayer(composite.clip(geometry), rgbVis, 'image'); // Add a random column and split the GCPs into training and validation set var gcp = gcp.randomColumn(); // This being a simpler classification, we take 60% points // for validation. Normal recommended ratio is // 70% training, 30% validation var trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6)); var validationGcp = gcp.filter(ee.Filter.gte('random', 0.6)); // Overlay the point on the image to get training data. var training = composite.sampleRegions({ collection: trainingGcp, properties: ['landcover'], scale: 10, tileScale: 16 }); // Train a classifier. var classifier = ee.Classifier.smileRandomForest(50) .train({ features: training, classProperty: 'landcover', inputProperties: composite.bandNames() }); // Classify the image. var classified = composite.classify(classifier); var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ]; Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019'); //************************************************************************** // Accuracy Assessment //************************************************************************** // Use classification map to assess accuracy using the validation fraction // of the overall training set created above. var test = classified.sampleRegions({ collection: validationGcp, properties: ['landcover'], tileScale: 16, scale: 10, }); var testConfusionMatrix = test.errorMatrix('landcover', 'classification') // Printing of confusion matrix may time out. Alternatively, you can export it as CSV print('Confusion Matrix', testConfusionMatrix); print('Test Accuracy', testConfusionMatrix.accuracy()); // Alternate workflow // This is similar to machine learning practice var validation = composite.sampleRegions({ collection: validationGcp, properties: ['landcover'], scale: 10, tileScale: 16 }); var test = validation.classify(classifier); var testConfusionMatrix = test.errorMatrix('landcover', 'classification') // Printing of confusion matrix may time out. Alternatively, you can export it as CSV print('Confusion Matrix', testConfusionMatrix); print('Test Accuracy', testConfusionMatrix.accuracy()); Exercise Try in Code Editor ↗\nvar composite = ee.Image('users/ujavalgandhi/e2e/arkavathy_2019_composite'); var gcp = ee.FeatureCollection('users/ujavalgandhi/e2e/arkavathy_gcps'); var gcp = gcp.randomColumn(); var trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6)); var validationGcp = gcp.filter(ee.Filter.gte('random', 0.6)); var training = composite.sampleRegions({ collection: trainingGcp, properties: ['landcover'], scale: 10, tileScale: 16 }); // Train a classifier. var classifier = ee.Classifier.smileRandomForest(50) .train({ features: training, classProperty: 'landcover', inputProperties: composite.bandNames() }); // Classify the image. var classified = composite.classify(classifier); //************************************************************************** // Accuracy Assessment //************************************************************************** // Use classification map to assess accuracy using the validation fraction // of the overall training set created above. var test = classified.sampleRegions({ collection: validationGcp, properties: ['landcover'], tileScale: 16, scale: 10, }); var testConfusionMatrix = test.errorMatrix('landcover', 'classification'); print('Confusion Matrix', testConfusionMatrix); print('Test Accuracy', testConfusionMatrix.accuracy()); // Exercise // Calculate and print the following assessment metrics // 1. Producer's accuracy // 2. Consumer's accuracy // 3. F1-score // Hint: Look at the ee.ConfusionMatrix module for appropriate methods 03. Improving the Classification The Earth Engine data-model is especially well suited for machine learning tasks because of its ability to easily incorporate data sources of different spatial resolutions, projections and data types together By giving additional information to the classifier, it is able to separate different classes easily. Here we take the same example and augment it with the following techniques\nApply Cloud Masking Add Spectral Indices: We add bands for different spectral indices such as - NDVI, NDBI, MNDWI and BSI. Add Elevation and Slope: We also add slope and elevation bands from the ALOS DEM. Normalize the Inputs: Machine learning models work best when all the inputs have the same scale. We will divide each band with the maximum value. This method ensures that all input values are between 0-1. A more complete and robust technique for image normalization is provided in the course Supplement. Our training features have more parameters and contain values of the same scale. The result is a much improved classification.\nImproved Classification Accuracy with use of Spectral Indices and Elevation Data\nOpen in Code Editor ↗\nvar s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED'); var basin = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_7'); var gcp = ee.FeatureCollection('users/ujavalgandhi/e2e/arkavathy_gcps'); var alos = ee.ImageCollection('JAXA/ALOS/AW3D30/V3_2'); var arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640)); var geometry = arkavathy.geometry(); Map.centerObject(geometry); var filtered = s2 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)); // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.5; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA) .select('B.*'); var composite = filteredMasked.median(); var addIndices = function(image) { var ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi']); var ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi']); var mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi']); var bsi = image.expression( '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', { 'X': image.select('B11'), //swir1 'Y': image.select('B4'), //red 'A': image.select('B8'), // nir 'B': image.select('B2'), // blue }).rename('bsi'); return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi); }; var composite = addIndices(composite); // Calculate Slope and Elevation // Use ALOS World 3D v3 // This comes as a collection of images // We mosaic it to create a single image // Need to set the projection correctly on the mosaic // for the slope computation var proj = alos.first().projection(); var elevation = alos.select('DSM').mosaic() .setDefaultProjection(proj) .rename('elev'); var slope = ee.Terrain.slope(elevation) .rename('slope'); var composite = composite.addBands(elevation).addBands(slope); var visParams = {bands: ['B4', 'B3', 'B2'], min: 0, max: 3000, gamma: 1.2}; Map.addLayer(composite.clip(geometry), visParams, 'RGB'); // Normalize the image // Machine learning algorithms work best on images when all features have // the same range // Function to Normalize Image // Pixel Values should be between 0 and 1 // Formula is (x - xmin) / (xmax - xmin) //************************************************************************** function normalize(image){ var bandNames = image.bandNames(); // Compute min and max of the image var minDict = image.reduceRegion({ reducer: ee.Reducer.min(), geometry: geometry, scale: 10, maxPixels: 1e9, bestEffort: true, tileScale: 16 }); var maxDict = image.reduceRegion({ reducer: ee.Reducer.max(), geometry: geometry, scale: 10, maxPixels: 1e9, bestEffort: true, tileScale: 16 }); var mins = ee.Image.constant(minDict.values(bandNames)); var maxs = ee.Image.constant(maxDict.values(bandNames)); var normalized = image.subtract(mins).divide(maxs.subtract(mins)); return normalized; } var composite = normalize(composite); // Add a random column and split the GCPs into training and validation set var gcp = gcp.randomColumn(); // This being a simpler classification, we take 60% points // for validation. Normal recommended ratio is // 70% training, 30% validation var trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6)); var validationGcp = gcp.filter(ee.Filter.gte('random', 0.6)); // Overlay the point on the image to get training data. var training = composite.sampleRegions({ collection: trainingGcp, properties: ['landcover'], scale: 10, tileScale: 16 }); print(training); // Train a classifier. var classifier = ee.Classifier.smileRandomForest(50) .train({ features: training, classProperty: 'landcover', inputProperties: composite.bandNames() }); // Classify the image. var classified = composite.classify(classifier); var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ]; Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019'); //************************************************************************** // Accuracy Assessment //************************************************************************** // Use classification map to assess accuracy using the validation fraction // of the overall training set created above. var test = classified.sampleRegions({ collection: validationGcp, properties: ['landcover'], scale: 10, tileScale: 16 }); var testConfusionMatrix = test.errorMatrix('landcover', 'classification'); // Printing of confusion matrix may time out. Alternatively, you can export it as CSV print('Confusion Matrix', testConfusionMatrix); print('Test Accuracy', testConfusionMatrix.accuracy()); Exercise Try in Code Editor ↗\n// Exercise // Improve your classification from Exercise 01c // Add different spectral indicies to your composite // by using the function below var addIndices = function(image) { var ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi']); var ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi']); var mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi']); var bsi = image.expression( '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', { 'X': image.select('B11'), //swir1 'Y': image.select('B4'), //red 'A': image.select('B8'), // nir 'B': image.select('B2'), // blue }).rename('bsi'); return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi); }; 04. Exporting Classification Results When working with complex classifiers over large regions, you may get a User memory limit exceeded or Computation timed out error in the Code Editor. The reason for this is that there is a fixed time limit and smaller memory allocated for code that is run with the On-Demand Computation mode. For larger computations, you can use the Batch mode with the Export functions. Exports run in the background and can run longer than 5-minutes time allocated to the computation code run from the Code Editor. This allows you to process very large and complex datasets. Here’s an example showing how to export your classification results to Google Drive.\nExported Classification Outputs\nOpen in Code Editor ↗\nvar s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED'); var basin = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_7'); var gcp = ee.FeatureCollection('users/ujavalgandhi/e2e/arkavathy_gcps'); var alos = ee.ImageCollection('JAXA/ALOS/AW3D30/V3_2'); var arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640)); var geometry = arkavathy.geometry(); Map.centerObject(geometry); var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; var filtered = s2 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)) // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.5; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA) .select('B.*'); var composite = filteredMasked.median(); var addIndices = function(image) { var ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi']); var ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi']); var mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi']); var bsi = image.expression( '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', { 'X': image.select('B11'), //swir1 'Y': image.select('B4'), //red 'A': image.select('B8'), // nir 'B': image.select('B2'), // blue }).rename('bsi'); return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi); }; var composite = addIndices(composite); // Calculate Slope and Elevation // Use ALOS World 3D v3 // This comes as a collection of images // We mosaic it to create a single image // Need to set the projection correctly on the mosaic // for the slope computation var proj = alos.first().projection(); var elevation = alos.select('DSM').mosaic() .setDefaultProjection(proj) .rename('elev'); var slope = ee.Terrain.slope(elevation) .rename('slope'); var composite = composite.addBands(elevation).addBands(slope); var visParams = {bands: ['B4', 'B3', 'B2'], min: 0, max: 3000, gamma: 1.2}; Map.addLayer(composite.clip(geometry), visParams, 'RGB'); // Normalize the image // Machine learning algorithms work best on images when all features have // the same range // Function to Normalize Image // Pixel Values should be between 0 and 1 // Formula is (x - xmin) / (xmax - xmin) //************************************************************************** function normalize(image){ var bandNames = image.bandNames(); // Compute min and max of the image var minDict = image.reduceRegion({ reducer: ee.Reducer.min(), geometry: geometry, scale: 10, maxPixels: 1e9, bestEffort: true, tileScale: 16 }); var maxDict = image.reduceRegion({ reducer: ee.Reducer.max(), geometry: geometry, scale: 10, maxPixels: 1e9, bestEffort: true, tileScale: 16 }); var mins = ee.Image.constant(minDict.values(bandNames)); var maxs = ee.Image.constant(maxDict.values(bandNames)); var normalized = image.subtract(mins).divide(maxs.subtract(mins)); return normalized; } var composite = normalize(composite); // Add a random column and split the GCPs into training and validation set var gcp = gcp.randomColumn(); // This being a simpler classification, we take 60% points // for validation. Normal recommended ratio is // 70% training, 30% validation var trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6)); var validationGcp = gcp.filter(ee.Filter.gte('random', 0.6)); // Overlay the point on the image to get training data. var training = composite.sampleRegions({ collection: trainingGcp, properties: ['landcover'], scale: 10, tileScale: 16 }); print(training); // Train a classifier. var classifier = ee.Classifier.smileRandomForest(50) .train({ features: training, classProperty: 'landcover', inputProperties: composite.bandNames() }); // Classify the image. var classified = composite.classify(classifier); var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ]; Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019'); //************************************************************************** // Accuracy Assessment //************************************************************************** // Use classification map to assess accuracy using the validation fraction // of the overall training set created above. var test = classified.sampleRegions({ collection: validationGcp, properties: ['landcover'], scale: 10, tileScale: 16 }); var testConfusionMatrix = test.errorMatrix('landcover', 'classification'); //************************************************************************** // Exporting Results //************************************************************************** // Export the classified image to Drive // For images having integers (such as class numbers) // we cast the image to floating point data type which // allows the masked values to be saved as NaN values // in the GeoTIFF format. // You can set these to actual NoData values using // GDAL tools after the export // gdal_translate -a_nodata 'nan' input.tif output.tif Export.image.toDrive({ image: classified.clip(geometry).toFloat(), description: 'Classified_Image_Export', folder: 'earthengine', fileNamePrefix: 'classified', region: geometry, scale: 10, maxPixels: 1e10 }) // Export the results of accuracy asssessment // Create a Feature with null geometry and the value we want to export. // Use .array() to convert Confusion Matrix to an Array so it can be // exported in a CSV file var fc = ee.FeatureCollection([ ee.Feature(null, { 'accuracy': testConfusionMatrix.accuracy(), 'matrix': testConfusionMatrix.array() }) ]); print(fc); Export.table.toDrive({ collection: fc, description: 'Accuracy_Assessment_Export', folder: 'earthengine', fileNamePrefix: 'accuracy', fileFormat: 'CSV' }); Exercise It is also a good idea to export the classified image as an Asset. This will allows you to import the classified image in another script without running the whole classification workflow. Use the Export.image.toAsset() function to export the classified image as an asset.\nTry in Code Editor ↗\nvar s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED'); var basin = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_7'); var gcp = ee.FeatureCollection('users/ujavalgandhi/e2e/arkavathy_gcps'); var alos = ee.ImageCollection('JAXA/ALOS/AW3D30/V3_2'); var arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640)); var geometry = arkavathy.geometry(); Map.centerObject(geometry); var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; var filtered = s2 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)) // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.5; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA) .select('B.*'); var composite = filteredMasked.median(); var addIndices = function(image) { var ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi']); var ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi']); var mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi']); var bsi = image.expression( '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', { 'X': image.select('B11'), //swir1 'Y': image.select('B4'), //red 'A': image.select('B8'), // nir 'B': image.select('B2'), // blue }).rename('bsi'); return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi); }; var composite = addIndices(composite); // Calculate Slope and Elevation // Use ALOS World 3D v3 // This comes as a collection of images // We mosaic it to create a single image // Need to set the projection correctly on the mosaic // for the slope computation var proj = alos.first().projection(); var elevation = alos.select('DSM').mosaic() .setDefaultProjection(proj) .rename('elev'); var slope = ee.Terrain.slope(elevation) .rename('slope'); var composite = composite.addBands(elevation).addBands(slope); var visParams = {bands: ['B4', 'B3', 'B2'], min: 0, max: 3000, gamma: 1.2}; Map.addLayer(composite.clip(geometry), visParams, 'RGB'); // Normalize the image // Machine learning algorithms work best on images when all features have // the same range // Function to Normalize Image // Pixel Values should be between 0 and 1 // Formula is (x - xmin) / (xmax - xmin) //************************************************************************** function normalize(image){ var bandNames = image.bandNames(); // Compute min and max of the image var minDict = image.reduceRegion({ reducer: ee.Reducer.min(), geometry: geometry, scale: 10, maxPixels: 1e9, bestEffort: true, tileScale: 16 }); var maxDict = image.reduceRegion({ reducer: ee.Reducer.max(), geometry: geometry, scale: 10, maxPixels: 1e9, bestEffort: true, tileScale: 16 }); var mins = ee.Image.constant(minDict.values(bandNames)); var maxs = ee.Image.constant(maxDict.values(bandNames)); var normalized = image.subtract(mins).divide(maxs.subtract(mins)); return normalized; } var composite = normalize(composite); // Add a random column and split the GCPs into training and validation set var gcp = gcp.randomColumn(); // This being a simpler classification, we take 60% points // for validation. Normal recommended ratio is // 70% training, 30% validation var trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6)); var validationGcp = gcp.filter(ee.Filter.gte('random', 0.6)); // Overlay the point on the image to get training data. var training = composite.sampleRegions({ collection: trainingGcp, properties: ['landcover'], scale: 10, tileScale: 16 }); // Train a classifier. var classifier = ee.Classifier.smileRandomForest(50) .train({ features: training, classProperty: 'landcover', inputProperties: composite.bandNames() }); // Classify the image. var classified = composite.classify(classifier); var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ]; Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019'); // Exercise // Use the Export.image.toAsset() function to export the // classified image as a Earth Engine Asset. // This will allows you to import the classified image in another // script without running the whole classification workflow. // Hint: For images with discrete pixel values, we must set the // pyramidingPolicy to 'mode'. // The pyramidingPolicy parameter should a dictionary specifying // the policy for each band. A simpler way to specify it for all // bands is to use {'.default': 'mode'} // assetId should be specified as a string // It can be just the asset name 'classified_image' // or a full path such as 'projects/ee-/classified_image' 05. Calculating Area Now that we have the results of our classification, we will learn how to calculate the area for pixels in each class. The functions used for area computations are different for vectors and raster data.\nArea of Polygons: Calculating area for polygons is done using the area() function. It computes area on a sphere (ignoring the ellipsoid flattening) and gives you the area in square meters. You can optionally supply proj and a non-zero maxError parameters to calculate area in a specific projected CRS. For example, area({proj:'EPSG:32643', maxError: 1}) will calculate the area of the polygon after reprojecting it to the WGS 84/UTM Zone 43 CRS with a tolerance of 1 meter. Area of Image Pixels: Area of image pixels is computed using the ee.Image.pixelArea() function. This function computes the area inside the 4 corners of each pixel using the WGS84 ellipsoid. The ee.Image.pixelArea() function uses a custom equal-area projection for area calculation. The result is area in square meters regardless of the projection of the input image. Learn more. Calculating Green Cover from Classified Image\nOpen in Code Editor ↗\nvar classified = ee.Image('users/ujavalgandhi/e2e/bangalore_classified'); var bangalore = ee.FeatureCollection('users/ujavalgandhi/public/bangalore_boundary'); Map.addLayer(bangalore, {color: 'blue'}, 'Bangalore City'); var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ]; Map.addLayer(classified, {min: 0, max: 3, palette: palette}, '2019'); // Calling .geometry() on a feature collection gives the // dissolved geometry of all features in the collection // .area() function calculates the area in square meters var cityArea = bangalore.geometry().area(); // We can cast the result to a ee.Number() and calculate the // area in square kilometers var cityAreaSqKm = ee.Number(cityArea).divide(1e6).round(); print(cityAreaSqKm); // Area Calculation for Images var vegetation = classified.eq(3); // If the image contains values 0 or 1, we can calculate the // total area using reduceRegion() function // The result of .eq() operation is a binary image with pixels // values of 1 where the condition matched and 0 where it didn't Map.addLayer(vegetation, {min:0, max:1, palette: ['white', 'green']}, 'Green Cover'); // Since our image has only 0 and 1 pixel values, the vegetation // pixels will have values equal to their area var areaImage = vegetation.multiply(ee.Image.pixelArea()); // Now that each pixel for vegetation class in the image has the value // equal to its area, we can sum up all the values in the region // to get the total green cover. var area = areaImage.reduceRegion({ reducer: ee.Reducer.sum(), geometry: bangalore.geometry(), scale: 10, maxPixels: 1e10 }); // The result of the reduceRegion() function is a dictionary with the key // being the band name. We can extract the area number and convert it to // square kilometers var vegetationAreaSqKm = ee.Number(area.get('classification')).divide(1e6).round(); print(vegetationAreaSqKm); If you want to compute area covered by each class, you can use a Grouped Reducer. See the Supplement to see a code snippet.\nExercise Try in Code Editor ↗\n// Exercise // Compute and print the percentage green cover of the city Assignment 3 Try in Code Editor ↗\n// Choose a city of your choice and create land use land classification // using supervised classification technique. // You can use your script 01c from 03-Supervised-Classification // module as a starting point. // The classification should incorporate the following techniques // 1. Add relevant indicies // 2. Add cloud masking // 3. Add elevation and slope // 4. Normalize the data // [Optional] // Accuracy Assessment // Post-processing Classification Module 4: Change Detection Introduction to Change Detection Many earth observation datasets are available at regular intervals over long periods of time. This enables us to detect changes on the Earth’s surface. Change detection technique in remote sensing fall in the following categories\nSingle Band Change: Measuring change in a single band image or a spectral index using a threshold Multi Band Change: Measuring spectral distance and spectral angle between two multiband images Classification of Change: One-pass classification using stacked image containing bands from before and after an event Post Classification Comparison: Comparing two classified images and computing class transitions Watch the Video ↗\n01. Spectral Index Change Many types of change can be detected by measuring the change in a spectral index and applying a threshold. This technique is suitable when there is a suitable spectral index is available for the type of change you are interested in detecting.\nHere we apply this technique to map the extent and severity of a forest fire. The Normalized Burn Ratio (NBR) is an index that is designed to highlight burnt vegetation areas. We compute the NBR for before and after images. Then we apply a suitable threshold to find burnt areas.\nSpectral Index Change Detection\nOpen in Code Editor ↗\n// On 21st February 2019, massive forest fires broke out in // numerous places across the Bandipur National Park of // the Karnataka state in India. // By 25 February 2019 most fire was brought under control // This script shows how to do damage assessment using // spectral index change detection technique. // Define the area of interest var geometry = ee.Geometry.Polygon([[ [76.37639666685044, 11.766523239445169], [76.37639666685044, 11.519036946599561], [76.78426409849106, 11.519036946599561], [76.78426409849106, 11.766523239445169] ]]); var fireStart = ee.Date('2019-02-20'); var fireEnd = ee.Date('2019-02-25'); Map.centerObject(geometry, 10) var s2 = ee.ImageCollection(\"COPERNICUS/S2\") // Apply filters var filtered = s2 .filter(ee.Filter.bounds(geometry)) .select('B.*') // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.5; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA); // Create Before and After composites var before = filteredMasked .filter(ee.Filter.date( fireStart.advance(-2, 'month'), fireStart)) .median() var after = filteredMasked .filter(ee.Filter.date( fireEnd, fireEnd.advance(1, 'month'))) .median() // Freshly burnt regions appeat bright in SWIR-bands // Use a False Color Visualization var swirVis = { min: 0.0, max: 3000, bands: ['B12', 'B8', 'B4'], }; Map.addLayer(before.clip(geometry), swirVis, 'Before') Map.addLayer(after.clip(geometry), swirVis, 'After') // Write a function to calculate Normalized Burn Ratio (NBR) // 'NIR' (B8) and 'SWIR-2' (B12) var addNBR = function(image) { var nbr = image.normalizedDifference(['B8', 'B12']).rename(['nbr']); return image.addBands(nbr) } var beforeNbr = addNBR(before).select('nbr'); var afterNbr = addNBR(after).select('nbr'); var nbrVis = {min: -0.5, max: 0.5, palette: ['white', 'black']} Map.addLayer(beforeNbr.clip(geometry), nbrVis, 'Prefire NBR'); Map.addLayer(afterNbr.clip(geometry), nbrVis, 'Postfire NBR'); // Calculate Change in NBR (dNBR) var change = beforeNbr.subtract(afterNbr) // Apply a threshold var threshold = 0.3 // Display Burned Areas var burned = change.gt(threshold) Map.addLayer(burned.clip(geometry), {min:0, max:1, palette: ['white', 'red']}, 'Burned', false) Exercise Classifying the Change Image\nTry in Code Editor ↗\n// Define the area of interest var geometry = ee.Geometry.Polygon([[ [76.37639666685044, 11.766523239445169], [76.37639666685044, 11.519036946599561], [76.78426409849106, 11.519036946599561], [76.78426409849106, 11.766523239445169] ]]); var fireStart = ee.Date('2019-02-20'); var fireEnd = ee.Date('2019-02-25'); Map.centerObject(geometry, 10) var s2 = ee.ImageCollection(\"COPERNICUS/S2\") // Apply filters var filtered = s2 .filter(ee.Filter.bounds(geometry)) .select('B.*') // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.5; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA); // Create Before and After composites var before = filteredMasked .filter(ee.Filter.date( fireStart.advance(-2, 'month'), fireStart)) .median() var after = filteredMasked .filter(ee.Filter.date( fireEnd, fireEnd.advance(1, 'month'))) .median() // Write a function to calculate Normalized Burn Ratio (NBR) // 'NIR' (B8) and 'SWIR-2' (B12) var addNBR = function(image) { var nbr = image.normalizedDifference(['B8', 'B12']).rename(['nbr']); return image.addBands(nbr) } var beforeNbr = addNBR(before).select('nbr'); var afterNbr = addNBR(after).select('nbr'); // Calculate Change in NBR (dNBR) var change = beforeNbr.subtract(afterNbr) var dnbrPalette = ['#ffffb2','#fecc5c','#fd8d3c','#f03b20','#bd0026']; // Display the change image Map.addLayer(change.clip(geometry), {min:0.1, max: 0.7, palette: dnbrPalette}, 'Change in NBR') // We can also classify the change image according to // burn severity // United States Geological Survey (USGS) proposed // a classification table to interpret the burn severity // We will assign a discrete class value and visualize it // | Severity | dNBR Range | Class | // |--------------|--------------------|-------| // | Unburned | \u003c 0.1 | 0 | // | Low Severity | \u003e= 0.10 and \u003c0.27 | 1 | // | Moderate-Low | \u003e= 0.27 and \u003c0.44 | 2 | // | Moderate-High| \u003e= 0.44 and\u003c 0.66 | 3 | // | High | \u003e= 0.66 | 4 | // Classification of continuous values can be done // using the .where() function var severity = change .where(change.lt(0.10), 0) .where(change.gte(0.10).and(change.lt(0.27)), 1) .where(change.gte(0.27).and(change.lt(0.44)), 2) .where(change.gte(0.44).and(change.lt(0.66)), 3) .where(change.gt(0.66), 4) // Exercise // The resulting image 'severity' is a discrete image with // pixel values from 0-4 representing the severity class // Display the image according to the following color table // | Severity | Class | Color | // |--------------|-------|---------| // | Unburned | 0 | green | // | Low Severity | 1 | yellow | // | Moderate-Low | 2 | organge | // | Moderate-High| 3 | red | // | High | 4 | magenta | 02. Spectral Distance Change When you want to detect changes from multi-band images, a useful technique is to compute the Spectral Distance and Spectral Angle between the two images. Pixels that exhibit a large change will have a larger distance compared to those that did not change. This technique is particularly useful when there are no suitable index to detect the change. It can be applied to detect change after natural disasters or human conflicts.\nHere we use this technique to detect landslides using before/after composites. You may learn more about this technique at Craig D’Souza’s Change Detection presentation.\nSpectral Distance Change Detection\nOpen in Code Editor ↗\nvar geometry = ee.Geometry.Polygon([[ [75.70357667713435, 12.49723970868507], [75.70357667713435, 12.470171844429931], [75.7528434923199, 12.470171844429931], [75.7528434923199, 12.49723970868507] ]]); Map.centerObject(geometry); var s2 = ee.ImageCollection('COPERNICUS/S2'); var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; var filtered = s2 .filter(ee.Filter.bounds(geometry)) .select('B.*'); // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.65; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA); var dateOfIncident = ee.Date('2018-08-15'); var before = filteredMasked .filter(ee.Filter.date(dateOfIncident.advance(-2, 'year'), dateOfIncident)) .filter(ee.Filter.calendarRange(6, 10, 'month')) .median() .select('B.*'); var after = filteredMasked .filter(ee.Filter.date( dateOfIncident, dateOfIncident.advance(1, 'month'))) .median() .select('B.*'); Map.addLayer(before.clip(geometry), rgbVis, 'Before'); Map.addLayer(after.clip(geometry), rgbVis, 'After'); // Use the spectralDistance() function to get spectral distance measures // Use the metric 'Spectral Angle Mapper (SAM) // The result is the spectral angle in radians var angle = after.spectralDistance(before, 'sam'); Map.addLayer(angle.clip(geometry), {min: 0, max: 1, palette: ['white', 'purple']}, 'Spectral Angle'); // Use the metric 'Squared Euclidian Distance (SED)' var sed = after.spectralDistance(before, 'sed'); // Take square root to get euclidian distance var distance = sed.sqrt(); Map.addLayer(distance.clip(geometry), {min: 0, max: 1500, palette: ['white', 'red']}, 'spectral distance'); Exercise Try in Code Editor ↗\nvar geometry = ee.Geometry.Polygon([[ [75.70357667713435, 12.49723970868507], [75.70357667713435, 12.470171844429931], [75.7528434923199, 12.470171844429931], [75.7528434923199, 12.49723970868507] ]]); Map.centerObject(geometry); var s2 = ee.ImageCollection('COPERNICUS/S2'); var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; var filtered = s2 .filter(ee.Filter.bounds(geometry)) .select('B.*'); // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.65; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA); var dateOfIncident = ee.Date('2018-08-15'); var before = filteredMasked .filter(ee.Filter.date(dateOfIncident.advance(-2, 'year'), dateOfIncident)) .filter(ee.Filter.calendarRange(6, 10, 'month')) .median() .select('B.*'); var after = filteredMasked .filter(ee.Filter.date( dateOfIncident, dateOfIncident.advance(1, 'month'))) .median() .select('B.*'); Map.addLayer(before.clip(geometry), rgbVis, 'Before'); Map.addLayer(after.clip(geometry), rgbVis, 'After'); // Use the spectralDistance() function to get spectral distance measures // Use the metric 'Spectral Angle Mapper (SAM) // The result is the spectral angle in radians var angle = after.spectralDistance(before, 'sam'); Map.addLayer(angle.clip(geometry), {min: 0, max: 1, palette: ['white', 'purple']}, 'Spectral Angle'); // Exercise // Inspect the angle image and find a suitable threshold // that signifies damage after the landslides // Apply the threshold and create a new image showing landslides // Display the results // Hint: Use the .gt() method to apply the threshold 03. Direct Classification of Change This technique of change detection is also known as One-pass Classification or Direct Multi-date Classification. Here we create a single stacked image containing bands from before and after images. We train a classifier with training data sampled from the stacked image and apply the classifier on the stacked image to find all change pixels.\nAll pixels that changed from bare ground to built-up\nOpen in Code Editor ↗\nvar bangalore = ee.FeatureCollection('users/ujavalgandhi/public/bangalore_boundary'); var change = ee.FeatureCollection('users/ujavalgandhi/e2e/bangalore_change_gcps'); var nochange = ee.FeatureCollection('users/ujavalgandhi/e2e/bangalore_nochange_gcps'); var s2 = ee.ImageCollection('COPERNICUS/S2'); var geometry = bangalore.geometry(); Map.centerObject(geometry); var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; // Write a function for Cloud masking var filtered = s2 .filter(ee.Filter.bounds(geometry)) // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.5; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA) .select('B.*'); // January 2019 var filtered2019 = filteredMasked.filter(ee.Filter.date('2019-01-01','2019-02-01')) var image2019 = filtered2019.median(); // Display the input composite. Map.addLayer(image2019.clip(geometry), rgbVis, '2019'); // January 2020 var filtered2020 = filteredMasked.filter(ee.Filter.date('2020-01-01','2020-02-01')) var image2020 = filtered2020.median(); // Display the input composite. Map.addLayer(image2020.clip(geometry), rgbVis, '2020'); var stackedImage = image2019.addBands(image2020); // Overlay the point on the image to get training data. var training = stackedImage.sampleRegions({ collection: change.merge(nochange), properties: ['class'], scale: 10 }); // Train a classifier. var classifier = ee.Classifier.smileRandomForest(50).train({ features: training, classProperty: 'class', inputProperties: stackedImage.bandNames() }); // Classify the image. var classified = stackedImage.classify(classifier); Map.addLayer(classified.clip(geometry), {min: 0, max: 1, palette: ['white', 'red']}, 'change'); Exercise Try in Code Editor ↗\n// Add an NDBI band to improve the detection of changes. var addNDBI = function(image) { var ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi']); return image.addBands(ndbi) } // use addNDBI() function to add the NDBI band to both 2019 and 2020 composite images // Hint1: You can save the resulting image in the same variable to avoid changing // a lot of code. // var image = addNDBI(image) 04. Post-classification Comparison We dealing with multi-class images, a useful metric for change detection is to know how many pixels from class X changed to class Y. This can be accomplished using the ee.Reducer.frequencyHistogram() reducer as shown below.\nOpen in Code Editor ↗\nvar bangalore = ee.FeatureCollection('users/ujavalgandhi/public/bangalore_boundary'); var urban = ee.FeatureCollection('users/ujavalgandhi/e2e/urban_gcps'); var bare = ee.FeatureCollection('users/ujavalgandhi/e2e/bare_gcps'); var water = ee.FeatureCollection('users/ujavalgandhi/e2e/water_gcps'); var vegetation = ee.FeatureCollection('users/ujavalgandhi/e2e/vegetation_gcps'); var s2 = ee.ImageCollection('COPERNICUS/S2_SR'); var geometry = bangalore.geometry(); Map.centerObject(geometry); var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; // 2019 Jan var filtered = s2 .filter(ee.Filter.date('2019-01-01', '2019-02-01')) .filter(ee.Filter.bounds(geometry)) .select('B.*'); var before = filtered.median().clip(geometry); // Display the input composite. Map.addLayer(before.clip(geometry), rgbVis, 'before'); var training = urban.merge(bare).merge(water).merge(vegetation); // Overlay the point on the image to get training data. var training = before.sampleRegions({ collection: training, properties: ['landcover'], scale: 10 }); // Train a classifier. var classifier = ee.Classifier.smileRandomForest(50).train({ features: training, classProperty: 'landcover', inputProperties: before.bandNames() }); // // Classify the image. var beforeClassified = before.classify(classifier); var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ]; var classifiedVis = {min: 0, max: 3, palette: palette}; Map.addLayer(beforeClassified.clip(geometry), classifiedVis, 'before_classified'); // 2020 Jan var after = s2 .filter(ee.Filter.date('2020-01-01', '2020-02-01')) .filter(ee.Filter.bounds(geometry)) .select('B.*') .median(); Map.addLayer(after.clip(geometry), rgbVis, 'after'); // Classify the image. var afterClassified= after.classify(classifier); Map.addLayer(afterClassified.clip(geometry), classifiedVis, 'after_classified'); // Reclassify from 0-3 to 1-4 var beforeClasses = beforeClassified.remap([0, 1, 2, 3], [1, 2, 3, 4]); var afterClasses = afterClassified.remap([0, 1, 2, 3], [1, 2, 3, 4]); // Show all changed areas var changed = afterClasses.subtract(beforeClasses).neq(0); Map.addLayer(changed.clip(geometry), {min:0, max:1, palette: ['white', 'red']}, 'Change'); // We multiply the before image with 100 and add the after image // The resulting pixel values will be unique and will represent each unique transition // i.e. 102 is urban to bare, 103 urban to water etc. var merged = beforeClasses.multiply(100).add(afterClasses).rename('transitions'); // Use a frequencyHistogram to get a pixel count per class var transitionMatrix = merged.reduceRegion({ reducer: ee.Reducer.frequencyHistogram(), geometry: geometry, maxPixels: 1e10, scale:10, tileScale: 16 }); // This prints number of pixels for each class transition print(transitionMatrix.get('transitions')); // If we want to calculate the area of each class transition // we can use a grouped reducer // Divide by 1e6 to get the area in sq.km. var areaImage = ee.Image.pixelArea().divide(1e6).addBands(merged); // Calculate Area by each Transition Class // using a Grouped Reducer var areas = areaImage.reduceRegion({ reducer: ee.Reducer.sum().group({ groupField: 1, groupName: 'transitions', }), geometry: geometry, scale: 100, tileScale: 4, maxPixels: 1e10 }); // Post-process the result to generate a clean output var classAreas = ee.List(areas.get('groups')); var classAreaLists = classAreas.map(function(item) { var areaDict = ee.Dictionary(item); var classNumber = ee.Number(areaDict.get('transitions')).format(); var area = ee.Number(areaDict.get('sum')).round(); return ee.List([classNumber, area]); }); var classTransitionsAreaDict = ee.Dictionary(classAreaLists.flatten()); print(classTransitionsAreaDict); Exercise Lost water pixels between 2019 and 2020\nTry in Code Editor ↗\n// Exercise // Show all areas where water became other classes and display the result // Hint1: Select class 3 pixels from before image and NOT class 3 pixels from after image // Hint2: use the .and() operation to select pixels matching both conditions Module 5: Earth Engine Apps This module is focused the concepts related to client vs. server that will help you in creating web apps. We will be building an app using the Earth Engine User Interface API and publishing it to Google Cloud.\nWatch the Video ↗\n01. Client vs. Server The User Interface elements in your Code Editor - Map View, Drawing Tools etc. are ‘client-side’ elements. They run in YOUR browser. Image Collections, feature collections, calculations on Earth Engine objects etc. are ‘server-side’ elements. They run in Google’s data center. You cannot mix both these objects. To learn more, visit the Client vs. Server section of the Earth Engine User Guide.\nTo convert client-side objects to server-side objects, you can use the appropriate API function. Server-side functions start with ee., such ee.Date(), ee.Image() etc. To convert server-side objects to client-side objects, you can call .getInfo() on am Earth Engine object. For the Python API, this is the only way to extract information from a server-side object, but the Javascript API provides a better (and preferred) - method for bring server-side objects to client-side using the evaluate() method. This method asynchronously retrieves the value of the object, without blocking the user interface - meaning it will let your code continue to execute while it fetches the value. Tip: You can use ee.Algorithms.ObjectType() to get the type of a server-side object\nOpen in Code Editor ↗\nvar date = '2020-01-01' // This is client-side print(typeof(date)) var eedate = ee.Date('2020-01-01').format() // This is server-side print(typeof(eedate)) // To bring server-side objects to client-side, you can call .getInfo() // var clientdate = eedate.getInfo() // print(clientdate) // print(typeof(clientdate)) // getInfo() blocks the execution of your code till the value is fetched // If the value takes time to compute, your code editor will freeze // This is not a good user experience var s2 = ee.ImageCollection(\"COPERNICUS/S2_SR\") var filtered = s2.filter(ee.Filter.date('2020-01-01', '2020-02-01')) //var numImages = filtered.size().getInfo() //print(numImages) // A better approach is to use evaluate() function // You need to define a 'callback' function which will be called once the // value has been computed and ready to be used. var myCallback = function(object) { print(object) } print('Computing the size of the collection') var numImages = filtered.size().evaluate(myCallback) Exercise Try in Code Editor ↗\nvar date = ee.Date.fromYMD(2019, 1, 1) print(date) // We can use the format() function to create // a string from a date object var dateString = date.format('dd MMM, YYYY') print(dateString) // Exercise // The print statement below combines a client-side string // with a server-side string - resulting in an error. // Fix the code so that the following message is printed // 'The date is 01 Jan, 2019' var message = 'The date is ' + dateString print(message) // Hint: // Convert the client-side string to a server-side string // Use ee.String() to create a server-side string // Use the .cat() function instead of + to combine 2 strings 02. Using UI Elements Earth Engine comes with a User Interface API that allows you to build an interactive web application powered by Earth Engine.\nThe Earth Engine API provides a library of User Interface (UI) widgets - such as Buttons, Drop-down Menus, Sliders etc. - that can be used to create interactive apps. All the user interface functions are contained in the ui. package - such as ui.Select(), ui.Button(). You can create those elements by calling these functions with appropriate parameters. Learn more in the Earth Engine User Interface API section of the Earth Engine User Guide.\nThis section shows how to build a drop-down selector using the ui.Select() widget.\nOpen in Code Editor ↗\n// You can add any widgets from the ui.* module to the map var years = ['2014', '2015', '2016', '2017']; // Let's create a ui.Select() dropdown with the above values var yearSelector = ui.Select({ items: years, value: '2014', placeholder: 'Select a year', }) Map.add(yearSelector); var loadImage = function() { var year = yearSelector.getValue(); var col = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\"); var startDate = ee.Date.fromYMD( ee.Number.parse(year), 1, 1); var endDate = startDate.advance(1, 'year'); var filtered = col.filter(ee.Filter.date(startDate, endDate)); var composite = filtered.mean().select('avg_rad'); var layerName = 'Night Lights ' + year; var nighttimeVis = {min: 0.0, max: 60.0}; Map.addLayer(composite, nighttimeVis, layerName); }; var button = ui.Button({ label: 'Click to Load Image', onClick: loadImage, }); Map.add(button); Exercise Try in Code Editor ↗\n// Instead of manually creating a list of years like before // we can create a list of years using ee.List.sequence() var years = ee.List.sequence(2014, 2020) // Convert them to strings using format() function var yearStrings = years.map(function(year){ return ee.Number(year).format('%04d') }) print(yearStrings); // Convert the server-side object to client-side using // evaluate() and use it with ui.Select() yearStrings.evaluate(function(yearList) { var yearSelector = ui.Select({ items: yearList, value: '2014', placeholder: 'Select a year', }) Map.add(yearSelector) }); // Exercise // Create another dropdown with months from 1 to 12 // and add it to the map. 03. Building and Publishing an App Building a web mapping application typically requires the skills of a full stack developer and are out of reach for most analysts and scientists. But the Earth Engine User Interface API makes this process much more accessible by providing ready-to-use widgets and free cloud hosting to allow anyone to publish an app with just a few lines of code. The main container object is the ui.Panel() which can contain different types of widgets.\nThe code below shows how to build an app called Night Lights Explorer that allows anyone to pick a year/month and load the VIIRS Nighttime Day/Night Band Composite for the selected month. Copy/paste the code below to your Code Editor and click Run.\nYou will see a panel on the right-hand side with 2 drop-down boxes and a button. These are User Interface (UI) widgets provided by the Earth Engine API that allows the user to interactively select the values. You can select the values for year and month and click Load button to see the image for the selected month.\nOpen in Code Editor ↗\n// Panels are the main container widgets var mainPanel = ui.Panel({ style: {width: '300px'} }); var title = ui.Label({ value: 'Night Lights Explorer', style: {'fontSize': '24px'} }); // You can add widgets to the panel mainPanel.add(title); // You can even add panels to other panels var dropdownPanel = ui.Panel({ layout: ui.Panel.Layout.flow('horizontal'), }); mainPanel.add(dropdownPanel); var yearSelector = ui.Select({ placeholder: 'please wait..', }) var monthSelector = ui.Select({ placeholder: 'please wait..', }) var button = ui.Button('Load') dropdownPanel.add(yearSelector) dropdownPanel.add(monthSelector) dropdownPanel.add(button) // Let's add a dropdown with the years var years = ee.List.sequence(2014, 2020) var months = ee.List.sequence(1, 12) // Dropdown items need to be strings var yearStrings = years.map(function(year){ return ee.Number(year).format('%04d'); }); var monthStrings = months.map(function(month){ return ee.Number(month).format('%02d'); }); // Evaluate the results and populate the dropdown yearStrings.evaluate(function(yearList) { yearSelector.items().reset(yearList); yearSelector.setPlaceholder('select a year'); }); monthStrings.evaluate(function(monthList) { monthSelector.items().reset(monthList); monthSelector.setPlaceholder('select a month'); }); // Define a function that triggers when any value is changed var loadComposite = function() { var col = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\"); var year = yearSelector.getValue(); var month = monthSelector.getValue(); var startDate = ee.Date.fromYMD( ee.Number.parse(year), ee.Number.parse(month), 1); var endDate = startDate.advance(1, 'month'); var filtered = col.filter(ee.Filter.date(startDate, endDate)); var image = ee.Image(filtered.first()).select('avg_rad'); var nighttimeVis = {min: 0.0, max: 60.0}; var layerName = 'Night Lights ' + year + '-' + month; Map.addLayer(image, nighttimeVis, layerName); }; button.onClick(loadComposite); Map.setCenter(76.43, 12.41, 8); ui.root.add(mainPanel); Exercise Try in Code Editor ↗\n// Exercise // Add a button called 'Reset' // Clicking the button should remove all loaded layers // Hint: Use Map.clear() for removing the layers 04. Publishing the App We will now publish this app. Click on the Apps button.\nApp with UI Elements\nIn the Manage Apps window, click New App.\nSelect the existing project or create a new project. The app will be hosted on Google Cloud, so you will need to create and link a Google Cloud project with the app. If you don’t have a Google Cloud account, you can select the Register a New Project option to create a new project. You can provide an edit access based on the project selection.\nGive the name of your app and see the URL created for your app.\nSelect code to use for the app. It can be from the current content or choose any repository path where the code is saved. We will go ahead with Current contents of editor\nClick next and in the Publish New App dialog, leave all other settings to default and click Publish.\nThe app will be hosted on Google Cloud and you can access it by clicking on the App Name of your app in the Manage Apps dialog.\nYou will see your Earth Engine powered app running in the browser. Anyone can access and interact with the app by just visiting the App URL.\nThe app publishing process takes a few minutes. So if you get an error that your app is not yet ready, check back in a few minutes.\nExplore The App ↗\nExercise Try in Code Editor ↗\n// Panels are the main container widgets var mainPanel = ui.Panel({ style: {width: '300px'} }); var title = ui.Label({ value: 'Night Lights Explorer', style: {'fontSize': '24px'} }); // You can add widgets to the panel mainPanel.add(title) // You can even add panels to other panels var dropdownPanel = ui.Panel({ layout: ui.Panel.Layout.flow('horizontal'), }); mainPanel.add(dropdownPanel); var yearSelector = ui.Select({ placeholder: 'please wait..', }) var monthSelector = ui.Select({ placeholder: 'please wait..', }) var button = ui.Button('Load') dropdownPanel.add(yearSelector) dropdownPanel.add(monthSelector) dropdownPanel.add(button) // Let's add a dropdown with the years var years = ee.List.sequence(2014, 2020) var months = ee.List.sequence(1, 12) // Dropdown items need to be strings var yearStrings = years.map(function(year){ return ee.Number(year).format('%04d') }) var monthStrings = months.map(function(month){ return ee.Number(month).format('%02d') }) // Evaluate the results and populate the dropdown yearStrings.evaluate(function(yearList) { yearSelector.items().reset(yearList) yearSelector.setPlaceholder('select a year') }) monthStrings.evaluate(function(monthList) { monthSelector.items().reset(monthList) monthSelector.setPlaceholder('select a month') }) // Define a function that triggers when any value is changed var loadComposite = function() { var col = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\"); var year = yearSelector.getValue() var month = monthSelector.getValue() var startDate = ee.Date.fromYMD( ee.Number.parse(year), ee.Number.parse(month), 1) var endDate = startDate.advance(1, 'month') var filtered = col.filter(ee.Filter.date(startDate, endDate)) var image = ee.Image(filtered.first()).select('avg_rad') var nighttimeVis = {min: 0.0, max: 60.0} var layerName = 'Night Lights ' + year + '-' + month Map.addLayer(image, nighttimeVis, layerName) } button.onClick(loadComposite) // Exercise // Set the map center to your area of interest // Replace the author label with your name // Publish the app. Map.setCenter(76.43, 12.41, 8) var authorLabel = ui.Label('App by: Ujaval Gandhi'); mainPanel.add(authorLabel); ui.root.add(mainPanel); 05. Create a Split Panel App Another useful widget that can be used in Apps is ui.SplitPanel(). This allows you to create an app that can display 2 different images of the same region that can be explored interactively by swiping. Here we create an app to explore the ESA WorldCover 10m global classification dataset.\nOn the left-hand panel, we will load a Sentinel-2 composite for the year 2020. On the right-hand panel, we will load the 11-class landcover classification of the same region.\nOpen in Code Editor ↗\nvar admin2 = ee.FeatureCollection(\"FAO/GAUL_SIMPLIFIED_500m/2015/level2\"); var selected = admin2 .filter(ee.Filter.eq('ADM1_NAME', 'Karnataka')) .filter(ee.Filter.eq('ADM2_NAME', 'Bangalore Urban')) var geometry = selected.geometry(); Map.centerObject(geometry) var s2 = ee.ImageCollection(\"COPERNICUS/S2_HARMONIZED\"); // Write a function to scale the bands var scaleImage = function(image) { return image .multiply(0.0001) .copyProperties(image, [\"system:time_start\"]) } var filtered = s2 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.bounds(geometry)) .filter(ee.Filter.date('2020-01-01', '2021-01-01')); // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.5; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA); var filteredMaskedScaled = filteredMasked.map(scaleImage); // Create a median composite for 2020 var composite = filteredMaskedScaled.median(); // Load ESA WorldCover 2020 Classification var worldcover = ee.ImageCollection(\"ESA/WorldCover/v100\") var filtered = worldcover .filter(ee.Filter.date('2020-01-01', '2021-01-01')); var classification = ee.Image(filtered.first()); // Create a Split Panel App // Set a center and zoom level. // Create two maps. var leftMap = ui.Map(); var rightMap = ui.Map(); // Link them together. var linker = ui.Map.Linker([leftMap, rightMap]); // Create a split panel with the two maps. var splitPanel = ui.SplitPanel({ firstPanel: leftMap, secondPanel: rightMap, orientation: 'horizontal', wipe: true }); // Remove the default map from the root panel. ui.root.clear(); // Add our split panel to the root panel. ui.root.add(splitPanel); // Add the layers to the maps // Composite goes to the leftMap var rgbVis = {min: 0.0, max: 0.3, bands: ['B4', 'B3', 'B2']}; leftMap.addLayer(composite.clip(geometry), rgbVis, '2020 Composite'); leftMap.centerObject(geometry); // Classification foes to the rightMap rightMap.addLayer(classification.clip(geometry), {}, 'WorldCover Classification'); rightMap.centerObject(geometry); Exercise Try in Code Editor ↗\nvar admin2 = ee.FeatureCollection(\"FAO/GAUL_SIMPLIFIED_500m/2015/level2\"); var selected = admin2 .filter(ee.Filter.eq('ADM1_NAME', 'Karnataka')) .filter(ee.Filter.eq('ADM2_NAME', 'Bangalore Urban')) var geometry = selected.geometry(); Map.centerObject(geometry) var s2 = ee.ImageCollection(\"COPERNICUS/S2_HARMONIZED\"); // Write a function to scale the bands var scaleImage = function(image) { return image .multiply(0.0001) .copyProperties(image, [\"system:time_start\"]) } var filtered = s2 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.bounds(geometry)) .filter(ee.Filter.date('2020-01-01', '2021-01-01')); // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.5; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA); var filteredMaskedScaled = filteredMasked.map(scaleImage); // Create a median composite for 2020 var composite = filteredMaskedScaled.median(); // Load ESA WorldCover 2020 Classification var worldcover = ee.ImageCollection(\"ESA/WorldCover/v100\") var filtered = worldcover .filter(ee.Filter.date('2020-01-01', '2021-01-01')); var classification = ee.Image(filtered.first()); // Create a Split Panel App // Create two maps. var leftMap = ui.Map(); var rightMap = ui.Map(); // Link them together. var linker = ui.Map.Linker([leftMap, rightMap]); // Create a split panel with the two maps. var splitPanel = ui.SplitPanel({ firstPanel: leftMap, secondPanel: rightMap, orientation: 'horizontal', wipe: true }); // Remove the default map from the root panel. ui.root.clear(); // Add our split panel to the root panel. ui.root.add(splitPanel); // Add the layers to the maps // Composite goes to the leftMap var rgbVis = {min: 0.0, max: 0.3, bands: ['B4', 'B3', 'B2']}; leftMap.addLayer(composite.clip(geometry), rgbVis, '2020 Composite'); leftMap.centerObject(geometry); // Classification foes to the rightMap rightMap.addLayer(classification.clip(geometry), {}, 'WorldCover Classification'); rightMap.centerObject(geometry); // Adding a Legend // The following code creates a legend with class names and colors // Create the panel for the legend items. var legend = ui.Panel({ style: { position: 'middle-right', padding: '8px 15px' } }); // Create and add the legend title. var legendTitle = ui.Label({ value: 'ESA WorldCover Classes', style: { fontWeight: 'bold', fontSize: '18px', margin: '0 0 4px 0', padding: '0' } }); legend.add(legendTitle); var loading = ui.Label('Loading legend...', {margin: '2px 0 4px 0'}); legend.add(loading); // Creates and styles 1 row of the legend. var makeRow = function(color, name) { // Create the label that is actually the colored box. var colorBox = ui.Label({ style: { backgroundColor: '#' + color, // Use padding to give the box height and width. padding: '8px', margin: '0 0 4px 0' } }); // Create the label filled with the description text. var description = ui.Label({ value: name, style: {margin: '0 0 4px 6px'} }); return ui.Panel({ widgets: [colorBox, description], layout: ui.Panel.Layout.Flow('horizontal') }); }; var BAND_NAME = 'Map'; // Get the list of palette colors and class names from the image. classification.toDictionary().select([BAND_NAME + \".*\"]).evaluate(function(result) { var palette = result[BAND_NAME + \"_class_palette\"]; var names = result[BAND_NAME + \"_class_names\"]; loading.style().set('shown', false); for (var i = 0; i \u003c names.length; i++) { legend.add(makeRow(palette[i], names[i])); } }); // Print the panel containing the legend print(legend); // Exercise // Change the filter to select your chosen Admin2 region // The 'legend' varaible above is a panel containing the legend // for the classification. Add it to the map below // Hint: UI Widgets can only be shown once in the app. Remove the // print statement before adding the legend to the map. // Hint: Load the legend in the right-hand side map. Module 6: Google Earth Engine Python API Introduction to the Python API Till this point in the course, we have used the Earth Engine Javascript API for all our analysis. Earth Engine also provides a Python API. If you are a Python programmer, you may prefer to use the Python API to integrate Earth Engine in your spatial analysis workflow. There are many options for running Python code that uses the Google Earth Engine API. We will use the following two methods in this course.\nWatch the Video ↗\nGoogle Colab An easy way to start using the Google Earth Engine Python API is via Google Colab. Google Colaboratory provides a hosted environment to run Python notebooks without having to install Python locally. It also comes pre-installed with many useful packages - including the Google Earth Engine Python API. You can simply visit https://colab.research.google.com/ and start a new notebook.\nLocal Development Environment An advantage of Python API is that you can use it in your own development environment - so you get a lot more flexibility to automate as well as combine other analysis and visualization libraries with Earth Engine. This requires installing Python and the Earth Engine Python API on your machine or server. You also need to do a one-time authentication and save the token on the machine. The preferred method for installing the Earth Engine Python API is via Anaconda. Please follow our Google Earth Engine Python API Installation Guide for step-by-step instructions.\n01. Python API Syntax Open in Google Colab ↗\nComing from the programming in Earth Engine through the Code Editor, you will need to slightly adapt your scripts to be able to run in Python. For the bulk of your code, you will be using Earth Engine API’s server-side objects and functions - which will be exactly the same in Python. You only need to make a few syntactical changes.\nHere’s the full list of differences.\nInitialization First of all, you need to run the following cells to initialize the API and authorize your account. You must have a Google Cloud Project associated with your GEE account. Replace the cloud_project with your own project from Google Cloud Console.\nYou will be prompted to allow the notebook to access your Google credentials to sign-in to the account and allow access to Google Drive and Google Cloud data. Once you approve, it will proceed to initialize the Earth Engine API. This step needs to be done just once per session.\ncloud_project = 'spatialthoughts' try: ee.Initialize(project=cloud_project) except: ee.Authenticate() ee.Initialize(project=cloud_project) Variables Python code doesn’t use the ‘var’ keyword\njavascript code:\nvar city = 'San Fransico' var state = 'California' print(city, state) var population = 881549 print(population) city = 'San Fransico' state = 'California' print(city, state) population = 881549 print(population) Earth Engine Objects You can create Earth Engine objects using the ee functions the same way.\ns2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') geometry = ee.Geometry.Polygon([[ [82.60642647743225, 27.16350437805251], [82.60984897613525, 27.1618529901377], [82.61088967323303, 27.163695288375266], [82.60757446289062, 27.16517483230927] ]]) Line Continuation Python doesn’t use a semi-colon for line ending. To indicate line-continuation you need to use the \\ character\njavascript code:\nvar s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED'); var filtered = s2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-02-01', '2019-03-01')) .filter(ee.Filter.bounds(geometry)); filtered = s2 \\ .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\ .filter(ee.Filter.date('2019-02-01', '2019-03-01')) \\ .filter(ee.Filter.bounds(geometry)) Functions Instead of the function keyword, Python uses the def keyword. Also the in-line functions are defined using lambda anonymous functions.\nIn the example below, also now the and operator - which is capitalized as And in Python version to avoid conflict with the built-in and operator. The same applies to Or and Not operators. true, false, null in Python are also spelled as True, False and None.\njavascript code:\nfunction maskS2clouds(image) { var qa = image.select('QA60') var cloudBitMask = 1 \u003c\u003c 10; var cirrusBitMask = 1 \u003c\u003c 11; var mask = qa.bitwiseAnd(cloudBitMask).eq(0).and( qa.bitwiseAnd(cirrusBitMask).eq(0)) return image.updateMask(mask)//.divide(10000) .select(\"B.*\") .copyProperties(image, [\"system:time_start\"]) } function addNDVI(image) { var ndvi = image.normalizedDifference(['B8', 'B4']).rename('ndvi'); return image.addBands(ndvi); } def maskS2clouds(image): qa = image.select('QA60') cloudBitMask = 1 \u003c\u003c 10 cirrusBitMask = 1 \u003c\u003c 11 mask = qa.bitwiseAnd(cloudBitMask).eq(0).And( qa.bitwiseAnd(cirrusBitMask).eq(0)) return image.updateMask(mask) \\ .select(\"B.*\") \\ .copyProperties(image, [\"system:time_start\"]) def addNDVI(image): ndvi = image.normalizedDifference(['B8', 'B4']).rename('ndvi') return image.addBands(ndvi) withNdvi = filtered \\ .map(maskS2clouds) \\ .map(addNDVI) Function Arguments Named arguments to Earth Engine functions need to be in quotes. Also when passing the named arguments as a dictionary, it needs to be passed using the ** keyword.\njavascript code:\nvar composite = withNdvi.median(); var ndvi = composite.select('ndvi'); var stats = ndvi.reduceRegion({ reducer: ee.Reducer.mean(), geometry: geometry, scale: 10, maxPixels: 1e10 }) composite = withNdvi.median() ndvi = composite.select('ndvi') stats = ndvi.reduceRegion(**{ 'reducer': ee.Reducer.mean(), 'geometry': geometry, 'scale': 10, 'maxPixels': 1e10 }) Printing Values The print() function syntax is the same. But you must remember that in the Code Editor when you cann print, the value of the server object is fetched and then printed. You must do that explicitely by calling getInfo() on any server-side object.\njavascript code:\nprint(stats.get('ndvi') print(stats.get('ndvi').getInfo()) In-line functions The syntax for defining in-line functions is also slightly different. You need to use the lambda keyword.\njavascript code:\nvar myList = ee.List.sequence(1, 10); var newList = myList.map(function(number) { return ee.Number(number).pow(2); print(newList); myList = ee.List.sequence(1, 10) newList = myList.map(lambda number: ee.Number(number).pow(2)) print(newList.getInfo()) Exercise Take the Javascript code snippet below and write the equiavalent Python code in the cell below.\nHint1: Chaining of filters require the use of line continuation character \\ Hint2: Printing of server-side objects requires calling .getInfo() on the object The correct code should print the value 30.\nvar geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241]); var s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED'); var filtered = s2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)); print(filtered.size()); 02. Automatic Conversion of Javascript Code to Python Open in Google Colab ↗\nInteractive leaflet map created by geemap\ngeemap is an open-source Python package that comes with many helpful features that help you use Earth Engine effectively in Python.\nIt comes with a function that can help you translate your javascript earth engine code to Python automatically.\nThe geemap package is pre-installed in Colab.\nInitialization First of all, you need to run the following cells to initialize the API and authorize your account. You must have a Google Cloud Project associated with your GEE account. Replace the cloud_project with your own project from Google Cloud Console.\ncloud_project = 'spatialthoughts' try: ee.Initialize(project=cloud_project) except: ee.Authenticate() ee.Initialize(project=cloud_project) Automatic Conversion using GUI geemap comes with a user interface that can be used to interactively do code conversion. Let’s try to convert the following Javascript code to Python.\nvar geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241]); var s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED'); var rgbVis = {min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2']}; var filtered = s2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)); var medianComposite = filtered.median(); Map.centerObject(geometry, 10); Map.addLayer(medianComposite, rgbVis, 'Median Composite'); Run the cell below to load the map widget. Once the map widget loads, click the Toolbar icon in the top-right corner and select the Convert Earth Engine Javascript to Python tool. Paste your Javascript code and click Convert.\nm = geemap.Map(width=800) m You will see the auto-converted code displayed. Copy and paste it into a new cell and run it. Your code will be run using the GEE Python API.\ngeometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241]) s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') rgbVis = {'min': 0.0, 'max': 3000, 'bands': ['B4', 'B3', 'B2']} filtered = s2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\ .filter(ee.Filter.date('2019-01-01', '2020-01-01')) \\ .filter(ee.Filter.bounds(geometry)) medianComposite = filtered.median() m.centerObject(geometry, 10) m.addLayer(medianComposite, rgbVis, 'Median Composite') If your code loads any layers, they will be loaded on the map widget. To display it, open a new code cell and just type m to display the widget.\nAutomatic Conversion using Code geemap offers a function js_snippet_to_py() that can be used to perform the conversion using code. This is useful for batch conversions. To use this, we first create a string with the javascript code.\njavascript_code = \"\"\" var geometry = ee.Geometry.Point([107.61303468448624, 12.130969369851766]); Map.centerObject(geometry, 12) var s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') var rgbVis = { min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2'], }; var filtered = s2 .filter(ee.Filter.date('2019-01-01', '2020-01-01')) .filter(ee.Filter.bounds(geometry)) // Load the Cloud Score+ collection var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED'); var csPlusBands = csPlus.first().bandNames(); // We need to add Cloud Score + bands to each Sentinel-2 // image in the collection // This is done using the linkCollection() function var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands); // Function to mask pixels with low CS+ QA scores. function maskLowQA(image) { var qaBand = 'cs'; var clearThreshold = 0.5; var mask = image.select(qaBand).gte(clearThreshold); return image.updateMask(mask); } var filteredMasked = filteredS2WithCs .map(maskLowQA); // Write a function that computes NDVI for an image and adds it as a band function addNDVI(image) { var ndvi = image.normalizedDifference(['B5', 'B4']).rename('ndvi'); return image.addBands(ndvi); } var withNdvi = filteredMasked.map(addNDVI); var composite = withNdvi.median() palette = [ 'CE7E45', 'DF923D', 'F1B555', 'FCD163', '99B718', '74A901', '66A000', '529400', '3E8601', '207401', '056201', '004C00', '023B01', '012E01', '011D01', '011301']; ndviVis = {min:0, max:0.7, palette: palette } Map.addLayer(withNdvi.select('ndvi'), ndviVis, 'NDVI Composite') \"\"\" lines = geemap.js_snippet_to_py( javascript_code, add_new_cell=False, import_ee=True, import_geemap=True, show_map=True) for line in lines: print(line.rstrip()) The automatic conversion works great. Review it and paste it to the cell below.\nimport ee import geemap m = geemap.Map() geometry = ee.Geometry.Point([107.61303468448624, 12.130969369851766]) m.centerObject(geometry, 12) s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') rgbVis = { 'min': 0.0, 'max': 3000, 'bands': ['B4', 'B3', 'B2'], } filtered = s2 \\ .filter(ee.Filter.date('2019-01-01', '2020-01-01')) \\ .filter(ee.Filter.bounds(geometry)) # Load the Cloud Score+ collection csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED') csPlusBands = csPlus.first().bandNames() # We need to add Cloud Score + bands to each Sentinel-2 # image in the collection # This is done using the linkCollection() function filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands) # Function to mask pixels with low CS+ QA scores. def maskLowQA(image): qaBand = 'cs' clearThreshold = 0.5 mask = image.select(qaBand).gte(clearThreshold) return image.updateMask(mask) filteredMasked = filteredS2WithCs \\ .map(maskLowQA) # Write a function that computes NDVI for an image and adds it as a band def addNDVI(image): ndvi = image.normalizedDifference(['B5', 'B4']).rename('ndvi') return image.addBands(ndvi) withNdvi = filteredMasked.map(addNDVI) composite = withNdvi.median() palette = [ 'CE7E45', 'DF923D', 'F1B555', 'FCD163', '99B718', '74A901', '66A000', '529400', '3E8601', '207401', '056201', '004C00', '023B01', '012E01', '011D01', '011301'] ndviVis = {'min':0, 'max':0.7, 'palette': palette } m.addLayer(withNdvi.select('ndvi'), ndviVis, 'NDVI Composite') m Exercise Take the Javascript code snippet below and use geemap to automatically convert it to Python.\nvar admin2 = ee.FeatureCollection(\"FAO/GAUL_SIMPLIFIED_500m/2015/level2\"); var karnataka = admin2.filter(ee.Filter.eq('ADM1_NAME', 'Karnataka')) var visParams = {color: 'red'} Map.centerObject(karnataka) Map.addLayer(karnataka, visParams, 'Karnataka Districts') 03. Batch Exports Open in Google Colab ↗\nOne of the most commonly asked questions by Earth Engine users is - How do I download all images in a collection? The Earth Engine Python API comes with a ee.batch module that allows you to launch batch exports and manage tasks. The recommended way to do batch exports like this is to use the Python API’s ee.batch.Export functions and use a Python for-loop to iterate and export each image. The ee.batch module also gives you ability to control Tasks - allowing you to automate exports.\nYou can also export images in a collection using Javascript API in the Code Editor but this requires you to manually start the tasks for each image. This approach is fine for small number of images. You can check out the recommended script.\nInitialization First of all, you need to run the following cells to initialize the API and authorize your account. You must have a Google Cloud Project associated with your GEE account. Replace the cloud_project with your own project from Google Cloud Console.\ncloud_project = 'spatialthoughts' try: ee.Initialize(project=cloud_project) except: ee.Authenticate() ee.Initialize(project=cloud_project) Create a Collection geometry = ee.Geometry.Point([107.61303468448624, 12.130969369851766]) s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') rgbVis = { 'min': 0.0, 'max': 3000, 'bands': ['B4', 'B3', 'B2'], } filtered = s2 \\ .filter(ee.Filter.date('2019-01-01', '2020-01-01')) \\ .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\ .filter(ee.Filter.bounds(geometry)) \\ # Load the Cloud Score+ collection csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED') csPlusBands = csPlus.first().bandNames() # We need to add Cloud Score + bands to each Sentinel-2 # image in the collection # This is done using the linkCollection() function filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands) # Function to mask pixels with low CS+ QA scores. def maskLowQA(image): qaBand = 'cs' clearThreshold = 0.5 mask = image.select(qaBand).gte(clearThreshold) return image.updateMask(mask) filteredMasked = filteredS2WithCs \\ .map(maskLowQA) # Write a function that computes NDVI for an image and adds it as a band def addNDVI(image): ndvi = image.normalizedDifference(['B5', 'B4']).rename('ndvi') return image.addBands(ndvi) withNdvi = filteredMasked.map(addNDVI) Export All Images Exports are done via the ee.batch module. This module allows you to automatically start an export - making it suitable for batch exports.\nimage_ids = withNdvi.aggregate_array('system:index').getInfo() print('Total images: ', len(image_ids)) # Export with 100m resolution for this demo for i, image_id in enumerate(image_ids): image = ee.Image(withNdvi.filter(ee.Filter.eq('system:index', image_id)).first()) task = ee.batch.Export.image.toDrive(**{ 'image': image.select('ndvi'), 'description': 'Image Export {}'.format(i+1), 'fileNamePrefix': image_id, 'folder':'earthengine', 'scale': 100, 'region': image.geometry(), 'maxPixels': 1e10 }) task.start() print('Started Task: ', i+1) Manage Running/Waiting Tasks You can manage tasks as well. Get a list of tasks and get state information on them\ntasks = ee.batch.Task.list() for task in tasks: task_id = task.status()['id'] task_state = task.status()['state'] print(task_id, task_state) You can cancel tasks as well\ntasks = ee.batch.Task.list() for task in tasks: task_id = task.status()['id'] task_state = task.status()['state'] if task_state == 'RUNNING' or task_state == 'READY': task.cancel() print('Task {} canceled'.format(task_id)) else: print('Task {} state is {}'.format(task_id, task_state)) Exercise The code below uses the TerraClimate data and creates an ImageCollection with 12 monthly images of maximum temperature. It also extract the geometry for Australia from the LSIB collection. Add the code to start an export task for each image in the collection for australia.\nHint1: TerraClimate images have a scale of 4638.3m Hint2: You need to export the image contained in the clippedImage variable import ee lsib = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017') australia = lsib.filter(ee.Filter.eq('country_na', 'Australia')) geometry = australia.geometry() terraclimate = ee.ImageCollection('IDAHO_EPSCOR/TERRACLIMATE') tmax = terraclimate.select('tmmx') def scale(image): return image.multiply(0.1) \\ .copyProperties(image,['system:time_start']) tmaxScaled = tmax.map(scale) filtered = tmaxScaled \\ .filter(ee.Filter.date('2020-01-01', '2021-01-01')) \\ .filter(ee.Filter.bounds(geometry)) image_ids = filtered.aggregate_array('system:index').getInfo() print('Total images: ', len(image_ids)) Replace the comments with your code.\nfor i, image_id in enumerate(image_ids): exportImage = ee.Image(filtered.filter(ee.Filter.eq('system:index', image_id)).first()) # Clip the image to the region geometry clippedImage = exportImage.clip(geometry) ## Create the export task using ee.batch.Export.image.toDrive() ## Start the task Launching multiple tasks using the Python API\n04. Using Earth Engine with XArray Open in Google Colab ↗\nXEE is an python package for working with Google Earth Engine data with XArray. XEE makes it possible to leverage the strengths of both GEE and the Python ecosystem around XArray.\nWe will learn how to use XEE to extract and process a NDVI time-series for a single point location.\nIf you want to download processed time-series images as GeoTIFF files, pleasee see this notebook.\nInstallation Let’s install the required packages in the Colab environment.\n%%capture if 'google.colab' in str(get_ipython()): !pip install --upgrade xee import ee import xarray import matplotlib.pyplot as plt Initialization First of all, you need to run the following cells to initialize the API and authorize your account. You must have a Google Cloud Project associated with your GEE account. Replace the cloud_project with your own project from Google Cloud Console.\nWe are using the High-volume Endpoint which supports large number of concurrent requests and is recommended when working with XEE.\ncloud_project = 'spatialthoughts' try: ee.Initialize( project=cloud_project, opt_url='https://earthengine-highvolume.googleapis.com' ) except: ee.Authenticate() ee.Initialize( project=cloud_project, opt_url='https://earthengine-highvolume.googleapis.com' ) Select a location. geometry = ee.Geometry.Point([82.60759592318209, 27.163481733946846]) Preprocess the data in GEE We start with the Sentinel-2 L1C collection. We pre-process the data by applying cloud masking and pixel scaling.\ns2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') filtered = s2 \\ .filter(ee.Filter.date('2017-01-01', '2018-01-01')) \\ .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\ .filter(ee.Filter.bounds(geometry)) # Load the Cloud Score+ collection csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED') csPlusBands = csPlus.first().bandNames() # We need to add Cloud Score + bands to each Sentinel-2 # image in the collection # This is done using the linkCollection() function filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands) # Function to mask pixels with low CS+ QA scores. def maskLowQA(image): qaBand = 'cs' clearThreshold = 0.5 mask = image.select(qaBand).gte(clearThreshold) return image.updateMask(mask) filteredMasked = filteredS2WithCs \\ .map(maskLowQA) # Write a function that computes NDVI for an image and adds it as a band # Create a new image to overcome https://github.com/google/Xee/issues/88 def addNDVI(image): ndvi = image.normalizedDifference(['B8', 'B4']).rename('ndvi') return image.multiply(0.0001).addBands(ndvi)\\ .copyProperties(image, ['system:time_start']) # Map the function over the collection withNdvi = filteredMasked.map(addNDVI) Load ImageCollection as XArray Dataset Now we have an ImageCollection that we want to get it as a XArray Dataset. We define the region of interest and extract the ImageCollection using the ee engine.\nds = xarray.open_dataset( withNdvi, engine='ee', crs='EPSG:3857', scale=10, geometry=geometry, ee_mask_value=-9999, ) ds Select the ndvi band.\nndvi_time_series = ds.ndvi Run compute() to fetch the pixels from Earth Engine. This may take some time depending on the size of the request. This is a time-series at a single pixel, so we also squeeze() to remove the X and Y dimensions and get an array of NDVI values.\noriginal_time_series = ndvi_time_series.compute() original_time_series = original_time_series.squeeze() original_time_series Plot the time-series.\nfig, ax = plt.subplots(1, 1) fig.set_size_inches(10, 5) original_time_series.plot.line( ax=ax, x='time', marker='o', color='#66c2a4', linestyle='--', linewidth=1, markersize=4) plt.show() Process Time-Series using XArray We use XArray’s excellent time-series processing functionality to process the time-series. First, we create a regularly spaced time-series.\ntime_series_resampled = original_time_series\\ .resample(time='5d').mean(dim='time') time_series_resampled Next we fill the cloud-masked pixels with linearly interpolated values from temporal neighbors.\ntime_series_interpolated = time_series_resampled\\ .interpolate_na('time', use_coordinate=False) time_series_interpolated We also apply a moving-window smoothing to remove noise.\ntime_series_smooth = time_series_interpolated\\ .rolling(time=3, center=True).mean() time_series_smooth A moving-window smoothing removed the first and last values of the time-series. We anchor the smoothed time-series with the values from the original time-series.\ntime_series_smooth[0] = original_time_series[0] time_series_smooth[-1] = original_time_series[-1] time_series_smooth Plot the original and smoothed time-series.\nfig, ax = plt.subplots(1, 1) fig.set_size_inches(10, 5) original_time_series.plot.line( ax=ax, x='time', marker='^', color='#66c2a4', linestyle='--', linewidth=1, markersize=2) time_series_smooth.plot.line( ax=ax, x='time', marker='o', color='#238b45', linestyle='-', linewidth=1, markersize=4) plt.show() Download the Time-Series Convert the DataArray to a Pandas DataFrame and save it as a CSV file.\ndf = time_series_smooth.to_dataframe('ndvi').reset_index() df output_filename = 'smoothed_time_series.csv' df[['time', 'ndvi']].to_csv(output_filename, index=False) Exercise Replace the geometry with the location of your choice. Extract and download the smoothed time-series as a CSV file.\n05. Automating Downloads Another common use of the GEE Python API is to automate data processing and export. You can create a Python script that can be called from a server or launched on a schedule using tools such as Windows Scheduler or crontab.\nThis script below provides a complete example of automating a download using Google Earth Engine API. It uses the Google Earth Engine API to compute the average soil moisture for the given time period over all districts in a state. The result is then downloaded as a CSV file and saved locally.\nBefore running the script, please install the Earth Engine Python Client Library and commplete the authentication workflow on your machine using our step-by-step instructions.\nOnce you have finished the authentication, follow the steps below to create a script to download data from GEE.\nCreate a new file named download_data.py with the content shown below. import datetime import ee import csv import os cloud_project = 'spatialthoughts' try: ee.Initialize(project=cloud_project) except: ee.Authenticate() ee.Initialize(project=cloud_project) # Get current date now = datetime.datetime.now() # Define the period of past 1-week end_date = ee.Date(now) start_date = end_date.advance(-1, 'week') date_string = end_date.format('YYYY_MM_dd') filename = 'ssm_{}.csv'.format(date_string.getInfo()) # Saving to current directory. You can change the path to appropriate location output_path = os.path.join(filename) soilmoisture = ee.ImageCollection('NASA/SMAP/SPL4SMGP/007') admin2 = ee.FeatureCollection('FAO/GAUL_SIMPLIFIED_500m/2015/level2') # Filter to a state karnataka = admin2.filter(ee.Filter.eq('ADM1_NAME', 'Karnataka')) # Select the ssm band ssm = soilmoisture.select('sm_surface') filtered = ssm .filter(ee.Filter.date(start_date, end_date)) mean = filtered.mean() stats = mean.reduceRegions(**{ 'collection': karnataka, 'reducer': ee.Reducer.mean().setOutputs(['meanssm']), 'scale': 11000, 'crs': 'EPSG:32643' }) # Select columns to keep and remove geometry to make the result lightweight # Change column names to match your uploaded shapefile columns = ['ADM2_NAME', 'meanssm'] exportCollection = stats.select(**{ 'propertySelectors': columns, 'retainGeometry': False}) features = exportCollection.getInfo()['features'] data = [] for f in features: data.append(f['properties']) field_names = ['ADM2_NAME', 'meanssm'] with open(output_path, 'w') as csvfile: writer = csv.DictWriter(csvfile, fieldnames = field_names) writer.writeheader() writer.writerows(data) print('Success: File written at', output_path) From the terminal, navigate to the directory where you have created the file and type the command below to run the script. python download_data.py The script will download the data from GEE and save a file to your current directory. 06. Automating Exports If you want to automate Earth Engine jobs on a server, it is preferable to use a Service Account for authentication. A service account is a virtual account linked to a Google Cloud project. Once you create a service account and give necessary permissions, it can be used to authenticate your Earth Engine account instead of your own account. Each service account is identified by an email address in the form of @.iam.gserviceaccount.com. Along with them, the credentials are stored in a separate .json file. You need to keep this .json file safe on the system with appropriate permissions so external users do not have access to it.\nBefore running the script, please install the Earth Engine Python Client Library on the server using our step-by-step instructions.\nThe below code example shows how to authenticate an Earth Engine Export job using a service account. The code snippet assumes that the private key file is in the same directory as the scirpt and saved as a file named .private_key.json.\nimport ee # Replace the service account with your service account email service_account = 'export-data-gee@spatialthoughts.iam.gserviceaccount.com' # Replace the value with the path to your private key json file private_key_path = '.private_key.json' credentials = ee.ServiceAccountCredentials(service_account, private_key_path) ee.Initialize(credentials) lsib = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017') australia = lsib.filter(ee.Filter.eq('country_na', 'Australia')) geometry = australia.geometry() terraclimate = ee.ImageCollection('IDAHO_EPSCOR/TERRACLIMATE') tmax = terraclimate.select('tmmx') def scale(image): return image.multiply(0.1) \\ .copyProperties(image,['system:time_start']) tmaxScaled = tmax.map(scale) filtered = tmaxScaled \\ .filter(ee.Filter.date('2020-01-01', '2021-01-01')) \\ .filter(ee.Filter.bounds(geometry)) image_ids = filtered.aggregate_array('system:index').getInfo() for i, image_id in enumerate(image_ids): exportImage = ee.Image(filtered.filter( ee.Filter.eq('system:index', image_id)).first()) clippedImage = exportImage.clip(geometry) task = ee.batch.Export.image.toDrive(**{ 'image': clippedImage, 'description': 'Terraclimate Image Export {}'.format(i+1), 'fileNamePrefix': image_id, 'folder':'earthengine', 'scale': 4638.3, 'region': geometry, 'maxPixels': 1e10 }) task.start() print('Started Task: ', i+1) 07. Using the Google Earth Engine QGIS Plugin The QGIS Google Earth Engine plugin allows GEE Python API code to be run from QGIS and visualize the results directly in QGIS. This allows users to integrate QGIS’s rich cartographic features with the cloud data processing capabilities. After installing the plugin, you will be prompted to authenticate to GEE using your credentials. Once authenticated, you are able to run EE Python API code along with other PyQGIS code within QGIS.\nIf you get an authentication error, follow these instructions to install the Python API client and run earthengine authenticate\nWe will run a script that processes and visualizes a future climate scenario using the CMIP6 Climate Models.\nOpen the QGIS Python Console from Plugins → Python Console and click the Show Editor button. Paste the following code and click the Run button. Once the code runs, the resulting image computed by Earth Engine and will be streamed to QGIS as a new layer.\nimport ee from ee_plugin import Map # Use the CMIP6 Climate Projections Dataset cmip6 = ee.ImageCollection('NASA/GDDP-CMIP6') # Select a model and a scenario model = 'ACCESS-CM2' scenario = 'ssp245' # Select the band # Here we are using maximum air temperature band = 'tasmax' # Select the date range startDate = ee.Date.fromYMD(2030, 3, 1) endDate = startDate.advance(1, 'month') filtered = cmip6 \\ .filter(ee.Filter.date(startDate, endDate)) \\ .filter(ee.Filter.eq('model', model)) \\ .filter(ee.Filter.eq('scenario', scenario)) \\ .select(band) # Temperature values are in Kelvin # convert to Celcius def scaleValues(image): return image \\ .subtract(273.15) \\ .copyProperties(image, ['system:time_start', 'model', 'scenario']) scaled = filtered.map(scaleValues) # Calculate average daily maximum temperature mean = scaled.mean() tempVis = { 'min': 10, 'max': 40, 'palette': ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'], } Map.addLayer(mean, tempVis, 'Average Daily Maximum Air Temperature') You can now use this layer in your QGIS project or Print Layout. Here’s an example of visualizing the layer on a custom globe using the Globe Builder Plugin.\nSupplement We have a large collection of scripts that accompany this course. Visit the Supplement.\nGuided Projects Below are step-by-step video-based walkthrough of implementing real-world projects using Earth Engine. You can continue their learning journey by implementing these projects for their region of interest after the class.\nWatch the Video ↗\nGet the Code Click this link to open Google Earth Engine code editor and add the repository to your account. If successful, you will have a new repository named users/ujavalgandhi/End-to-End-Projects in the Scripts tab in the Reader section. Code Editor After Adding the Projects Repository\nIf you do not see the repository in the Reader section, click Refresh repository cache button in your Scripts tab and it will show up.\nRefresh repository cache\nProject 1: Calculating Rainfall Deviation Calculating Rainfall Deviation from the 30-year mean using CHIRPS Gridded Rainfall Data\nWatch the Video ↗\nProject 2: Flood Mapping Rapid mapping of a flood using Sentinel-1 SAR Data.\nWatch the Video ↗\nProject 4: LandCover Analysis Use existing land cover products to extract specific classes and compute statistics across many regions.\nWatch the Video ↗\nLearning Resources Cloud-Based Remote Sensing with Google Earth Engine: Fundamentals and Applications: A free and open-access book with 55-chapters covering fundamentals and applications of GEE. Also includes YouTube videos summarizing each chapter. Awesome Earth Engine: A curated list of Google Earth Engine resources. Google Earth Engine for Water Resources Management: Application-focused Introduction to Google Earth Engine. Creating Publication Quality Charts with GEE: A comprehesive guide on creating high-quality data visualizations with Google Earth Engine and Google Charts. Useful Public Repositories Please visit Awesome Earth Engine to see a curated list of Google Earth Engine resources.\nWe also have a few recommendations of a few selected packages, which have very useful functions to make you productive in Earth Engine.\nGeneral Purpose Packages\neepackages: A set of Google Earth Engine utilities by maintained by Gennadii Donchyts for both Javascript and Python API. geetools: Tools for cloud masking, batch processing, and more ee-palettes: Module for generating color palettes spectral: A javascript module that provides ready-to-use curated list of spectral indices for GEE. eemont: Python package that provides utility methods to create a more fluid code by being friendly with the Python method chaining. Application Specific Packages\nLEAF-Toolbox: Google Earth Engine application that produces various Vegetation Biophysical Products, including Leaf Area Index (LAI). RivWidthCloud: Package to automate extracting river centerline and width for both Javascript and Python API. Debugging Errors and Scaling Your Analysis As you start implementing more complex workflows and analyze large regions - you are bound to run into scaling issues and errors such as below:\nUser memory-limit exceeded Computation timed-out Computed value is too large These are usually the result of inefficient code and structure of your script. Below are my recommendations for improving your coding style and utilizing the full power of the Earth Engine infrastructure.\nIf/else statements and for-loops should be avoided completely and replaced with filter/map/reduce. The former are sequential and will be slow. Refer to the Function Programming Concepts guide on how to restructure your code to utilize the parallel computing infratructure provided by GEE. Remove any reprojection or resampling calls fro your script. Barring a few exceptions, you should not be reprojecting or resampling data. Earth Engine is designed to take care of it internally. For complex analysis involving large volumes of data, you should break down your workflow into logical steps and export intermediate results. For example, if you are implementing a complex supervised classification workflow - do it in multiple stages. A) Create your composite, add required bands, normalize them and export it as an Asset. B) Import the exported composite into another script and train a classifier. Export the classified image as an Asset. C) Import the exported classified image and do accuracy assessment and visualize the results. You will be able to run your analysis much faster, experiment easily and avoid scaling errors. Refer to the Export Intermediate Result guide to learn more. You may also break your export region into smaller regions (typically by admin units) and Export each region separately. For example, if you want to export results for an entire country at 30m resolution - rather than a running a large Export - you can export each Admin1 unit in your country separately. This helps with computation timed-out errors and improves overall processing time. You can start as many exports from your account as you want and they will be executed in a queue. But do not split your exports over multiple Earth Engine accounts. This is a violation of GEE Terms of Service and may result in your account getting blocked. The Earth Engine User Guide also has tips and examples of best practices. You can review the following articles to learn them.\nCoding Best Practices Debugging Guide The following videos are highly recommended and contain good advice on debugging and scaling workflows.\nWatch the Video ↗\nWatch the Video ↗\nData Credits Sentinel-2 Level-1C, Level-2A and Sentinel-1 SAR GRD: Contains Copernicus Sentinel data. TerraClimate: Monthly Climate and Climatic Water Balance for Global Terrestrial Surfaces, University of Idaho: Abatzoglou, J.T., S.Z. Dobrowski, S.A. Parks, K.C. Hegewisch, 2018, Terraclimate, a high-resolution global dataset of monthly climate and climatic water balance from 1958-2015, Scientific Data 5:170191, doi:10.1038/sdata.2017.191 VIIRS Stray Light Corrected Nighttime Day/Night Band Composites Version 1: C. D. Elvidge, K. E. Baugh, M. Zhizhin, and F.-C. Hsu, “Why VIIRS data are superior to DMSP for mapping nighttime lights,” Asia-Pacific Advanced Network 35, vol. 35, p. 62, 2013. FAO GAUL 500m: Global Administrative Unit Layers 2015, Second-Level Administrative Units: Source of Administrative boundaries: The Global Administrative Unit Layers (GAUL) dataset, implemented by FAO within the CountrySTAT and Agricultural Market Information System (AMIS) projects. CHIRPS Pentad: Climate Hazards Group InfraRed Precipitation with Station Data (version 2.0 final): Funk, Chris, Pete Peterson, Martin Landsfeld, Diego Pedreros, James Verdin, Shraddhanand Shukla, Gregory Husak, James Rowland, Laura Harrison, Andrew Hoell \u0026 Joel Michaelsen. “The climate hazards infrared precipitation with stations—a new environmental record for monitoring extremes”. Scientific Data 2, 150066. doi:10.1038/sdata.2015.66 2015. MOD13Q1.006 Terra Vegetation Indices 16-Day Global 250m: Didan, K. (2015). MOD13Q1 MODIS/Terra Vegetation Indices 16-Day L3 Global 250m SIN Grid V006 [Data set]. NASA EOSDIS Land Processes DAAC. Accessed 2021-05-06 from https://doi.org/10.5067/MODIS/MOD13Q1.006 GHS Urban Centre Database 2015 multitemporal and multidimensional attributes R2019A: Florczyk A., Corbane C,. Schiavina M., Pesaresi M., Maffenini L., Melchiorri, M., Politis P., Sabo F., Freire S., Ehrlich D., Kemper T., Tommasi P., Airaghi D., Zanchetta L. (2019) European Commission, Joint Research Centre (JRC) PID ESA WorldCover v100: Zanaga, D., Van De Kerchove, R., De Keersmaecker, W., Souverijns, N., Brockmann, C., Quast, R., Wevers, J., Grosu, A., Paccini, A., Vergnaud, S., Cartus, O., Santoro, M., Fritz, S., Georgieva, I., Lesiv, M., Carter, S., Herold, M., Li, Linlin, Tsendbazar, N.E., Ramoino, F., Arino, O., 2021. ESA WorldCover 10 m 2020 v100. doi:10.5281/zenodo.5571936 References Composites Phan, T.N.; Kuch, V.; Lehnert, L.W. Land Cover Classification using Google Earth Engine and Random Forest Classifier—The Role of Image Composition. Remote Sens. 2020, 12, 2411. https://doi.org/10.3390/rs12152411 D. Simonetti, U. Pimple, A. Langner, A. Marelli, Pan-tropical Sentinel-2 cloud-free annual composite datasets, Data in Brief, Volume 39, 2021, 107488, ISSN 2352-3409,https://doi.org/10.1016/j.dib.2021.107488. Supervised Classification Shetty, S.; Gupta, P.K.; Belgiu, M.; Srivastav, S.K. Assessing the Effect of Training Sampling Design on the Performance of Machine Learning Classifiers for Land Cover Mapping Using Multi-Temporal Remote Sensing Data and Google Earth Engine. Remote Sens. 2021, 13, 1433. https://doi.org/10.3390/rs13081433 Kelley, L.C.; Pitcher, L.; Bacon, C. Using Google Earth Engine to Map Complex Shade-Grown Coffee Landscapes in Northern Nicaragua. Remote Sens. 2018, 10, 952. https://doi.org/10.3390/rs10060952 Arsalan Ghorbanian, Mohammad Kakooei, Meisam Amani, Sahel Mahdavi, Ali Mohammadzadeh, Mahdi Hasanlou, Improved land cover map of Iran using Sentinel imagery within Google Earth Engine and a novel automatic workflow for land cover classification using migrated training samples, ISPRS Journal of Photogrammetry and Remote Sensing, Volume 167, 2020, https://doi.org/10.1016/j.isprsjprs.2020.07.013 Tassi, A.; Vizzari, M. Object-Oriented LULC Classification in Google Earth Engine Combining SNIC, GLCM, and Machine Learning Algorithms. Remote Sens. 2020, 12, 3776. https://doi.org/10.3390/rs12223776 Cristina Gómez, Joanne C. White, Michael A. Wulder, Optical remotely sensed time series data for land cover classification: A review, ISPRS Journal of Photogrammetry and Remote Sensing, Volume 116, 2016, Pages 55-72, ISSN 0924-2716, https://doi.org/10.1016/j.isprsjprs.2016.03.008 Sherrie Wang, George Azzari, David B. Lobell, Crop type mapping without field-level labels: Random forest transfer and unsupervised clustering techniques, Remote Sensing of Environment, Volume 222, 2019, Pages 303-317, ISSN 0034-4257, https://doi.org/10.1016/j.rse.2018.12.026 ","wordCount":"17672","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":[{"@type":"Person","name":"[[Ujaval Gandhi]]"}],"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/blog/end-to-end-google-earth-engine-full-course/"},"publisher":{"@type":"Organization","name":"ExampleSite","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Ujjwal (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Ujjwal</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/blog title=Blog><span>Blog</span></a></li><li><a href=http://localhost:1313/categories title=Projects><span>Projects</span></a></li><li><a href=http://localhost:1313/archive title=Archive><span>Archive</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/blog/>Blogs</a></div><h1 class="post-title entry-hint-parent">End-to-End Google Earth Engine (Full Course)
<span class=entry-hint title=Draft><svg height="35" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h1><div class=post-meta>83 min&nbsp;·&nbsp;17672 words&nbsp;·&nbsp;[[Ujaval Gandhi]]</div></header><div class=post-content><ul><li><a href=https://courses.spatialthoughts.com/#introduction>Introduction</a></li><li><a href=https://courses.spatialthoughts.com/#sign-up-for-google-earth-engine>Sign-up for Google Earth Engine</a></li><li><a href=https://courses.spatialthoughts.com/#complete-the-class-pre-work>Complete the Class Pre-Work</a></li><li><a href=https://courses.spatialthoughts.com/#get-the-course-videos>Get the Course Videos</a></li><li><a href=https://courses.spatialthoughts.com/#youtube>YouTube</a></li><li><a href=https://courses.spatialthoughts.com/#vimeo>Vimeo</a></li><li><a href=https://courses.spatialthoughts.com/#get-the-course-materials>Get the Course Materials</a></li><li><a href=https://courses.spatialthoughts.com/#module-1-earth-engine-basics>Module 1: Earth Engine Basics</a></li><li><a href=https://courses.spatialthoughts.com/#hello-world>01. Hello World</a></li><li><a href=https://courses.spatialthoughts.com/#exercise>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#saving-your-work>Saving Your Work</a></li><li><a href=https://courses.spatialthoughts.com/#working-with-image-collections>02. Working with Image Collections</a></li><li><a href=#exercise-1>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#filtering-image-collections>03. Filtering Image Collections</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-2>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#creating-mosaics-and-composites-from-imagecollections>04. Creating Mosaics and Composites from ImageCollections</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-3>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#working-with-feature-collections>05. Working with Feature Collections</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-4>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#importing-data>06. Importing Data</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-5>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#clipping-images>07. Clipping Images</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-6>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#exporting-data>08. Exporting Data</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-7>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#assignment-1>Assignment 1</a></li><li><a href=https://courses.spatialthoughts.com/#module-2-earth-engine-intermediate>Module 2: Earth Engine Intermediate</a></li><li><a href=https://courses.spatialthoughts.com/#earth-engine-objects>01. Earth Engine Objects</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-8>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#calculating-indices>02. Calculating Indices</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-9>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#computation-on-imagecollections>03. Computation on ImageCollections</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-10>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#cloud-masking>04. Cloud Masking</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-11>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#reducers>05. Reducers</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-12>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#time-series-charts>06. Time-Series Charts</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-13>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#assignment-2>Assignment 2</a></li><li><a href=https://courses.spatialthoughts.com/#module-3-supervised-classification>Module 3: Supervised Classification</a></li><li><a href=https://courses.spatialthoughts.com/#introduction-to-machine-learning-and-supervised-classification>Introduction to Machine Learning and Supervised Classification</a></li><li><a href=https://courses.spatialthoughts.com/#basic-supervised-classification>01. Basic Supervised Classification</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-14>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#accuracy-assessment>02. Accuracy Assessment</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-15>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#improving-the-classification>03. Improving the Classification</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-16>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#exporting-classification-results>04. Exporting Classification Results</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-17>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#calculating-area>05. Calculating Area</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-18>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#assignment-3>Assignment 3</a></li><li><a href=https://courses.spatialthoughts.com/#module-4-change-detection>Module 4: Change Detection</a></li><li><a href=https://courses.spatialthoughts.com/#introduction-to-change-detection>Introduction to Change Detection</a></li><li><a href=https://courses.spatialthoughts.com/#spectral-index-change>01. Spectral Index Change</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-19>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#spectral-distance-change>02. Spectral Distance Change</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-20>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#direct-classification-of-change>03. Direct Classification of Change</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-21>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#post-classification-comparison>04. Post-classification Comparison</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-22>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#module-5-earth-engine-apps>Module 5: Earth Engine Apps</a></li><li><a href=https://courses.spatialthoughts.com/#client-vs.-server>01. Client vs. Server</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-23>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#using-ui-elements>02. Using UI Elements</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-24>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#building-and-publishing-an-app>03. Building and Publishing an App</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-25>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#publishing-the-app>04. Publishing the App</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-26>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#create-a-split-panel-app>05. Create a Split Panel App</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-27>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#module-6-google-earth-engine-python-api>Module 6: Google Earth Engine Python API</a></li><li><a href=https://courses.spatialthoughts.com/#introduction-to-the-python-api>Introduction to the Python API</a></li><li><a href=https://courses.spatialthoughts.com/#google-colab>Google Colab</a></li><li><a href=https://courses.spatialthoughts.com/#local-development-environment>Local Development Environment</a></li><li><a href=https://courses.spatialthoughts.com/#python-api-syntax>01. Python API Syntax</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-28>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#automatic-conversion-of-javascript-code-to-python>02. Automatic Conversion of Javascript Code to Python</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-29>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#batch-exports>03. Batch Exports</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-30>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#using-earth-engine-with-xarray>04. Using Earth Engine with XArray</a></li><li><a href=https://courses.spatialthoughts.com/#exercise-31>Exercise</a></li><li><a href=https://courses.spatialthoughts.com/#automating-downloads>05. Automating Downloads</a></li><li><a href=https://courses.spatialthoughts.com/#automating-exports>06. Automating Exports</a></li><li><a href=https://courses.spatialthoughts.com/#using-the-google-earth-engine-qgis-plugin>07. Using the Google Earth Engine QGIS Plugin</a></li><li><a href=https://courses.spatialthoughts.com/#supplement>Supplement</a></li><li><a href=https://courses.spatialthoughts.com/#guided-projects>Guided Projects</a></li><li><a href=https://courses.spatialthoughts.com/#get-the-code>Get the Code</a></li><li><a href=https://courses.spatialthoughts.com/#project-1-calculating-rainfall-deviation>Project 1: Calculating Rainfall Deviation</a></li><li><a href=https://courses.spatialthoughts.com/#project-2-flood-mapping>Project 2: Flood Mapping</a></li><li><a href=https://courses.spatialthoughts.com/#project-3-extracting-time-series>Project 3: Extracting Time-Series</a></li><li><a href=https://courses.spatialthoughts.com/#project-4-landcover-analysis>Project 4: LandCover Analysis</a></li><li><a href=https://courses.spatialthoughts.com/#project-5-extracting-nighttime-lights-statistics>Project 5: Extracting Nighttime Lights Statistics</a></li><li><a href=https://courses.spatialthoughts.com/#learning-resources>Learning Resources</a></li><li><a href=https://courses.spatialthoughts.com/#useful-public-repositories>Useful Public Repositories</a></li><li><a href=https://courses.spatialthoughts.com/#debugging-errors-and-scaling-your-analysis>Debugging Errors and Scaling Your Analysis</a></li><li><a href=https://courses.spatialthoughts.com/#data-credits>Data Credits</a></li><li><a href=https://courses.spatialthoughts.com/#references>References</a></li><li><a href=https://courses.spatialthoughts.com/#composites>Composites</a></li><li><a href=https://courses.spatialthoughts.com/#supervised-classification>Supervised Classification</a></li><li><a href=https://courses.spatialthoughts.com/#license>License</a></li><li><a href=https://courses.spatialthoughts.com/#citing-and-referencing>Citing and Referencing</a></li></ul><hr><p><img loading=lazy src=https://courses.spatialthoughts.com/images/spatial_thoughts_logo.png></p><hr><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>Google Earth Engine is a cloud-based platform that enables large-scale processing of satellite imagery to detect changes, map trends, and quantify differences on the Earth’s surface. This course covers the full range of topics in Earth Engine to give the participants practical skills to master the platform and implement their remote sensing projects.</p><p><a href="https://www.youtube.com/watch?v=jGuCnu1I2qw&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=1"><img alt="Watch the video" loading=lazy src=https://img.youtube.com/vi/jGuCnu1I2qw/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=jGuCnu1I2qw&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=1">Watch the Video ↗</a></p><p><a href="https://docs.google.com/presentation/d/1q8HRDTqgQEp3Hmi8IG0T7djPLTC1wRig3jXrwFTmoVE/edit?usp=sharing">Access the Presentation ↗</a></p><h2 id=sign-up-for-google-earth-engine>Sign-up for Google Earth Engine<a hidden class=anchor aria-hidden=true href=#sign-up-for-google-earth-engine>#</a></h2><p>If you already have a Google Earth Engine account, you can skip this step.</p><p>Visit our <a href=https://courses.spatialthoughts.com/gee-sign-up.html>GEE Sign-Up Guide</a> for step-by-step instructions.</p><h2 id=complete-the-class-pre-work>Complete the Class Pre-Work<a hidden class=anchor aria-hidden=true href=#complete-the-class-pre-work>#</a></h2><p>This class needs about 2-hours of pre-work. Please watch the following videos to get a good understanding of remote sensing and how Earth Engine works.</p><ul><li><a href="https://www.youtube.com/watch?v=xAyNu9HbK8s">Introduction to Remote Sensing</a>: This video introduces the remote sensing concepts, terminology and techniques.</li><li><a href="https://www.youtube.com/watch?v=kpfncBHZBto">Introduction to Google Earth Engine</a>: This video gives a broad overview of Google Earth Engine with selected case studies and application. The video also covers the Earth Engine architecture and how it is different than traditional remote sensing software.</li></ul><h2 id=get-the-course-videos>Get the Course Videos<a hidden class=anchor aria-hidden=true href=#get-the-course-videos>#</a></h2><p>The course is accompanied by a set of videos covering the all the modules. These videos are recorded from our live instructor-led classes and are edited to make them easier to consume for self-study. We have 2 versions of the videos:</p><h2 id=youtube>YouTube<a hidden class=anchor aria-hidden=true href=#youtube>#</a></h2><p>We have created a YouTube Playlist with separate videos for each module to enable effective online-learning. <a href="https://www.youtube.com/playlist?list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha">Access the YouTube Playlist ↗</a></p><h2 id=vimeo>Vimeo<a hidden class=anchor aria-hidden=true href=#vimeo>#</a></h2><p>We are also making the module videos available on Vimeo. These videos can be downloaded for offline learning. <a href="https://vimeo.com/showcase/11467828?share=copy">Access the Vimeo Playlist ↗</a></p><h2 id=get-the-course-materials>Get the Course Materials<a hidden class=anchor aria-hidden=true href=#get-the-course-materials>#</a></h2><p>The course material and exercises are in the form of Earth Engine scripts shared via a code repository.</p><ol><li><a href="https://code.earthengine.google.co.in/?accept_repo=users/ujavalgandhi/End-to-End-GEE">Click this link</a> to open Google Earth Engine code editor and add the repository to your account.</li><li>If successful, you will have a new repository named <code>users/ujavalgandhi/End-to-End-GEE</code> in the <em>Scripts</em> tab in the <em>Reader</em> section.</li><li>Verify that your code editor looks like below</li></ol><p><img alt="Code Editor After Adding the Class Repository" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/repository.png></p><p>Code Editor After Adding the Class Repository</p><p>If you do not see the repository in the <em>Reader</em> section, click <em>Refresh repository cache</em> button in your <em>Scripts</em> tab and it will show up.</p><p><img alt="Refresh repository cache" loading=lazy src=https://courses.spatialthoughts.com/images/common/repository_cache.png></p><p>Refresh repository cache</p><p>There are several slide decks containing useful information and references. You can access all the presentations used in the course from the links below.</p><ul><li>Introduction and course overview [<a href="https://docs.google.com/presentation/d/1q8HRDTqgQEp3Hmi8IG0T7djPLTC1wRig3jXrwFTmoVE/edit?usp=sharing">Presentation ↗</a>]</li><li>Map/Reduce Programming Concepts [<a href="https://docs.google.com/presentation/d/10qOyxhubkwnsAVjniW54ETgwUHq3DXYKo3HGb6Gemi0/edit?usp=sharing">Presentation ↗</a>]</li><li>Introduction to Machine Learning & Supervised Classification [<a href="https://docs.google.com/presentation/d/19L1b5vsxb38xS8GlHNKOjvPZ0IGqDhv93681btMEL5w/edit?usp=sharing">Presentation ↗</a>]</li><li>Introduction to Change Detection [<a href="https://docs.google.com/presentation/d/1vdFTWJ61yDuVfbfhpnumQ8zuMPGwGcHpHsBTRgo_o5I/edit?usp=sharing">Presentation ↗</a>]</li><li>Introduction to Earth Engine Apps [<a href="https://docs.google.com/presentation/d/1u4Q91OqT9_OS4m1OWMm3uRUgu_oseqDUxHV-8mpzGz4/edit?usp=sharing">Presentation ↗</a>]</li><li>Introduction to Google Earth Engine Python API [<a href="https://docs.google.com/presentation/d/1hPVRnxp2Vp1VHXBtu36SH_UtEOjPz70KcDV-zGIin3U/edit?usp=sharing">Presentation ↗</a>]</li></ul><h2 id=module-1-earth-engine-basics>Module 1: Earth Engine Basics<a hidden class=anchor aria-hidden=true href=#module-1-earth-engine-basics>#</a></h2><p>Module 1 is designed to give you basic skills to be able to find datasets you need for your project, filter them to your region of interest, apply basic processing and export the results. Mastering this will allow you to start using Earth Engine for your project quickly and save a lot of time pre-processing the data.</p><p><a href="https://www.youtube.com/watch?v=daYhxVVIpJU&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=2"><img alt="Watch the Video" loading=lazy src=https://img.youtube.com/vi/daYhxVVIpJU/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=daYhxVVIpJU&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=2">Watch the Video ↗</a></p><h2 id=01-hello-world>01. Hello World<a hidden class=anchor aria-hidden=true href=#01-hello-world>#</a></h2><p>This script introduces the basic Javascript syntax and the video covers the programming concepts you need to learn when using Earth Engine. To learn more, visit <a href=https://developers.google.com/earth-engine/tutorials/tutorial_js_01>Introduction to JavaScript for Earth Engine</a> section of the Earth Engine User Guide.</p><p>The <em>Code Editor</em> is an Integrated Development Environment (IDE) for Earth Engine Javascript API.. It offers an easy way to type, debug, run and manage code. Type the code below and click <em>Run</em> to execute it and see the output in the <em>Console</em> tab.</p><blockquote><p>Tip: You can use the keyboard shortcut <em>Ctrl+Enter</em> to run the code in the Code Editor</p></blockquote><p><img alt="Hello World" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/hello_world.png></p><p>Hello World</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F01b_Hello_World_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>print(&#39;Hello World&#39;);

// Variables
var city = &#39;Bengaluru&#39;;
var country = &#39;India&#39;;
print(city, country);

var population = 8400000;
print(population);
 
// List
var majorCities = [&#39;Mumbai&#39;, &#39;Delhi&#39;, &#39;Chennai&#39;, &#39;Kolkata&#39;];
print(majorCities);

// Dictionary
var cityData = {
  &#39;city&#39;: city,
  &#39;population&#39;: 8400000,
  &#39;elevation&#39;: 930
};
print(cityData);

// Function
var greet = function(name) {
    return &#39;Hello &#39; + name;
};
print(greet(&#39;World&#39;));

// This is a comment
</code></pre><h3 id=exercise>Exercise<a hidden class=anchor aria-hidden=true href=#exercise>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F01c_Hello_World_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// These are the 5 largest cities in the world: 
// Tokyo, Delhi, Shanghai, Mexico City, Sao Paulo

// Create a list named &#39;largeCities&#39;
// The list should have names of all the above cities
// Print the list 
</code></pre><h3 id=saving-your-work>Saving Your Work<a hidden class=anchor aria-hidden=true href=#saving-your-work>#</a></h3><p>When you modify any script for the course repository, you may want to save a copy for yourself. If you try to click the <em>Save</em> button, you will get an error message like below</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/setup1.png></p><p>This is because the shared class repository is a <em>Read-only</em> repository. You can click <em>Yes</em> to save a copy in your repository. If this is the first time you are using Earth Engine, you will be prompted to choose a <em>Earth Engine username</em>. Choose the name carefully, as it cannot be changed once created.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/setup2.png></p><p>After entering your username, your home folder will be created. After that, you will be prompted to enter a new repository. A repository can help you organize and share code. Your account can have multiple repositories and each repository can have multiple scripts inside it. To get started, you can create a repository named <em>default</em>. Finally, you will be able to save the script.</p><h2 id=02-working-with-image-collections>02. Working with Image Collections<a hidden class=anchor aria-hidden=true href=#02-working-with-image-collections>#</a></h2><p>Most datasets in Earth Engine come as a <code>ImageCollection</code>. An ImageCollection is a dataset that consists of images takes at different time and locations - usually from the same satellite or data provider. You can load a collection by searching the <a href=https://developers.google.com/earth-engine/datasets>Earth Engine Data Catalog</a> for the <em>ImageCollection ID</em>. Search for the <em>Sentinel-2 Level 1C</em> dataset and you will find its id <code>COPERNICUS/S2_SR</code>. Visit the <a href=https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2>Sentinel-2, Level 1C page</a> and see <em>Explore in Earth Engine</em> section to find the code snippet to load and visualize the collection. This snippet is a great starting point for your work with this dataset. Click the <strong>Copy Code Sample</strong> button and paste the code into the code editor. Click <em>Run</em> and you will see the image tiles load in the map.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/image_collection1.png></p><p>In the code snippet, You will see a function <code>Map.setCenter()</code> which sets the viewport to a specific location and zoom level. The function takes the X coordinate (longitude), Y coordinate (latitude) and Zoom Level parameters. Replace the X and Y coordinates with the coordinates of your city and click <em>Run</em> to see the images of your city.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/image_collection2.png></p><h3 id=exercise-1>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-1>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F02c_Image_Collections_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Find the &#39;Sentinel-2 Level-1C&#39; dataset page
// https://developers.google.com/earth-engine/datasets

// Copy/paste the code snippet

// Change the code to display images for your home city
</code></pre><h2 id=03-filtering-image-collections>03. Filtering Image Collections<a hidden class=anchor aria-hidden=true href=#03-filtering-image-collections>#</a></h2><p>The collection contains all imagery ever collected by the sensor. The entire collections are not very useful. Most applications require a subset of the images. We use <strong>filters</strong> to select the appropriate images. There are many types of filter functions, look at <code>ee.Filter...</code> module to see all available filters. Select a filter and then run the <code>filter()</code> function with the filter parameters.</p><p>We will learn about 3 main types of filtering techniques</p><ul><li><strong>Filter by metadata</strong>: You can apply a filter on the image metadata using filters such as <code>ee.Filter.eq()</code>, <code>ee.Filter.lt()</code> etc. You can filter by PATH/ROW values, Orbit number, Cloud cover etc.</li><li><strong>Filter by date</strong>: You can select images in a particular date range using filters such as <code>ee.Filter.date()</code>.</li><li><strong>Filter by location</strong>: You can select the subset of images with a bounding box, location or geometry using the <code>ee.Filter.bounds()</code>. You can also use the drawing tools to draw a geometry for filtering.</li></ul><p>After applying the filters, you can use the <code>size()</code> function to check how many images match the filters.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/filters.png></p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F03b_Filtering_Image_Collection_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241])
Map.centerObject(geometry, 10)

var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;);

// Filter by metadata
var filtered = s2.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30));

// Filter by date
var filtered = s2.filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;));

// Filter by location
var filtered = s2.filter(ee.Filter.bounds(geometry));

// Let&#39;s apply all the 3 filters together on the collection

// First apply metadata fileter
var filtered1 = s2.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30));
// Apply date filter on the results
var filtered2 = filtered1.filter(
  ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;));
// Lastly apply the location filter
var filtered3 = filtered2.filter(ee.Filter.bounds(geometry));

// Instead of applying filters one after the other, we can &#39;chain&#39; them
// Use the . notation to apply all the filters together
var filtered = s2.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry));
  
print(filtered.size());
</code></pre><h3 id=exercise-2>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-2>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F03c_Filtering_Image_Collection_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>var geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241]);

var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;);

var filtered = s2
  .filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry));

print(filtered.size());

// Exercise
// Delete the &#39;geometry&#39; variable
// Add a point at your chosen location
// Change the filter to find images from January 2023

// Note: If you are in a very cloudy region, 
// make sure to adjust the CLOUDY_PIXEL_PERCENTAGE
</code></pre><h2 id=04-creating-mosaics-and-composites-from-imagecollections>04. Creating Mosaics and Composites from ImageCollections<a hidden class=anchor aria-hidden=true href=#04-creating-mosaics-and-composites-from-imagecollections>#</a></h2><p>The default order of the collection is by date. So when you display the collection, it implicitly creates a mosaic with the latest pixels on top. You can call <code>.mosaic()</code> on a ImageCollection to create a mosaic image from the pixels at the top.</p><p>We can also create a composite image by applying selection criteria to each pixel from all pixels in the stack. Here we use the <code>median()</code> function to create a composite where each pixel value is the median of all pixels from the stack.</p><blockquote><p>Tip: If you need to create a mosaic where the images are in a specific order, you can use the <code>.sort()</code> function to sort your collection by a property first.</p></blockquote><p><img alt="Mosaic vs. Composite" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/mosaic_composite.png></p><p>Mosaic vs. Composite</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F04b_Mosaics_and_Composites_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241]);
var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;);

var filtered = s2.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry));
 
var mosaic = filtered.mosaic();
 
var medianComposite = filtered.median();

Map.centerObject(geometry, 10);

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
};

Map.addLayer(filtered, rgbVis, &#39;Filtered Collection&#39;);
Map.addLayer(mosaic, rgbVis, &#39;Mosaic&#39;);
Map.addLayer(medianComposite, rgbVis, &#39;Median Composite&#39;);
</code></pre><h3 id=exercise-3>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-3>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F04c_Mosaics_and_Composites_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Create a median composite for the year 2020 and load it to the map

// Compare both the composites to see the changes in your city
</code></pre><h2 id=05-working-with-feature-collections>05. Working with Feature Collections<a hidden class=anchor aria-hidden=true href=#05-working-with-feature-collections>#</a></h2><p>Feature Collections are similar to Image Collections - but they contain <em>Features</em>, not images. They are equivalent to Vector Layers in a GIS. We can load, filter and display Feature Collections using similar techniques that we have learned so far.</p><p>Search for <em>GAUL Second Level Administrative Boundaries</em> and load the collection. This is a global collection that contains all Admin2 boundaries. We can apply a filter using the <code>ADM1_NAME</code> property to get all Admin2 boundaries (i.e. Districts) from a state.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/feature_collection.png></p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F05b_Feature_Collections_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var admin2 = ee.FeatureCollection(&#39;FAO/GAUL_SIMPLIFIED_500m/2015/level2&#39;);

var karnataka = admin2.filter(ee.Filter.eq(&#39;ADM1_NAME&#39;, &#39;Karnataka&#39;));

var visParams = {&#39;color&#39;: &#39;red&#39;};
Map.addLayer(karnataka, visParams, &#39;Karnataka Districts&#39;);
</code></pre><h3 id=exercise-4>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-4>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F05c_Feature_Collections_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>var admin2 = ee.FeatureCollection(&#39;FAO/GAUL_SIMPLIFIED_500m/2015/level2&#39;);
Map.addLayer(admin2, {color: &#39;grey&#39;}, &#39;All Admin2 Polygons&#39;);

// Exercise 
// Apply filters to select your chosen Admin2 region
// Display the results in &#39;red&#39; color

// Hint1: Switch to the &#39;Inspector&#39; tab and click on any
// polygon to know its properties and their values

// Hint2: Many countries do not have unique names for
// Admin2 regions. Make sure to apply a filter to select
// the Admin1 region that contains your chosen Admin2 region
</code></pre><h2 id=06-importing-data>06. Importing Data<a hidden class=anchor aria-hidden=true href=#06-importing-data>#</a></h2><p>You can import vector or raster data into Earth Engine. We will now import a shapefile of <a href=https://bit.ly/ghs-ucdb-shapefile>Urban Centres</a> from JRC’s GHS Urban Centre Database (GHS-UCDB). Unzip the <code>ghs_urban_centers.zip</code> into a folder on your computer. In the Code Editor, go to <em>Assets → New → Table Upload → Shape Files</em>. Select the <code>.shp</code>, <code>.shx</code>, <code>.dbf</code> and .<code>prj</code> files. Enter <code>ghs_urban_centers</code> as the <em>Asset Name</em> and click <em>Upload</em>. Once the upload and ingest finishes, you will have a new asset in the <em>Assets</em> tab. The shapefile is imported as a Feature Collection in Earth Engine. Select the <code>ghs_urban_centers</code> asset and click <em>Import</em>. You can then visualize the imported data.</p><p><img alt="Importing a Shapefile" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/import.png></p><p>Importing a Shapefile</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F06b_Import_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>// Let&#39;s import some data to Earth Engine

// Upload the &#39;GHS Urban Centers&#39; database from JRC
// https://ghsl.jrc.ec.europa.eu/ghs_stat_ucdb2015mt_r2019a.php

// Download the shapefile from https://bit.ly/ghs-ucdb-shapefile
// Unzip and upload

// Import the collection
var urban = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/ghs_urban_centers&#39;);

// Visualize the collection
Map.addLayer(urban, {color: &#39;blue&#39;}, &#39;Urban Areas&#39;);
</code></pre><h3 id=exercise-5>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-5>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F06c_Import_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>var urban = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/ghs_urban_centers&#39;);
print(urban.first());

// Exercise
// Apply a filter to select only large urban centers
// in your country and display it on the map.

// Select all urban centers in your country with
// a population greater than 1000000

// Hint1: Use the property &#39;CTR_MN_NM&#39; containing country names
// Hint2: Use the property &#39;P15&#39; containing 2015 Population
</code></pre><h2 id=07-clipping-images>07. Clipping Images<a hidden class=anchor aria-hidden=true href=#07-clipping-images>#</a></h2><p>It is often desirable to clip the images to your area of interest. You can use the <code>clip()</code> function to mask out an image using a geometry.</p><blockquote><p>While in a Desktop software, clipping is desirable to remove unnecessary portion of a large image and save computation time, in Earth Engine clipping can actually increase the computation time. As described in the <a href="https://developers.google.com/earth-engine/guides/best_practices?hl=en#if-you-dont-need-to-clip,-dont-use-clip">Earth Engine Coding Best Practices</a> guide, avoid clipping the images or do it at the end of your script.</p></blockquote><p><img alt="Original vs. Clipped Image" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/clipping.png></p><p>Original vs. Clipped Image</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F07b_Clipping_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;);
var urban = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/ghs_urban_centers&#39;);
// Find the name of the urban centre
// by adding the layer to the map and using Inspector.
var filtered = urban
  .filter(ee.Filter.eq(&#39;UC_NM_MN&#39;, &#39;Bengaluru&#39;))
  .filter(ee.Filter.eq(&#39;CTR_MN_NM&#39;, &#39;India&#39;));

var geometry = filtered.geometry();

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;], 
};
var filtered = s2.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry));

var image = filtered.median(); 

var clipped = image.clip(geometry);

Map.centerObject(geometry);
Map.addLayer(clipped, rgbVis, &#39;Clipped&#39;);
</code></pre><h3 id=exercise-6>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-6>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F07c_Clipping_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Add the imported table to the Map
// Use the Inspector to find the id of your home city or any urban area of your choice
// Change the filter to use the id of the selected feature
</code></pre><h2 id=08-exporting-data>08. Exporting Data<a hidden class=anchor aria-hidden=true href=#08-exporting-data>#</a></h2><p>Earth Engine allows for exporting both vector and raster data to be used in an external program. Vector data can be exported as a <code>CSV</code> or a <code>Shapefile</code>, while Rasters can be exported as <code>GeoTIFF</code> files. We will now export the Sentinel-2 Composite as a GeoTIFF file.</p><blockquote><p>Tip: Code Editor supports autocompletion of API functions using the combination <em>Ctrl+Space</em>. Type a few characters of a function and press <em>Ctrl+Space</em> to see autocomplete suggestions. You can also use the same key combination to fill all parameters of the function automatically.</p></blockquote><p>Once you run this script, the <em>Tasks</em> tab will be highlighted. Switch to the tab and you will see the tasks waiting. Click <em>Run</em> next to each task to start the process.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/export_task01.png></p><p>On clicking the <em>Run</em> button, you will be prompted for a confirmation dialog. Verify the settings and click <em>Run</em> to start the export.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/export_task02.png></p><p>Once the Export finishes, a GeoTiff file for each export task will be added to your Google Drive in the specified folder. You can download them and use it in a GIS software.</p><p><img alt="Visualized vs. Raw Composite" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/exporting_data.png></p><p>Visualized vs. Raw Composite</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F08b_Export_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;);
var urban = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/ghs_urban_centers&#39;);

var filtered = urban
  .filter(ee.Filter.eq(&#39;UC_NM_MN&#39;, &#39;Bengaluru&#39;))
  .filter(ee.Filter.eq(&#39;CTR_MN_NM&#39;, &#39;India&#39;));
var geometry = filtered.geometry();

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;], 
};
var filtered = s2.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry));

var image = filtered.median(); 

var clipped = image.clip(geometry);

Map.centerObject(geometry);
Map.addLayer(clipped, rgbVis, &#39;Clipped&#39;);

var exportImage = clipped.select(&#39;B.*&#39;);

// Export raw image with original pixel values
Export.image.toDrive({
    image: exportImage,
    description: &#39;Bangalore_Composite_Raw&#39;,
    folder: &#39;earthengine&#39;,
    fileNamePrefix: &#39;bangalore_composite_raw&#39;,
    region: geometry,
    scale: 10,
    maxPixels: 1e9
});

// Export visualized image as colorized RGB image

// Rather than exporting raw bands, we can apply a rendered image
// visualize() function allows you to apply the same parameters 
// that are used in earth engine which exports a 3-band RGB image

// Note: Visualized images are not suitable for analysis
var visualized = clipped.visualize(rgbVis);

Export.image.toDrive({
    image: visualized,
    description: &#39;Bangalore_Composite_Visualized&#39;,
    folder: &#39;earthengine&#39;,
    fileNamePrefix: &#39;bangalore_composite_visualized&#39;,
    region: geometry,
    scale: 10,
    maxPixels: 1e9
});
</code></pre><h3 id=exercise-7>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-7>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A01-Earth-Engine-Basics%2F08c_Export_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Write the export function to export the results for your chosen urban area
</code></pre><h2 id=assignment-1>Assignment 1<a hidden class=anchor aria-hidden=true href=#assignment-1>#</a></h2><p>Load the Night Lights Data for May 2015 and May 2020. Compare the imagery for your region and find the changes in the city due to COVID-19 effect.</p><p><img alt="Assignment1 Expected Output" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/assignment1.png></p><p>Assignment1 Expected Output</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3AAssignments%2FAssignment1">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Assignment
// Export the Night Lights images for May,2015 and May,2020

// Workflow:
// Load the VIIRS Nighttime Day/Night Band Composites collection
// Filter the collection to the date range
// Extract the &#39;avg_rad&#39; band which represents the nighttime lights
// Clip the image to the geometry of your city
// Export the resulting image as a GeoTIFF file.

// Hint1: 

// There are 2 VIIRS Nighttime Day/Night collections
// Use the one that corrects for stray light

// Hint2: 

// The collection contains 1 global image per month
// After filtering for the month, there will be only 1 image in the collection

// You can use the following technique to extract that image
// var image = ee.Image(filtered.first())
</code></pre><h2 id=module-3-supervised-classification>Module 3: Supervised Classification<a hidden class=anchor aria-hidden=true href=#module-3-supervised-classification>#</a></h2><h2 id=introduction-to-machine-learning-and-supervised-classification>Introduction to Machine Learning and Supervised Classification<a hidden class=anchor aria-hidden=true href=#introduction-to-machine-learning-and-supervised-classification>#</a></h2><p>Supervised classification is arguably the most important classical machine learning techniques in remote sensing. Applications range from generating Land Use/Land Cover maps to change detection. Google Earth Engine is unique suited to do supervised classification at scale. The interactive nature of Earth Engine development allows for iterative development of supervised classification workflows by combining many different datasets into the model. This module covers basic supervised classification workflow, accuracy assessment, hyperparameter tuning and change detection.</p><p><a href="https://www.youtube.com/watch?v=lULwcRpkMv8&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=4"><img alt="Watch the Video" loading=lazy src=https://img.youtube.com/vi/lULwcRpkMv8/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=lULwcRpkMv8&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=4">Watch the Video ↗</a></p><h2 id=01-basic-supervised-classification>01. Basic Supervised Classification<a hidden class=anchor aria-hidden=true href=#01-basic-supervised-classification>#</a></h2><p>We will learn how to do a basic land cover classification using training samples collected from the Code Editor using the High Resolution basemap imagery provided by Google Maps. This method requires no prior training data and is quite effective to generate high quality classification samples anywhere in the world. The goal is to classify each source pixel into one of the following classes - urban, bare, water or vegetation. Using the drawing tools in the code editor, you create 4 new feature collection with points representing pixels of that class. Each feature collection has a property called <code>landcover</code> with values of 0, 1, 2 or 3 indicating whether the feature collection represents urban, bare, water or vegetation respectively. We then train a <em>Random Forest</em> classifier using these training set to build a model and apply it to all the pixels of the image to create a 4 class image.</p><blockquote><p>Fun fact: The classifiers in Earth Engine API have names starting with <strong>smile</strong> - such as <code>ee.Classifier.smileRandomForest()</code>. The <em>smile</em> part refers to the <a href=https://haifengl.github.io/index.html>Statistical Machine Intelligence and Learning Engine (SMILE)</a> JAVA library which is used by Google Earth Engine to implement these algorithms.</p></blockquote><p><img alt="Supervised Classification Output" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/classified.png></p><p>Supervised Classification Output</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A03-Supervised-Classification%2F01d_Basic_Supervised_Classification_(noimport)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var bangalore = ee.FeatureCollection(&#39;users/ujavalgandhi/public/bangalore_boundary&#39;);
var geometry = bangalore.geometry();

var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_SR_HARMONIZED&#39;);
// The following collections were created using the 
// Drawing Tools in the code editor 
var urban = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/urban_gcps&#39;);
var bare = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/bare_gcps&#39;);
var water = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/water_gcps&#39;);
var vegetation = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/vegetation_gcps&#39;);

var filtered = s2
.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry))
  .select(&#39;B.*&#39;);

var composite = filtered.median();

// Display the input composite.
var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
};
Map.addLayer(composite.clip(geometry), rgbVis, &#39;image&#39;);

var gcps = urban.merge(bare).merge(water).merge(vegetation);

// Overlay the point on the image to get training data.
var training = composite.sampleRegions({
  collection: gcps, 
  properties: [&#39;landcover&#39;], 
  scale: 10
});

// Train a classifier.
var classifier = ee.Classifier.smileRandomForest(50).train({
  features: training,  
  classProperty: &#39;landcover&#39;, 
  inputProperties: composite.bandNames()
});
// // Classify the image.
var classified = composite.classify(classifier);
// Choose a 4-color palette
// Assign a color for each class in the following order
// Urban, Bare, Water, Vegetation
var palette = [&#39;#cc6d8f&#39;, &#39;#ffc107&#39;, &#39;#1e88e5&#39;, &#39;#004d40&#39; ];

Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, &#39;2019&#39;);
// Display the GCPs
// We use the style() function to style the GCPs
var palette = ee.List(palette);
var landcover = ee.List([0, 1, 2, 3]);

var gcpsStyled = ee.FeatureCollection(
  landcover.map(function(lc){
    var color = palette.get(landcover.indexOf(lc));
    var markerStyle = { color: &#39;white&#39;, pointShape: &#39;diamond&#39;, 
      pointSize: 4, width: 1, fillColor: color};
    return gcps.filter(ee.Filter.eq(&#39;landcover&#39;, lc))
                .map(function(point){
                  return point.set(&#39;style&#39;, markerStyle)
                })
      })).flatten();
      
Map.addLayer(gcpsStyled.style({styleProperty:&#34;style&#34;}), {}, &#39;GCPs&#39;)
Map.centerObject(gcpsStyled)
</code></pre><h3 id=exercise-8>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-8>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A03-Supervised-Classification%2F01c_Basic_Supervised_Classification_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_SR_HARMONIZED&#39;);

// Perform supervised classification for your city

// Delete the geometry below and draw a polygon
// over your chosen city
var geometry = ee.Geometry.Polygon([[
  [77.4149, 13.1203],
  [77.4149, 12.7308],
  [77.8090, 12.7308],
  [77.8090, 13.1203]
]]);
          
Map.centerObject(geometry);

var filtered = s2
.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry))
  .select(&#39;B.*&#39;);

var composite = filtered.median();

// Display the input composite.

var rgbVis = {min: 0.0, max: 3000, bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;]};
Map.addLayer(composite.clip(geometry), rgbVis, &#39;image&#39;);

// Exercise
// Add training points for 4 classes
// Assign the &#39;landcover&#39; property as follows

// urban: 0
// bare: 1
// water: 2
// vegetation: 3

// After adding points, uncomments lines below

// var gcps = urban.merge(bare).merge(water).merge(vegetation);

// // Overlay the point on the image to get training data.
// var training = composite.sampleRegions({
//   collection: gcps, 
//   properties: [&#39;landcover&#39;], 
//   scale: 10,
//   tileScale: 16
// });
// print(training);

// // Train a classifier.
// var classifier = ee.Classifier.smileRandomForest(50).train({
//   features: training,  
//   classProperty: &#39;landcover&#39;, 
//   inputProperties: composite.bandNames()
// });
// // // Classify the image.
// var classified = composite.classify(classifier);

// // Choose a 4-color palette
// // Assign a color for each class in the following order
// // Urban, Bare, Water, Vegetation
// var palette = [&#39;#cc6d8f&#39;, &#39;#ffc107&#39;, &#39;#1e88e5&#39;, &#39;#004d40&#39; ];

// Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, &#39;2019&#39;);
</code></pre><h2 id=02-accuracy-assessment>02. Accuracy Assessment<a hidden class=anchor aria-hidden=true href=#02-accuracy-assessment>#</a></h2><p>It is important to get a quantitative estimate of the accuracy of the classification. To do this, a common strategy is to divide your training samples into 2 random fractions - one used for <em>training</em> the model and the other for <em>validation</em> of the predictions. Once a classifier is trained, it can be used to classify the entire image. We can then compare the classified values with the ones in the validation fraction. We can use the <code>ee.Classifier.confusionMatrix()</code> method to calculate a <em>Confusion Matrix</em> representing expected accuracy.</p><p>Classification results are evaluated based on the following metrics</p><ul><li><strong>Overall Accuracy</strong>: How many samples were classified correctly.</li><li><strong>Producer’s Accuracy</strong>: How well did the classification predict each class.</li><li><strong>Consumer’s Accuracy (Reliability)</strong>: How reliable is the prediction in each class.</li><li><strong>Kappa Coefficient</strong>: How well the classification performed as compared to random assignment.</li></ul><p><img alt="Accuracy Assessment" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/accuracy_assessment.png></p><p>Accuracy Assessment</p><blockquote><p>Don’t get carried away tweaking your model to give you the highest validation accuracy. You must use both qualitative measures (such as visual inspection of results) along with quantitative measures to assess the results.</p></blockquote><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A03-Supervised-Classification%2F02b_Accuracy_Assessment_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_SR_HARMONIZED&#39;);
var basin = ee.FeatureCollection(&#34;WWF/HydroSHEDS/v1/Basins/hybas_7&#34;);
var gcp = ee.FeatureCollection(&#34;users/ujavalgandhi/e2e/arkavathy_gcps&#34;);
    
var arkavathy = basin.filter(ee.Filter.eq(&#39;HYBAS_ID&#39;, 4071139640));
var geometry = arkavathy.geometry();
Map.centerObject(geometry);

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
};
 
var filtered = s2
.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry))
  .select(&#39;B.*&#39;);

var composite = filtered.median();

// Display the input composite.
Map.addLayer(composite.clip(geometry), rgbVis, &#39;image&#39;);

// Add a random column and split the GCPs into training and validation set
var gcp = gcp.randomColumn();

// This being a simpler classification, we take 60% points
// for validation. Normal recommended ratio is
// 70% training, 30% validation
var trainingGcp = gcp.filter(ee.Filter.lt(&#39;random&#39;, 0.6));
var validationGcp = gcp.filter(ee.Filter.gte(&#39;random&#39;, 0.6));

// Overlay the point on the image to get training data.
var training = composite.sampleRegions({
  collection: trainingGcp,
  properties: [&#39;landcover&#39;],
  scale: 10,
  tileScale: 16
});

// Train a classifier.
var classifier = ee.Classifier.smileRandomForest(50)
.train({
  features: training,  
  classProperty: &#39;landcover&#39;,
  inputProperties: composite.bandNames()
});

// Classify the image.
var classified = composite.classify(classifier);

var palette = [&#39;#cc6d8f&#39;, &#39;#ffc107&#39;, &#39;#1e88e5&#39;, &#39;#004d40&#39; ];
Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, &#39;2019&#39;);
//************************************************************************** 
// Accuracy Assessment
//************************************************************************** 

// Use classification map to assess accuracy using the validation fraction
// of the overall training set created above.
var test = classified.sampleRegions({
  collection: validationGcp,
  properties: [&#39;landcover&#39;],
  tileScale: 16,
  scale: 10,
});

var testConfusionMatrix = test.errorMatrix(&#39;landcover&#39;, &#39;classification&#39;)
// Printing of confusion matrix may time out. Alternatively, you can export it as CSV
print(&#39;Confusion Matrix&#39;, testConfusionMatrix);
print(&#39;Test Accuracy&#39;, testConfusionMatrix.accuracy());

// Alternate workflow 
// This is similar to machine learning practice
var validation = composite.sampleRegions({
  collection: validationGcp,
  properties: [&#39;landcover&#39;],
  scale: 10,
  tileScale: 16
});

var test = validation.classify(classifier);

var testConfusionMatrix = test.errorMatrix(&#39;landcover&#39;, &#39;classification&#39;)
// Printing of confusion matrix may time out. Alternatively, you can export it as CSV
print(&#39;Confusion Matrix&#39;, testConfusionMatrix);
print(&#39;Test Accuracy&#39;, testConfusionMatrix.accuracy());
</code></pre><h3 id=exercise-9>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-9>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A03-Supervised-Classification%2F02c_Accuracy_Assessment_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>var composite = ee.Image(&#39;users/ujavalgandhi/e2e/arkavathy_2019_composite&#39;);
var gcp = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/arkavathy_gcps&#39;);
var gcp = gcp.randomColumn();

var trainingGcp = gcp.filter(ee.Filter.lt(&#39;random&#39;, 0.6));
var validationGcp = gcp.filter(ee.Filter.gte(&#39;random&#39;, 0.6));

var training = composite.sampleRegions({
  collection: trainingGcp,
  properties: [&#39;landcover&#39;],
  scale: 10,
  tileScale: 16
});

// Train a classifier.
var classifier = ee.Classifier.smileRandomForest(50)
.train({
  features: training,  
  classProperty: &#39;landcover&#39;,
  inputProperties: composite.bandNames()
});

// Classify the image.
var classified = composite.classify(classifier);

//************************************************************************** 
// Accuracy Assessment
//************************************************************************** 

// Use classification map to assess accuracy using the validation fraction
// of the overall training set created above.
var test = classified.sampleRegions({
  collection: validationGcp,
  properties: [&#39;landcover&#39;],
  tileScale: 16,
  scale: 10,
});

var testConfusionMatrix = test.errorMatrix(&#39;landcover&#39;, &#39;classification&#39;);
print(&#39;Confusion Matrix&#39;, testConfusionMatrix);
print(&#39;Test Accuracy&#39;, testConfusionMatrix.accuracy());

// Exercise

// Calculate and print the following assessment metrics
// 1. Producer&#39;s accuracy
// 2. Consumer&#39;s accuracy
// 3. F1-score

// Hint: Look at the ee.ConfusionMatrix module for appropriate methods
</code></pre><h2 id=03-improving-the-classification>03. Improving the Classification<a hidden class=anchor aria-hidden=true href=#03-improving-the-classification>#</a></h2><p>The Earth Engine data-model is especially well suited for machine learning tasks because of its ability to easily incorporate data sources of different spatial resolutions, projections and data types together By giving additional information to the classifier, it is able to separate different classes easily. Here we take the same example and augment it with the following techniques</p><ul><li><em>Apply Cloud Masking</em></li><li><em>Add Spectral Indices</em>: We add bands for different spectral indices such as - NDVI, NDBI, MNDWI and BSI.</li><li><em>Add Elevation and Slope</em>: We also add slope and elevation bands from the ALOS DEM.</li><li><em>Normalize the Inputs</em>: Machine learning models work best when all the inputs have the same scale. We will divide each band with the maximum value. This method ensures that all input values are between 0-1. A more <a href=https://courses.spatialthoughts.com/#image-normalization-and-standardization>complete and robust technique</a> for image normalization is provided in the course Supplement.</li></ul><p>Our training features have more parameters and contain values of the same scale. The result is a much improved classification.</p><p><img alt="Improved Classification Accuracy with use of Spectral Indices and Elevation Data" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/improving_classification.png></p><p>Improved Classification Accuracy with use of Spectral Indices and Elevation Data</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A03-Supervised-Classification%2F03b_Improving_the_Classification_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_SR_HARMONIZED&#39;);
var basin = ee.FeatureCollection(&#39;WWF/HydroSHEDS/v1/Basins/hybas_7&#39;);
var gcp = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/arkavathy_gcps&#39;);
var alos = ee.ImageCollection(&#39;JAXA/ALOS/AW3D30/V3_2&#39;);

var arkavathy = basin.filter(ee.Filter.eq(&#39;HYBAS_ID&#39;, 4071139640));
var geometry = arkavathy.geometry();
Map.centerObject(geometry);

var filtered = s2
  .filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry));

// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA)
  .select(&#39;B.*&#39;);

var composite = filteredMasked.median();

var addIndices = function(image) {
  var ndvi = image.normalizedDifference([&#39;B8&#39;, &#39;B4&#39;]).rename([&#39;ndvi&#39;]);
  var ndbi = image.normalizedDifference([&#39;B11&#39;, &#39;B8&#39;]).rename([&#39;ndbi&#39;]);
  var mndwi = image.normalizedDifference([&#39;B3&#39;, &#39;B11&#39;]).rename([&#39;mndwi&#39;]); 
  var bsi = image.expression(
      &#39;(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) &#39;, {
        &#39;X&#39;: image.select(&#39;B11&#39;), //swir1
        &#39;Y&#39;: image.select(&#39;B4&#39;),  //red
        &#39;A&#39;: image.select(&#39;B8&#39;), // nir
        &#39;B&#39;: image.select(&#39;B2&#39;), // blue
  }).rename(&#39;bsi&#39;);
  return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi);
};

var composite = addIndices(composite);

// Calculate Slope and Elevation

// Use ALOS World 3D v3

// This comes as a collection of images
// We mosaic it to create a single image

// Need to set the projection correctly on the mosaic
// for the slope computation
var proj = alos.first().projection();

var elevation = alos.select(&#39;DSM&#39;).mosaic()
  .setDefaultProjection(proj)
  .rename(&#39;elev&#39;);

var slope = ee.Terrain.slope(elevation)
  .rename(&#39;slope&#39;);

var composite = composite.addBands(elevation).addBands(slope);
var visParams = {bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;], min: 0, max: 3000, gamma: 1.2};
Map.addLayer(composite.clip(geometry), visParams, &#39;RGB&#39;);

// Normalize the image 

// Machine learning algorithms work best on images when all features have
// the same range

// Function to Normalize Image
// Pixel Values should be between 0 and 1
// Formula is (x - xmin) / (xmax - xmin)
//************************************************************************** 
function normalize(image){
  var bandNames = image.bandNames();
  // Compute min and max of the image
  var minDict = image.reduceRegion({
    reducer: ee.Reducer.min(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var maxDict = image.reduceRegion({
    reducer: ee.Reducer.max(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var mins = ee.Image.constant(minDict.values(bandNames));
  var maxs = ee.Image.constant(maxDict.values(bandNames));

  var normalized = image.subtract(mins).divide(maxs.subtract(mins));
  return normalized;
}

var composite = normalize(composite);
// Add a random column and split the GCPs into training and validation set
var gcp = gcp.randomColumn();

// This being a simpler classification, we take 60% points
// for validation. Normal recommended ratio is
// 70% training, 30% validation
var trainingGcp = gcp.filter(ee.Filter.lt(&#39;random&#39;, 0.6));
var validationGcp = gcp.filter(ee.Filter.gte(&#39;random&#39;, 0.6));

// Overlay the point on the image to get training data.
var training = composite.sampleRegions({
  collection: trainingGcp,
  properties: [&#39;landcover&#39;],
  scale: 10,
  tileScale: 16
});
print(training);

// Train a classifier.
var classifier = ee.Classifier.smileRandomForest(50)
.train({
  features: training,  
  classProperty: &#39;landcover&#39;,
  inputProperties: composite.bandNames()
});

// Classify the image.
var classified = composite.classify(classifier);

var palette = [&#39;#cc6d8f&#39;, &#39;#ffc107&#39;, &#39;#1e88e5&#39;, &#39;#004d40&#39; ];
Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, &#39;2019&#39;);

//************************************************************************** 
// Accuracy Assessment
//************************************************************************** 

// Use classification map to assess accuracy using the validation fraction
// of the overall training set created above.
var test = classified.sampleRegions({
  collection: validationGcp,
  properties: [&#39;landcover&#39;],
  scale: 10,
  tileScale: 16
});

var testConfusionMatrix = test.errorMatrix(&#39;landcover&#39;, &#39;classification&#39;);

// Printing of confusion matrix may time out. Alternatively, you can export it as CSV
print(&#39;Confusion Matrix&#39;, testConfusionMatrix);
print(&#39;Test Accuracy&#39;, testConfusionMatrix.accuracy());
</code></pre><h3 id=exercise-10>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-10>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A03-Supervised-Classification%2F03c_Improving_the_Classification_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Exercise

// Improve your classification from Exercise 01c 
// Add different spectral indicies to your composite
// by using the function below

var addIndices = function(image) {
  var ndvi = image.normalizedDifference([&#39;B8&#39;, &#39;B4&#39;]).rename([&#39;ndvi&#39;]);
  var ndbi = image.normalizedDifference([&#39;B11&#39;, &#39;B8&#39;]).rename([&#39;ndbi&#39;]);
  var mndwi = image.normalizedDifference([&#39;B3&#39;, &#39;B11&#39;]).rename([&#39;mndwi&#39;]); 
  var bsi = image.expression(
      &#39;(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) &#39;, {
        &#39;X&#39;: image.select(&#39;B11&#39;), //swir1
        &#39;Y&#39;: image.select(&#39;B4&#39;),  //red
        &#39;A&#39;: image.select(&#39;B8&#39;), // nir
        &#39;B&#39;: image.select(&#39;B2&#39;), // blue
  }).rename(&#39;bsi&#39;);
  return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi);
};

 
</code></pre><h2 id=04-exporting-classification-results>04. Exporting Classification Results<a hidden class=anchor aria-hidden=true href=#04-exporting-classification-results>#</a></h2><p>When working with complex classifiers over large regions, you may get a <em>User memory limit exceeded</em> or <em>Computation timed out</em> error in the Code Editor. The reason for this is that there is a fixed time limit and smaller memory allocated for code that is run with the <em>On-Demand Computation</em> mode. For larger computations, you can use the <em>Batch</em> mode with the <code>Export</code> functions. Exports run in the background and can run longer than 5-minutes time allocated to the computation code run from the Code Editor. This allows you to process very large and complex datasets. Here’s an example showing how to export your classification results to Google Drive.</p><p><img alt="Exported Classification Outputs" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/export_classification.png></p><p>Exported Classification Outputs</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A03-Supervised-Classification%2F04b_Exporting_Classification_Results_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_SR_HARMONIZED&#39;);
var basin = ee.FeatureCollection(&#39;WWF/HydroSHEDS/v1/Basins/hybas_7&#39;);
var gcp = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/arkavathy_gcps&#39;);
var alos = ee.ImageCollection(&#39;JAXA/ALOS/AW3D30/V3_2&#39;);

var arkavathy = basin.filter(ee.Filter.eq(&#39;HYBAS_ID&#39;, 4071139640));
var geometry = arkavathy.geometry();
Map.centerObject(geometry);

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
};

var filtered = s2
  .filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry))

// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA)
  .select(&#39;B.*&#39;);

var composite = filteredMasked.median();

var addIndices = function(image) {
  var ndvi = image.normalizedDifference([&#39;B8&#39;, &#39;B4&#39;]).rename([&#39;ndvi&#39;]);
  var ndbi = image.normalizedDifference([&#39;B11&#39;, &#39;B8&#39;]).rename([&#39;ndbi&#39;]);
  var mndwi = image.normalizedDifference([&#39;B3&#39;, &#39;B11&#39;]).rename([&#39;mndwi&#39;]); 
  var bsi = image.expression(
      &#39;(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) &#39;, {
        &#39;X&#39;: image.select(&#39;B11&#39;), //swir1
        &#39;Y&#39;: image.select(&#39;B4&#39;),  //red
        &#39;A&#39;: image.select(&#39;B8&#39;), // nir
        &#39;B&#39;: image.select(&#39;B2&#39;), // blue
  }).rename(&#39;bsi&#39;);
  return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi);
};

var composite = addIndices(composite);

// Calculate Slope and Elevation

// Use ALOS World 3D v3

// This comes as a collection of images
// We mosaic it to create a single image

// Need to set the projection correctly on the mosaic
// for the slope computation
var proj = alos.first().projection();

var elevation = alos.select(&#39;DSM&#39;).mosaic()
  .setDefaultProjection(proj)
  .rename(&#39;elev&#39;);

var slope = ee.Terrain.slope(elevation)
  .rename(&#39;slope&#39;);

var composite = composite.addBands(elevation).addBands(slope);
var visParams = {bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;], min: 0, max: 3000, gamma: 1.2};
Map.addLayer(composite.clip(geometry), visParams, &#39;RGB&#39;);

// Normalize the image 

// Machine learning algorithms work best on images when all features have
// the same range

// Function to Normalize Image
// Pixel Values should be between 0 and 1
// Formula is (x - xmin) / (xmax - xmin)
//************************************************************************** 
function normalize(image){
  var bandNames = image.bandNames();
  // Compute min and max of the image
  var minDict = image.reduceRegion({
    reducer: ee.Reducer.min(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var maxDict = image.reduceRegion({
    reducer: ee.Reducer.max(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var mins = ee.Image.constant(minDict.values(bandNames));
  var maxs = ee.Image.constant(maxDict.values(bandNames));

  var normalized = image.subtract(mins).divide(maxs.subtract(mins));
  return normalized;
}

var composite = normalize(composite);
// Add a random column and split the GCPs into training and validation set
var gcp = gcp.randomColumn();

// This being a simpler classification, we take 60% points
// for validation. Normal recommended ratio is
// 70% training, 30% validation
var trainingGcp = gcp.filter(ee.Filter.lt(&#39;random&#39;, 0.6));
var validationGcp = gcp.filter(ee.Filter.gte(&#39;random&#39;, 0.6));

// Overlay the point on the image to get training data.
var training = composite.sampleRegions({
  collection: trainingGcp,
  properties: [&#39;landcover&#39;],
  scale: 10,
  tileScale: 16
});
print(training);

// Train a classifier.
var classifier = ee.Classifier.smileRandomForest(50)
.train({
  features: training,  
  classProperty: &#39;landcover&#39;,
  inputProperties: composite.bandNames()
});

// Classify the image.
var classified = composite.classify(classifier);

var palette = [&#39;#cc6d8f&#39;, &#39;#ffc107&#39;, &#39;#1e88e5&#39;, &#39;#004d40&#39; ];
Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, &#39;2019&#39;);

//************************************************************************** 
// Accuracy Assessment
//************************************************************************** 

// Use classification map to assess accuracy using the validation fraction
// of the overall training set created above.
var test = classified.sampleRegions({
  collection: validationGcp,
  properties: [&#39;landcover&#39;],
  scale: 10,
  tileScale: 16
});

var testConfusionMatrix = test.errorMatrix(&#39;landcover&#39;, &#39;classification&#39;);

//************************************************************************** 
// Exporting Results
//************************************************************************** 

// Export the classified image to Drive

// For images having integers (such as class numbers)
// we cast the image to floating point data type which
// allows the masked values to be saved as NaN values
// in the GeoTIFF format.
// You can set these to actual NoData values using
// GDAL tools after the export
// gdal_translate -a_nodata &#39;nan&#39; input.tif output.tif
Export.image.toDrive({
  image: classified.clip(geometry).toFloat(),
  description: &#39;Classified_Image_Export&#39;,
  folder: &#39;earthengine&#39;,
  fileNamePrefix: &#39;classified&#39;,
  region: geometry,
  scale: 10,
  maxPixels: 1e10
})

// Export the results of accuracy asssessment

// Create a Feature with null geometry and the value we want to export.
// Use .array() to convert Confusion Matrix to an Array so it can be
// exported in a CSV file
var fc = ee.FeatureCollection([
  ee.Feature(null, {
    &#39;accuracy&#39;: testConfusionMatrix.accuracy(),
    &#39;matrix&#39;: testConfusionMatrix.array()
  })
]);

print(fc);

Export.table.toDrive({
  collection: fc,
  description: &#39;Accuracy_Assessment_Export&#39;,
  folder: &#39;earthengine&#39;,
  fileNamePrefix: &#39;accuracy&#39;,
  fileFormat: &#39;CSV&#39;
});
</code></pre><h3 id=exercise-11>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-11>#</a></h3><p>It is also a good idea to export the classified image as an Asset. This will allows you to import the classified image in another script without running the whole classification workflow. Use the Export.image.toAsset() function to export the classified image as an asset.</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A03-Supervised-Classification%2F04c_Exporting_Classification_Results_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_SR_HARMONIZED&#39;);
var basin = ee.FeatureCollection(&#39;WWF/HydroSHEDS/v1/Basins/hybas_7&#39;);
var gcp = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/arkavathy_gcps&#39;);
var alos = ee.ImageCollection(&#39;JAXA/ALOS/AW3D30/V3_2&#39;);

var arkavathy = basin.filter(ee.Filter.eq(&#39;HYBAS_ID&#39;, 4071139640));
var geometry = arkavathy.geometry();
Map.centerObject(geometry);

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
};

var filtered = s2
  .filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry))

// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA)
  .select(&#39;B.*&#39;);

var composite = filteredMasked.median();

var addIndices = function(image) {
  var ndvi = image.normalizedDifference([&#39;B8&#39;, &#39;B4&#39;]).rename([&#39;ndvi&#39;]);
  var ndbi = image.normalizedDifference([&#39;B11&#39;, &#39;B8&#39;]).rename([&#39;ndbi&#39;]);
  var mndwi = image.normalizedDifference([&#39;B3&#39;, &#39;B11&#39;]).rename([&#39;mndwi&#39;]); 
  var bsi = image.expression(
      &#39;(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) &#39;, {
        &#39;X&#39;: image.select(&#39;B11&#39;), //swir1
        &#39;Y&#39;: image.select(&#39;B4&#39;),  //red
        &#39;A&#39;: image.select(&#39;B8&#39;), // nir
        &#39;B&#39;: image.select(&#39;B2&#39;), // blue
  }).rename(&#39;bsi&#39;);
  return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi);
};

var composite = addIndices(composite);

// Calculate Slope and Elevation

// Use ALOS World 3D v3

// This comes as a collection of images
// We mosaic it to create a single image

// Need to set the projection correctly on the mosaic
// for the slope computation
var proj = alos.first().projection();

var elevation = alos.select(&#39;DSM&#39;).mosaic()
  .setDefaultProjection(proj)
  .rename(&#39;elev&#39;);

var slope = ee.Terrain.slope(elevation)
  .rename(&#39;slope&#39;);

var composite = composite.addBands(elevation).addBands(slope);
var visParams = {bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;], min: 0, max: 3000, gamma: 1.2};
Map.addLayer(composite.clip(geometry), visParams, &#39;RGB&#39;);

// Normalize the image 

// Machine learning algorithms work best on images when all features have
// the same range

// Function to Normalize Image
// Pixel Values should be between 0 and 1
// Formula is (x - xmin) / (xmax - xmin)
//************************************************************************** 
function normalize(image){
  var bandNames = image.bandNames();
  // Compute min and max of the image
  var minDict = image.reduceRegion({
    reducer: ee.Reducer.min(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var maxDict = image.reduceRegion({
    reducer: ee.Reducer.max(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var mins = ee.Image.constant(minDict.values(bandNames));
  var maxs = ee.Image.constant(maxDict.values(bandNames));

  var normalized = image.subtract(mins).divide(maxs.subtract(mins));
  return normalized;
}

var composite = normalize(composite);
// Add a random column and split the GCPs into training and validation set
var gcp = gcp.randomColumn();

// This being a simpler classification, we take 60% points
// for validation. Normal recommended ratio is
// 70% training, 30% validation
var trainingGcp = gcp.filter(ee.Filter.lt(&#39;random&#39;, 0.6));
var validationGcp = gcp.filter(ee.Filter.gte(&#39;random&#39;, 0.6));

// Overlay the point on the image to get training data.
var training = composite.sampleRegions({
  collection: trainingGcp,
  properties: [&#39;landcover&#39;],
  scale: 10,
  tileScale: 16
});

// Train a classifier.
var classifier = ee.Classifier.smileRandomForest(50)
.train({
  features: training,  
  classProperty: &#39;landcover&#39;,
  inputProperties: composite.bandNames()
});

// Classify the image.
var classified = composite.classify(classifier);

var palette = [&#39;#cc6d8f&#39;, &#39;#ffc107&#39;, &#39;#1e88e5&#39;, &#39;#004d40&#39; ];
Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, &#39;2019&#39;);

// Exercise 

// Use the Export.image.toAsset() function to export the 
// classified image as a Earth Engine Asset.

// This will allows you to import the classified image in another
// script without running the whole classification workflow.

// Hint: For images with discrete pixel values, we must set the
// pyramidingPolicy to &#39;mode&#39;.
// The pyramidingPolicy parameter should a dictionary specifying
// the policy for each band. A simpler way to specify it for all
// bands is to use {&#39;.default&#39;: &#39;mode&#39;}

// assetId should be specified as a string
// It can be just the asset name &#39;classified_image&#39;
// or a full path such as &#39;projects/ee-&lt;yourusername&gt;/classified_image&#39;
</code></pre><h2 id=05-calculating-area>05. Calculating Area<a hidden class=anchor aria-hidden=true href=#05-calculating-area>#</a></h2><p>Now that we have the results of our classification, we will learn how to calculate the area for pixels in each class. The functions used for area computations are different for vectors and raster data.</p><ul><li><strong>Area of Polygons</strong>: Calculating area for polygons is done using the <code>area()</code> function. It computes area on a sphere (ignoring the ellipsoid flattening) and gives you the area in square meters. You can optionally supply <code>proj</code> and a non-zero <code>maxError</code> parameters to calculate area in a specific projected CRS. For example, <code>area({proj:'EPSG:32643', maxError: 1})</code> will calculate the area of the polygon after reprojecting it to the <em>WGS 84/UTM Zone 43</em> CRS with a tolerance of 1 meter.</li><li><strong>Area of Image Pixels</strong>: Area of image pixels is computed using the <code>ee.Image.pixelArea()</code> function. This function computes the area inside the 4 corners of each pixel using the WGS84 ellipsoid. The <code>ee.Image.pixelArea()</code> function uses a custom equal-area projection for area calculation. The result is area in square meters regardless of the projection of the input image. <a href=https://groups.google.com/g/google-earth-engine-developers/c/Ccaorx-obVw/m/_ZQdP2wVAgAJ>Learn more</a>.</li></ul><p><img alt="Calculating Green Cover from Classified Image" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/area_calculation.png></p><p>Calculating Green Cover from Classified Image</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A03-Supervised-Classification%2F05b_Calculating_Area_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var classified = ee.Image(&#39;users/ujavalgandhi/e2e/bangalore_classified&#39;);
var bangalore = ee.FeatureCollection(&#39;users/ujavalgandhi/public/bangalore_boundary&#39;);

Map.addLayer(bangalore, {color: &#39;blue&#39;}, &#39;Bangalore City&#39;);

var palette = [&#39;#cc6d8f&#39;, &#39;#ffc107&#39;, &#39;#1e88e5&#39;, &#39;#004d40&#39; ];
Map.addLayer(classified, {min: 0, max: 3, palette: palette}, &#39;2019&#39;);

// Calling .geometry() on a feature collection gives the
// dissolved geometry of all features in the collection

// .area() function calculates the area in square meters
var cityArea = bangalore.geometry().area();

// We can cast the result to a ee.Number() and calculate the
// area in square kilometers
var cityAreaSqKm = ee.Number(cityArea).divide(1e6).round();
print(cityAreaSqKm);

// Area Calculation for Images
var vegetation = classified.eq(3);
// If the image contains values 0 or 1, we can calculate the
// total area using reduceRegion() function

// The result of .eq() operation is a binary image with pixels
// values of 1 where the condition matched and 0 where it didn&#39;t
Map.addLayer(vegetation, {min:0, max:1, palette: [&#39;white&#39;, &#39;green&#39;]}, &#39;Green Cover&#39;);

// Since our image has only 0 and 1 pixel values, the vegetation
// pixels will have values equal to their area
var areaImage = vegetation.multiply(ee.Image.pixelArea());

// Now that each pixel for vegetation class in the image has the value
// equal to its area, we can sum up all the values in the region
// to get the total green cover.

var area = areaImage.reduceRegion({
  reducer: ee.Reducer.sum(),
  geometry: bangalore.geometry(),
  scale: 10,
  maxPixels: 1e10
});
// The result of the reduceRegion() function is a dictionary with the key
// being the band name. We can extract the area number and convert it to
// square kilometers
var vegetationAreaSqKm = ee.Number(area.get(&#39;classification&#39;)).divide(1e6).round();
print(vegetationAreaSqKm);
</code></pre><blockquote><p>If you want to compute area covered by each class, you can use a <a href=https://developers.google.com/earth-engine/reducers_grouping>Grouped Reducer</a>. See the <a href=https://courses.spatialthoughts.com/end-to-end-gee-supplement.html#calculating-area-by-class>Supplement</a> to see a code snippet.</p></blockquote><h3 id=exercise-12>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-12>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A03-Supervised-Classification%2F05c_Calculating_Area_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Exercise
// Compute and print the percentage green cover of the city
</code></pre><h2 id=assignment-3>Assignment 3<a hidden class=anchor aria-hidden=true href=#assignment-3>#</a></h2><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3AAssignments%2FAssignment3">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Choose a city of your choice and create land use land classification
// using supervised classification technique. 

// You can use your script 01c from 03-Supervised-Classification
// module as a starting point.

// The classification should incorporate the following techniques
// 1. Add relevant indicies
// 2. Add cloud masking
// 3. Add elevation and slope
// 4. Normalize the data

// [Optional]
// Accuracy Assessment
// Post-processing Classification
</code></pre><h2 id=module-4-change-detection>Module 4: Change Detection<a hidden class=anchor aria-hidden=true href=#module-4-change-detection>#</a></h2><h2 id=introduction-to-change-detection>Introduction to Change Detection<a hidden class=anchor aria-hidden=true href=#introduction-to-change-detection>#</a></h2><p>Many earth observation datasets are available at regular intervals over long periods of time. This enables us to detect changes on the Earth’s surface. Change detection technique in remote sensing fall in the following categories</p><ul><li><strong>Single Band Change</strong>: Measuring change in a single band image or a spectral index using a threshold</li><li><strong>Multi Band Change</strong>: Measuring spectral distance and spectral angle between two multiband images</li><li><strong>Classification of Change</strong>: One-pass classification using stacked image containing bands from before and after an event</li><li><strong>Post Classification Comparison</strong>: Comparing two classified images and computing class transitions</li></ul><p><a href="https://www.youtube.com/watch?v=ybHxiygVVz0&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=5"><img alt="Watch the Video" loading=lazy src=https://img.youtube.com/vi/ybHxiygVVz0/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=ybHxiygVVz0&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=5">Watch the Video ↗</a></p><h2 id=01-spectral-index-change>01. Spectral Index Change<a hidden class=anchor aria-hidden=true href=#01-spectral-index-change>#</a></h2><p>Many types of change can be detected by measuring the change in a spectral index and applying a threshold. This technique is suitable when there is a suitable spectral index is available for the type of change you are interested in detecting.</p><p>Here we apply this technique to map the extent and severity of a forest fire. The <strong>Normalized Burn Ratio (NBR)</strong> is an index that is designed to highlight burnt vegetation areas. We compute the NBR for before and after images. Then we apply a suitable threshold to find burnt areas.</p><p><img alt="Spectral Index Change Detection" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/spectral_index_change.png></p><p>Spectral Index Change Detection</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A04-Change-Detection%2F01b_Spectral_Index_Change_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>// On 21st February 2019, massive forest fires broke out in
// numerous places across the Bandipur National Park of
// the Karnataka state in India.
// By 25 February 2019 most fire was brought under control
// This script shows how to do damage assessment using
// spectral index change detection technique.

// Define the area of interest
var geometry = ee.Geometry.Polygon([[
  [76.37639666685044, 11.766523239445169],
  [76.37639666685044, 11.519036946599561],
  [76.78426409849106, 11.519036946599561],
  [76.78426409849106, 11.766523239445169]
]]);
var fireStart = ee.Date(&#39;2019-02-20&#39;);
var fireEnd = ee.Date(&#39;2019-02-25&#39;);

Map.centerObject(geometry, 10)

var s2 = ee.ImageCollection(&#34;COPERNICUS/S2&#34;)

// Apply filters 
var filtered = s2
  .filter(ee.Filter.bounds(geometry))
  .select(&#39;B.*&#39;)

// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA);

// Create Before and After composites
var before = filteredMasked
  .filter(ee.Filter.date(
    fireStart.advance(-2, &#39;month&#39;), fireStart))
  .median()

var after = filteredMasked
  .filter(ee.Filter.date(
    fireEnd, fireEnd.advance(1, &#39;month&#39;)))
  .median()

// Freshly burnt regions appeat bright in SWIR-bands
// Use a False Color Visualization
var swirVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B12&#39;, &#39;B8&#39;, &#39;B4&#39;],
};
Map.addLayer(before.clip(geometry), swirVis, &#39;Before&#39;)
Map.addLayer(after.clip(geometry), swirVis, &#39;After&#39;)

// Write a function to calculate  Normalized Burn Ratio (NBR)
// &#39;NIR&#39; (B8) and &#39;SWIR-2&#39; (B12)
var addNBR = function(image) {
  var nbr = image.normalizedDifference([&#39;B8&#39;, &#39;B12&#39;]).rename([&#39;nbr&#39;]);
  return image.addBands(nbr)
}

var beforeNbr = addNBR(before).select(&#39;nbr&#39;);
var afterNbr = addNBR(after).select(&#39;nbr&#39;);

var nbrVis = {min: -0.5, max: 0.5, palette: [&#39;white&#39;, &#39;black&#39;]}

Map.addLayer(beforeNbr.clip(geometry), nbrVis, &#39;Prefire NBR&#39;);
Map.addLayer(afterNbr.clip(geometry), nbrVis, &#39;Postfire NBR&#39;);

// Calculate Change in NBR (dNBR)
var change = beforeNbr.subtract(afterNbr)

// Apply a threshold
var threshold = 0.3

// Display Burned Areas
var burned = change.gt(threshold)
Map.addLayer(burned.clip(geometry), {min:0, max:1, palette: [&#39;white&#39;, &#39;red&#39;]}, &#39;Burned&#39;, false) 
</code></pre><h3 id=exercise-13>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-13>#</a></h3><p><img alt="Classifying the Change Image" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/spectral_index_change_exercise.png></p><p>Classifying the Change Image</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A04-Change-Detection%2F01c_Spectral_Index_Change_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Define the area of interest
var geometry = ee.Geometry.Polygon([[
  [76.37639666685044, 11.766523239445169],
  [76.37639666685044, 11.519036946599561],
  [76.78426409849106, 11.519036946599561],
  [76.78426409849106, 11.766523239445169]
]]);
var fireStart = ee.Date(&#39;2019-02-20&#39;);
var fireEnd = ee.Date(&#39;2019-02-25&#39;);

Map.centerObject(geometry, 10)

var s2 = ee.ImageCollection(&#34;COPERNICUS/S2&#34;)

// Apply filters 
var filtered = s2
  .filter(ee.Filter.bounds(geometry))
  .select(&#39;B.*&#39;)

// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA);

// Create Before and After composites
var before = filteredMasked
  .filter(ee.Filter.date(
    fireStart.advance(-2, &#39;month&#39;), fireStart))
  .median()

var after = filteredMasked
  .filter(ee.Filter.date(
    fireEnd, fireEnd.advance(1, &#39;month&#39;)))
  .median()

// Write a function to calculate  Normalized Burn Ratio (NBR)
// &#39;NIR&#39; (B8) and &#39;SWIR-2&#39; (B12)
var addNBR = function(image) {
  var nbr = image.normalizedDifference([&#39;B8&#39;, &#39;B12&#39;]).rename([&#39;nbr&#39;]);
  return image.addBands(nbr)
}

var beforeNbr = addNBR(before).select(&#39;nbr&#39;);
var afterNbr = addNBR(after).select(&#39;nbr&#39;);

// Calculate Change in NBR (dNBR)
var change = beforeNbr.subtract(afterNbr)

var dnbrPalette = [&#39;#ffffb2&#39;,&#39;#fecc5c&#39;,&#39;#fd8d3c&#39;,&#39;#f03b20&#39;,&#39;#bd0026&#39;];
// Display the change image
Map.addLayer(change.clip(geometry), {min:0.1, max: 0.7, palette: dnbrPalette},
  &#39;Change in NBR&#39;)

// We can also classify the change image according to
// burn severity

// United States Geological Survey (USGS) proposed
// a classification table to interpret the burn severity
// We will assign a discrete class value and visualize it
// | Severity     | dNBR Range         | Class |
// |--------------|--------------------|-------|
// | Unburned     | &lt; 0.1              | 0     |
// | Low Severity | &gt;= 0.10 and &lt;0.27  | 1     |
// | Moderate-Low | &gt;= 0.27 and &lt;0.44  | 2     |
// | Moderate-High| &gt;= 0.44 and&lt; 0.66  | 3     |
// | High         | &gt;= 0.66            | 4     |

// Classification of continuous values can be done
// using the .where() function
var severity = change
  .where(change.lt(0.10), 0)
  .where(change.gte(0.10).and(change.lt(0.27)), 1)
  .where(change.gte(0.27).and(change.lt(0.44)), 2)
  .where(change.gte(0.44).and(change.lt(0.66)), 3)
  .where(change.gt(0.66), 4)

// Exercise

// The resulting image &#39;severity&#39; is a discrete image with 
// pixel values from 0-4 representing the severity class

// Display the image according to the following color table

// | Severity     | Class | Color   |
// |--------------|-------|---------|
// | Unburned     | 0     | green   |
// | Low Severity | 1     | yellow  |
// | Moderate-Low | 2     | organge |
// | Moderate-High| 3     | red     |
// | High         | 4     | magenta |
</code></pre><h2 id=02-spectral-distance-change>02. Spectral Distance Change<a hidden class=anchor aria-hidden=true href=#02-spectral-distance-change>#</a></h2><p>When you want to detect changes from multi-band images, a useful technique is to compute the Spectral Distance and Spectral Angle between the two images. Pixels that exhibit a large change will have a larger distance compared to those that did not change. This technique is particularly useful when there are no suitable index to detect the change. It can be applied to detect change after natural disasters or human conflicts.</p><p>Here we use this technique to detect landslides using before/after composites. You may learn more about this technique at <a href=https://goo.gl/xotYhk>Craig D’Souza’s Change Detection</a> presentation.</p><p><img alt="Spectral Distance Change Detection" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/spectral_distance.png></p><p>Spectral Distance Change Detection</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A04-Change-Detection%2F01b_Spectral_Distance_Change_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var geometry = ee.Geometry.Polygon([[
  [75.70357667713435, 12.49723970868507],
  [75.70357667713435, 12.470171844429931],
  [75.7528434923199, 12.470171844429931],
  [75.7528434923199, 12.49723970868507]
]]);
Map.centerObject(geometry);
var s2 = ee.ImageCollection(&#39;COPERNICUS/S2&#39;);
var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
};

var filtered = s2
  .filter(ee.Filter.bounds(geometry))
  .select(&#39;B.*&#39;);

// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.65;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA);

var dateOfIncident = ee.Date(&#39;2018-08-15&#39;);

var before = filteredMasked
  .filter(ee.Filter.date(dateOfIncident.advance(-2, &#39;year&#39;), dateOfIncident))
  .filter(ee.Filter.calendarRange(6, 10, &#39;month&#39;))
  .median()
  .select(&#39;B.*&#39;);
  
var after = filteredMasked
  .filter(ee.Filter.date(
    dateOfIncident, dateOfIncident.advance(1, &#39;month&#39;)))
  .median()
  .select(&#39;B.*&#39;);

Map.addLayer(before.clip(geometry), rgbVis, &#39;Before&#39;);
Map.addLayer(after.clip(geometry), rgbVis, &#39;After&#39;);

// Use the spectralDistance() function to get spectral distance measures

// Use the metric &#39;Spectral Angle Mapper (SAM)
// The result is the spectral angle in radians
var angle = after.spectralDistance(before, &#39;sam&#39;);
Map.addLayer(angle.clip(geometry), {min: 0, max: 1, palette: [&#39;white&#39;, &#39;purple&#39;]}, &#39;Spectral Angle&#39;);

// Use the metric &#39;Squared Euclidian Distance (SED)&#39;
var sed = after.spectralDistance(before, &#39;sed&#39;);
// Take square root to get euclidian distance
var distance = sed.sqrt();

Map.addLayer(distance.clip(geometry), {min: 0, max: 1500, palette: [&#39;white&#39;, &#39;red&#39;]}, &#39;spectral distance&#39;);
</code></pre><h3 id=exercise-14>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-14>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A04-Change-Detection%2F01c_Spectral_Distance_Change_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>var geometry = ee.Geometry.Polygon([[
  [75.70357667713435, 12.49723970868507],
  [75.70357667713435, 12.470171844429931],
  [75.7528434923199, 12.470171844429931],
  [75.7528434923199, 12.49723970868507]
]]);
Map.centerObject(geometry);
var s2 = ee.ImageCollection(&#39;COPERNICUS/S2&#39;);
var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
};

var filtered = s2
  .filter(ee.Filter.bounds(geometry))
  .select(&#39;B.*&#39;);

// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.65;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA);

var dateOfIncident = ee.Date(&#39;2018-08-15&#39;);

var before = filteredMasked
  .filter(ee.Filter.date(dateOfIncident.advance(-2, &#39;year&#39;), dateOfIncident))
  .filter(ee.Filter.calendarRange(6, 10, &#39;month&#39;))
  .median()
  .select(&#39;B.*&#39;);
  
var after = filteredMasked
  .filter(ee.Filter.date(
    dateOfIncident, dateOfIncident.advance(1, &#39;month&#39;)))
  .median()
  .select(&#39;B.*&#39;);

Map.addLayer(before.clip(geometry), rgbVis, &#39;Before&#39;);
Map.addLayer(after.clip(geometry), rgbVis, &#39;After&#39;);

// Use the spectralDistance() function to get spectral distance measures

// Use the metric &#39;Spectral Angle Mapper (SAM)
// The result is the spectral angle in radians
var angle = after.spectralDistance(before, &#39;sam&#39;);
Map.addLayer(angle.clip(geometry), {min: 0, max: 1, palette: [&#39;white&#39;, &#39;purple&#39;]}, &#39;Spectral Angle&#39;);

// Exercise
// Inspect the angle image and find a suitable threshold
// that signifies damage after the landslides
// Apply the threshold and create a new image showing landslides
// Display the results

// Hint: Use the .gt() method to apply the threshold
</code></pre><h2 id=03-direct-classification-of-change>03. Direct Classification of Change<a hidden class=anchor aria-hidden=true href=#03-direct-classification-of-change>#</a></h2><p>This technique of change detection is also known as <em>One-pass Classification</em> or <em>Direct Multi-date Classification</em>. Here we create a single stacked image containing bands from before and after images. We train a classifier with training data sampled from the stacked image and apply the classifier on the stacked image to find all change pixels.</p><p><img alt="All pixels that changed from bare ground to built-up" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/change_classification.png></p><p>All pixels that changed from bare ground to built-up</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A04-Change-Detection%2F03b_Classifying_Change_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var bangalore = ee.FeatureCollection(&#39;users/ujavalgandhi/public/bangalore_boundary&#39;);
var change = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/bangalore_change_gcps&#39;);
var nochange = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/bangalore_nochange_gcps&#39;);
var s2 = ee.ImageCollection(&#39;COPERNICUS/S2&#39;);

var geometry = bangalore.geometry();
Map.centerObject(geometry);

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
};

// Write a function for Cloud masking

var filtered = s2
  .filter(ee.Filter.bounds(geometry))

// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA)
  .select(&#39;B.*&#39;);

// January 2019
var filtered2019 = filteredMasked.filter(ee.Filter.date(&#39;2019-01-01&#39;,&#39;2019-02-01&#39;))
var image2019 = filtered2019.median();
// Display the input composite.
Map.addLayer(image2019.clip(geometry), rgbVis, &#39;2019&#39;);

// January 2020
var filtered2020 = filteredMasked.filter(ee.Filter.date(&#39;2020-01-01&#39;,&#39;2020-02-01&#39;))
var image2020 = filtered2020.median();
// Display the input composite.
Map.addLayer(image2020.clip(geometry), rgbVis, &#39;2020&#39;);

var stackedImage = image2019.addBands(image2020);

// Overlay the point on the image to get training data.
var training = stackedImage.sampleRegions({
  collection: change.merge(nochange), 
  properties: [&#39;class&#39;], 
  scale: 10
});

// Train a classifier.
var classifier = ee.Classifier.smileRandomForest(50).train({
  features: training,  
  classProperty: &#39;class&#39;, 
  inputProperties: stackedImage.bandNames()
});

// Classify the image.
var classified = stackedImage.classify(classifier);
Map.addLayer(classified.clip(geometry), {min: 0, max: 1, palette: [&#39;white&#39;, &#39;red&#39;]}, &#39;change&#39;); 
</code></pre><h3 id=exercise-15>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-15>#</a></h3><p><a href="https://code.earthengine.google.co.in/?accept_repo=users%2Fujavalgandhi%2FEnd-to-End-GEE&amp;scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A04-Change-Detection%2F03c_Classifying_Change_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Add an NDBI band to improve the detection of changes.

var addNDBI = function(image) {
  var ndbi = image.normalizedDifference([&#39;B11&#39;, &#39;B8&#39;]).rename([&#39;ndbi&#39;]);
  return image.addBands(ndbi)
}

// use addNDBI() function to add the NDBI band to both 2019 and 2020 composite images
// Hint1: You can save the resulting image in the same variable to avoid changing 
// a lot of code.
// var image = addNDBI(image)
</code></pre><h2 id=04-post-classification-comparison>04. Post-classification Comparison<a hidden class=anchor aria-hidden=true href=#04-post-classification-comparison>#</a></h2><p>We dealing with multi-class images, a useful metric for change detection is to know how many pixels from class X changed to class Y. This can be accomplished using the <code>ee.Reducer.frequencyHistogram()</code> reducer as shown below.</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A04-Change-Detection%2F04b_Post_Classification_Comparison_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var bangalore = ee.FeatureCollection(&#39;users/ujavalgandhi/public/bangalore_boundary&#39;);
var urban = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/urban_gcps&#39;);
var bare = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/bare_gcps&#39;);
var water = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/water_gcps&#39;);
var vegetation = ee.FeatureCollection(&#39;users/ujavalgandhi/e2e/vegetation_gcps&#39;);
var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_SR&#39;);
var geometry = bangalore.geometry();
Map.centerObject(geometry);

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;], 
};

// 2019 Jan
var filtered = s2
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2019-02-01&#39;))
  .filter(ee.Filter.bounds(geometry))
  .select(&#39;B.*&#39;);

  
var before = filtered.median().clip(geometry);
// Display the input composite.
Map.addLayer(before.clip(geometry), rgbVis, &#39;before&#39;);

var training = urban.merge(bare).merge(water).merge(vegetation);

// Overlay the point on the image to get training data.
var training = before.sampleRegions({
  collection: training, 
  properties: [&#39;landcover&#39;], 
  scale: 10
});

// Train a classifier.
var classifier = ee.Classifier.smileRandomForest(50).train({
  features: training,  
  classProperty: &#39;landcover&#39;, 
  inputProperties: before.bandNames()
});

// // Classify the image.
var beforeClassified = before.classify(classifier);
var palette = [&#39;#cc6d8f&#39;, &#39;#ffc107&#39;, &#39;#1e88e5&#39;, &#39;#004d40&#39; ];
var classifiedVis = {min: 0, max: 3, palette: palette};
Map.addLayer(beforeClassified.clip(geometry), classifiedVis, &#39;before_classified&#39;);

// 2020 Jan
var after = s2
  .filter(ee.Filter.date(&#39;2020-01-01&#39;, &#39;2020-02-01&#39;))
  .filter(ee.Filter.bounds(geometry))
  .select(&#39;B.*&#39;)
  .median();

Map.addLayer(after.clip(geometry), rgbVis, &#39;after&#39;);

// Classify the image.
var afterClassified= after.classify(classifier);
Map.addLayer(afterClassified.clip(geometry), classifiedVis, &#39;after_classified&#39;);

// Reclassify from 0-3 to 1-4
var beforeClasses = beforeClassified.remap([0, 1, 2, 3], [1, 2, 3, 4]);
var afterClasses = afterClassified.remap([0, 1, 2, 3], [1, 2, 3, 4]);

// Show all changed areas
var changed = afterClasses.subtract(beforeClasses).neq(0);
Map.addLayer(changed.clip(geometry), {min:0, max:1, palette: [&#39;white&#39;, &#39;red&#39;]}, &#39;Change&#39;);

// We multiply the before image with 100 and add the after image
// The resulting pixel values will be unique and will represent each unique transition
// i.e. 102 is urban to bare, 103 urban to water etc.
var merged = beforeClasses.multiply(100).add(afterClasses).rename(&#39;transitions&#39;);

// Use a frequencyHistogram to get a pixel count per class
var transitionMatrix = merged.reduceRegion({
  reducer: ee.Reducer.frequencyHistogram(), 
  geometry: geometry,
  maxPixels: 1e10,
  scale:10,
  tileScale: 16
});
// This prints number of pixels for each class transition
print(transitionMatrix.get(&#39;transitions&#39;));

// If we want to calculate the area of each class transition
// we can use a grouped reducer

// Divide by 1e6 to get the area in sq.km.
var areaImage = ee.Image.pixelArea().divide(1e6).addBands(merged);
// Calculate Area by each Transition Class
// using a Grouped Reducer
var areas = areaImage.reduceRegion({
      reducer: ee.Reducer.sum().group({
      groupField: 1,
      groupName: &#39;transitions&#39;,
    }),
    geometry: geometry,
    scale: 100,
    tileScale: 4,
    maxPixels: 1e10
    }); 

// Post-process the result to generate a clean output
var classAreas = ee.List(areas.get(&#39;groups&#39;));
var classAreaLists = classAreas.map(function(item) {
      var areaDict = ee.Dictionary(item);
      var classNumber = ee.Number(areaDict.get(&#39;transitions&#39;)).format();
      var area = ee.Number(areaDict.get(&#39;sum&#39;)).round();
      return ee.List([classNumber, area]);
    });
var classTransitionsAreaDict = ee.Dictionary(classAreaLists.flatten());
print(classTransitionsAreaDict);
</code></pre><h3 id=exercise-16>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-16>#</a></h3><p><img alt="Lost water pixels between 2019 and 2020" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/post_classification.png></p><p>Lost water pixels between 2019 and 2020</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A04-Change-Detection%2F04c_Post_Classification_Comparison_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Exercise
// Show all areas where water became other classes and display the result
// Hint1: Select class 3 pixels from before image and NOT class 3 pixels from after image
// Hint2: use the .and() operation to select pixels matching both conditions
</code></pre><h2 id=module-5-earth-engine-apps>Module 5: Earth Engine Apps<a hidden class=anchor aria-hidden=true href=#module-5-earth-engine-apps>#</a></h2><p>This module is focused the concepts related to client vs. server that will help you in creating web apps. We will be building an app using the Earth Engine User Interface API and publishing it to Google Cloud.</p><p><a href="https://www.youtube.com/watch?v=Y4lM7Wtckhs&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=6"><img alt="Watch the Video" loading=lazy src=https://img.youtube.com/vi/Y4lM7Wtckhs/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=Y4lM7Wtckhs&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=6">Watch the Video ↗</a></p><h2 id=01-client-vsserver>01. Client vs. Server<a hidden class=anchor aria-hidden=true href=#01-client-vsserver>#</a></h2><p>The User Interface elements in your Code Editor - Map View, Drawing Tools etc. are ‘client-side’ elements. They run in YOUR browser. Image Collections, feature collections, calculations on Earth Engine objects etc. are ‘server-side’ elements. They run in Google’s data center. You cannot mix both these objects. To learn more, visit the <a href=https://developers.google.com/earth-engine/guides/client_server>Client vs. Server</a> section of the Earth Engine User Guide.</p><ul><li>To convert client-side objects to server-side objects, you can use the appropriate API function. Server-side functions start with <code>ee.</code>, such <code>ee.Date()</code>, <code>ee.Image()</code> etc.</li><li>To convert server-side objects to client-side objects, you can call <code>.getInfo()</code> on am Earth Engine object. For the Python API, this is the only way to extract information from a server-side object, but the Javascript API provides a better (and preferred) - method for bring server-side objects to client-side using the <code>evaluate()</code> method. This method asynchronously retrieves the value of the object, without blocking the user interface - meaning it will let your code continue to execute while it fetches the value.</li></ul><blockquote><p>Tip: You can use <code>ee.Algorithms.ObjectType()</code> to get the type of a server-side object</p></blockquote><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A05-Earth-Engine-Apps%2F01b_Client_vs_Server_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var date = &#39;2020-01-01&#39; // This is client-side
print(typeof(date))

var eedate = ee.Date(&#39;2020-01-01&#39;).format() // This is server-side
print(typeof(eedate)) 

// To bring server-side objects to client-side, you can call .getInfo()

// var clientdate = eedate.getInfo()
// print(clientdate)
// print(typeof(clientdate)) 

// getInfo() blocks the execution of your code till the value is fetched
// If the value takes time to compute, your code editor will freeze
// This is not a good user experience
var s2 = ee.ImageCollection(&#34;COPERNICUS/S2_SR&#34;)
var filtered = s2.filter(ee.Filter.date(&#39;2020-01-01&#39;, &#39;2020-02-01&#39;))

//var numImages = filtered.size().getInfo()
//print(numImages)

// A better approach is to use evaluate() function

// You need to define a &#39;callback&#39; function which will be called once the 
// value has been computed and ready to be used.

var myCallback = function(object) {
  print(object)
}
print(&#39;Computing the size of the collection&#39;)
var numImages = filtered.size().evaluate(myCallback)
</code></pre><h3 id=exercise-17>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-17>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A05-Earth-Engine-Apps%2F01c_Client_vs_Server_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>var date = ee.Date.fromYMD(2019, 1, 1)
print(date)

// We can use the format() function to create
// a string from a date object
var dateString = date.format(&#39;dd MMM, YYYY&#39;)
print(dateString)

// Exercise
// The print statement below combines a client-side string
// with a server-side string - resulting in an error.

// Fix the code so that the following message is printed
// &#39;The date is 01 Jan, 2019&#39;
var message = &#39;The date is &#39; + dateString
print(message)

// Hint: 
// Convert the client-side string to a server-side string
// Use ee.String() to create a server-side string
// Use the .cat() function instead of + to combine 2 strings
</code></pre><h2 id=02-using-ui-elements>02. Using UI Elements<a hidden class=anchor aria-hidden=true href=#02-using-ui-elements>#</a></h2><p>Earth Engine comes with a User Interface API that allows you to build an interactive web application powered by Earth Engine.</p><p>The Earth Engine API provides a library of User Interface (UI) widgets - such as Buttons, Drop-down Menus, Sliders etc. - that can be used to create interactive apps. All the user interface functions are contained in the <code>ui.</code> package - such as <code>ui.Select()</code>, <code>ui.Button()</code>. You can create those elements by calling these functions with appropriate parameters. Learn more in the <a href=https://developers.google.com/earth-engine/guides/ui>Earth Engine User Interface API</a> section of the Earth Engine User Guide.</p><p>This section shows how to build a drop-down selector using the <code>ui.Select()</code> widget.</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A05-Earth-Engine-Apps%2F02b_Using_UI_Elements_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>// You can add any widgets from the ui.* module to the map
var years = [&#39;2014&#39;, &#39;2015&#39;, &#39;2016&#39;, &#39;2017&#39;];

// Let&#39;s create a ui.Select() dropdown with the above values
var yearSelector = ui.Select({
  items: years,
  value: &#39;2014&#39;,
  placeholder: &#39;Select a year&#39;,
  })
Map.add(yearSelector);

var loadImage = function() {
  var year = yearSelector.getValue();
  var col = ee.ImageCollection(&#34;NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG&#34;);
  var startDate = ee.Date.fromYMD(
    ee.Number.parse(year), 1, 1);
  var endDate = startDate.advance(1, &#39;year&#39;);
  var filtered = col.filter(ee.Filter.date(startDate, endDate));
  var composite = filtered.mean().select(&#39;avg_rad&#39;);
  var layerName = &#39;Night Lights &#39; + year;
  var nighttimeVis = {min: 0.0, max: 60.0};
  Map.addLayer(composite, nighttimeVis, layerName);
};

var button = ui.Button({
  label: &#39;Click to Load Image&#39;,
  onClick: loadImage,
  });
Map.add(button);
</code></pre><h3 id=exercise-18>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-18>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A05-Earth-Engine-Apps%2F02c_Using_UI_Elements_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Instead of manually creating a list of years like before
// we can create a list of years using ee.List.sequence()
var years = ee.List.sequence(2014, 2020)

// Convert them to strings using format() function
var yearStrings = years.map(function(year){
  return ee.Number(year).format(&#39;%04d&#39;)
})
print(yearStrings);

// Convert the server-side object to client-side using
// evaluate() and use it with ui.Select()
yearStrings.evaluate(function(yearList) {
  var yearSelector = ui.Select({
    items: yearList,
    value: &#39;2014&#39;,
    placeholder: &#39;Select a year&#39;,
    })
  Map.add(yearSelector)
});

// Exercise

// Create another dropdown with months from 1 to 12
// and add it to the map.
</code></pre><h2 id=03-building-and-publishing-an-app>03. Building and Publishing an App<a hidden class=anchor aria-hidden=true href=#03-building-and-publishing-an-app>#</a></h2><p>Building a web mapping application typically requires the skills of a full stack developer and are out of reach for most analysts and scientists. But the Earth Engine User Interface API makes this process much more accessible by providing ready-to-use widgets and free cloud hosting to allow anyone to publish an app with just a few lines of code. The main container object is the <code>ui.Panel()</code> which can contain different types of widgets.</p><p>The code below shows how to build an app called <a href=https://santhosh-m.users.earthengine.app/view/night-lights-explorer>Night Lights Explorer</a> that allows anyone to pick a year/month and load the <em>VIIRS Nighttime Day/Night Band Composite</em> for the selected month. Copy/paste the code below to your Code Editor and click <em>Run</em>.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/app1.png></p><p>You will see a panel on the right-hand side with 2 drop-down boxes and a button. These are User Interface (UI) widgets provided by the Earth Engine API that allows the user to interactively select the values. You can select the values for <em>year</em> and <em>month</em> and click <em>Load</em> button to see the image for the selected month.</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A05-Earth-Engine-Apps%2F03b_Building_an_App_with_UI_Widgets_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>// Panels are the main container widgets
var mainPanel = ui.Panel({
  style: {width: &#39;300px&#39;}
});

var title = ui.Label({
  value: &#39;Night Lights Explorer&#39;,
  style: {&#39;fontSize&#39;: &#39;24px&#39;}
});
// You can add widgets to the panel
mainPanel.add(title);

// You can even add panels to other panels
var dropdownPanel = ui.Panel({
  layout: ui.Panel.Layout.flow(&#39;horizontal&#39;),
});
mainPanel.add(dropdownPanel);

var yearSelector = ui.Select({
  placeholder: &#39;please wait..&#39;,
  })

var monthSelector = ui.Select({
  placeholder: &#39;please wait..&#39;,
  })

var button = ui.Button(&#39;Load&#39;)
dropdownPanel.add(yearSelector)
dropdownPanel.add(monthSelector)
dropdownPanel.add(button)

// Let&#39;s add a dropdown with the years
var years = ee.List.sequence(2014, 2020)
var months = ee.List.sequence(1, 12)

// Dropdown items need to be strings
var yearStrings = years.map(function(year){
  return ee.Number(year).format(&#39;%04d&#39;);
});
var monthStrings = months.map(function(month){
  return ee.Number(month).format(&#39;%02d&#39;);
});

// Evaluate the results and populate the dropdown
yearStrings.evaluate(function(yearList) {
  yearSelector.items().reset(yearList);
  yearSelector.setPlaceholder(&#39;select a year&#39;);
});

monthStrings.evaluate(function(monthList) {
  monthSelector.items().reset(monthList);
  monthSelector.setPlaceholder(&#39;select a month&#39;);

});

// Define a function that triggers when any value is changed
var loadComposite = function() {
  var col = ee.ImageCollection(&#34;NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG&#34;);
  var year = yearSelector.getValue();
  var month = monthSelector.getValue();
  var startDate = ee.Date.fromYMD(
    ee.Number.parse(year), ee.Number.parse(month), 1);
  var endDate = startDate.advance(1, &#39;month&#39;);
  var filtered = col.filter(ee.Filter.date(startDate, endDate));

  var image = ee.Image(filtered.first()).select(&#39;avg_rad&#39;);
  var nighttimeVis = {min: 0.0, max: 60.0};
  var layerName = &#39;Night Lights &#39; + year + &#39;-&#39; + month;
  Map.addLayer(image, nighttimeVis, layerName);
};
button.onClick(loadComposite);

Map.setCenter(76.43, 12.41, 8);
ui.root.add(mainPanel);
</code></pre><h3 id=exercise-19>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-19>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A05-Earth-Engine-Apps%2F03c_Building_an_App_with_UI_Widgets_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Exercise
// Add a button called &#39;Reset&#39;
// Clicking the button should remove all loaded layers

// Hint: Use Map.clear() for removing the layers
</code></pre><h2 id=04-publishing-the-app>04. Publishing the App<a hidden class=anchor aria-hidden=true href=#04-publishing-the-app>#</a></h2><p>We will now publish this app. Click on the <em>Apps</em> button.</p><p><img alt="App with UI Elements" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/app2.png></p><p>App with UI Elements</p><p>In the <em>Manage Apps</em> window, click <em>New App</em>.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/app3.png></p><p>Select the existing project or create a new project. The app will be hosted on Google Cloud, so you will need to create and link a Google Cloud project with the app. If you don’t have a Google Cloud account, you can select the <em>Register a New Project</em> option to create a new project. You can provide an edit access based on the project selection.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/app4.png></p><p>Give the name of your app and see the URL created for your app.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/app5.png></p><p>Select code to use for the app. It can be from the current content or choose any repository path where the code is saved. We will go ahead with <em>Current contents of editor</em></p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/app6.png></p><p>Click next and in the <em>Publish New App</em> dialog, leave all other settings to default and click <em>Publish</em>.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/app7.png></p><p>The app will be hosted on Google Cloud and you can access it by clicking on the <em>App Name</em> of your app in the <em>Manage Apps</em> dialog.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/app8.png></p><p>You will see your Earth Engine powered app running in the browser. Anyone can access and interact with the app by just visiting the App URL.</p><blockquote><p>The app publishing process takes a few minutes. So if you get an error that your app is not yet ready, check back in a few minutes.</p></blockquote><p><a href=https://ujavalgandhi.users.earthengine.app/view/night-lights-explorer>Explore The App ↗</a></p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/app9.png></p><h3 id=exercise-20>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-20>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A05-Earth-Engine-Apps%2F04c_Publishing_the_App_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>// Panels are the main container widgets
var mainPanel = ui.Panel({
  style: {width: &#39;300px&#39;}
});

var title = ui.Label({
  value: &#39;Night Lights Explorer&#39;,
  style: {&#39;fontSize&#39;: &#39;24px&#39;}
});
// You can add widgets to the panel
mainPanel.add(title)

// You can even add panels to other panels
var dropdownPanel = ui.Panel({
  layout: ui.Panel.Layout.flow(&#39;horizontal&#39;),
});
mainPanel.add(dropdownPanel);

var yearSelector = ui.Select({
  placeholder: &#39;please wait..&#39;,
  })

var monthSelector = ui.Select({
  placeholder: &#39;please wait..&#39;,
  })

var button = ui.Button(&#39;Load&#39;)
dropdownPanel.add(yearSelector)
dropdownPanel.add(monthSelector)
dropdownPanel.add(button)

// Let&#39;s add a dropdown with the years
var years = ee.List.sequence(2014, 2020)
var months = ee.List.sequence(1, 12)

// Dropdown items need to be strings
var yearStrings = years.map(function(year){
  return ee.Number(year).format(&#39;%04d&#39;)
})
var monthStrings = months.map(function(month){
  return ee.Number(month).format(&#39;%02d&#39;)
})

// Evaluate the results and populate the dropdown
yearStrings.evaluate(function(yearList) {
  yearSelector.items().reset(yearList)
  yearSelector.setPlaceholder(&#39;select a year&#39;)
})

monthStrings.evaluate(function(monthList) {
  monthSelector.items().reset(monthList)
  monthSelector.setPlaceholder(&#39;select a month&#39;)

})

// Define a function that triggers when any value is changed
var loadComposite = function() {
  var col = ee.ImageCollection(&#34;NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG&#34;);
  var year = yearSelector.getValue()
  var month = monthSelector.getValue()
  var startDate = ee.Date.fromYMD(
    ee.Number.parse(year), ee.Number.parse(month), 1)
  var endDate = startDate.advance(1, &#39;month&#39;)
  var filtered = col.filter(ee.Filter.date(startDate, endDate))

  var image = ee.Image(filtered.first()).select(&#39;avg_rad&#39;)
  var nighttimeVis = {min: 0.0, max: 60.0}
  var layerName = &#39;Night Lights &#39; + year + &#39;-&#39; + month
  Map.addLayer(image, nighttimeVis, layerName)
}
button.onClick(loadComposite)

// Exercise
// Set the map center to your area of interest
// Replace the author label with your name
// Publish the app.
Map.setCenter(76.43, 12.41, 8)
var authorLabel = ui.Label(&#39;App by: Ujaval Gandhi&#39;);
mainPanel.add(authorLabel);

ui.root.add(mainPanel);
</code></pre><h2 id=05-create-a-split-panel-app>05. Create a Split Panel App<a hidden class=anchor aria-hidden=true href=#05-create-a-split-panel-app>#</a></h2><p>Another useful widget that can be used in Apps is <code>ui.SplitPanel()</code>. This allows you to create an app that can display 2 different images of the same region that can be explored interactively by swiping. Here we create an app to explore the <a href=https://developers.google.com/earth-engine/datasets/catalog/ESA_WorldCover_v100>ESA WorldCover 10m</a> global classification dataset.</p><p>On the left-hand panel, we will load a Sentinel-2 composite for the year 2020. On the right-hand panel, we will load the 11-class landcover classification of the same region.</p><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A05-Earth-Engine-Apps%2F05b_Split_Panel_App_(complete)">Open in Code Editor ↗</a></p><pre tabindex=0><code>var admin2 = ee.FeatureCollection(&#34;FAO/GAUL_SIMPLIFIED_500m/2015/level2&#34;);
var selected = admin2
  .filter(ee.Filter.eq(&#39;ADM1_NAME&#39;, &#39;Karnataka&#39;))
  .filter(ee.Filter.eq(&#39;ADM2_NAME&#39;, &#39;Bangalore Urban&#39;))
var geometry = selected.geometry();
Map.centerObject(geometry)

var s2 = ee.ImageCollection(&#34;COPERNICUS/S2_HARMONIZED&#34;);

// Write a function to scale the bands
var scaleImage = function(image) {
  return image
    .multiply(0.0001)
    .copyProperties(image, [&#34;system:time_start&#34;])
}

var filtered = s2
  .filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.bounds(geometry))
  .filter(ee.Filter.date(&#39;2020-01-01&#39;, &#39;2021-01-01&#39;));
  
// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA);
  
var filteredMaskedScaled = filteredMasked.map(scaleImage);

// Create a median composite for 2020
var composite =  filteredMaskedScaled.median();

// Load ESA WorldCover 2020 Classification
var worldcover = ee.ImageCollection(&#34;ESA/WorldCover/v100&#34;)
var filtered = worldcover
  .filter(ee.Filter.date(&#39;2020-01-01&#39;, &#39;2021-01-01&#39;));
var classification = ee.Image(filtered.first());

// Create a Split Panel App

// Set a center and zoom level.
// Create two maps.
var leftMap = ui.Map();
var rightMap = ui.Map();

// Link them together.
var linker = ui.Map.Linker([leftMap, rightMap]);

// Create a split panel with the two maps.
var splitPanel = ui.SplitPanel({
  firstPanel: leftMap,
  secondPanel: rightMap,
  orientation: &#39;horizontal&#39;,
  wipe: true
});

// Remove the default map from the root panel.
ui.root.clear();

// Add our split panel to the root panel.
ui.root.add(splitPanel);

// Add the layers to the maps
// Composite goes to the leftMap
var rgbVis = {min: 0.0, max: 0.3, bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;]};
leftMap.addLayer(composite.clip(geometry), rgbVis, &#39;2020 Composite&#39;);
leftMap.centerObject(geometry);
// Classification foes to the rightMap
rightMap.addLayer(classification.clip(geometry), {}, &#39;WorldCover Classification&#39;);
rightMap.centerObject(geometry);
</code></pre><h3 id=exercise-21>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-21>#</a></h3><p><a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3A05-Earth-Engine-Apps%2F05c_Split_Panel_App_(exercise)">Try in Code Editor ↗</a></p><pre tabindex=0><code>var admin2 = ee.FeatureCollection(&#34;FAO/GAUL_SIMPLIFIED_500m/2015/level2&#34;);
var selected = admin2
  .filter(ee.Filter.eq(&#39;ADM1_NAME&#39;, &#39;Karnataka&#39;))
  .filter(ee.Filter.eq(&#39;ADM2_NAME&#39;, &#39;Bangalore Urban&#39;))
var geometry = selected.geometry();
Map.centerObject(geometry)

var s2 = ee.ImageCollection(&#34;COPERNICUS/S2_HARMONIZED&#34;);

// Write a function to scale the bands
var scaleImage = function(image) {
  return image
    .multiply(0.0001)
    .copyProperties(image, [&#34;system:time_start&#34;])
}

var filtered = s2
  .filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.bounds(geometry))
  .filter(ee.Filter.date(&#39;2020-01-01&#39;, &#39;2021-01-01&#39;));
  
  
// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA);

var filteredMaskedScaled = filteredMasked.map(scaleImage);
  
// Create a median composite for 2020
var composite =  filteredMaskedScaled.median();

// Load ESA WorldCover 2020 Classification
var worldcover = ee.ImageCollection(&#34;ESA/WorldCover/v100&#34;)
var filtered = worldcover
  .filter(ee.Filter.date(&#39;2020-01-01&#39;, &#39;2021-01-01&#39;));
var classification = ee.Image(filtered.first());

// Create a Split Panel App

// Create two maps.
var leftMap = ui.Map();
var rightMap = ui.Map();

// Link them together.
var linker = ui.Map.Linker([leftMap, rightMap]);

// Create a split panel with the two maps.
var splitPanel = ui.SplitPanel({
  firstPanel: leftMap,
  secondPanel: rightMap,
  orientation: &#39;horizontal&#39;,
  wipe: true
});

// Remove the default map from the root panel.
ui.root.clear();

// Add our split panel to the root panel.
ui.root.add(splitPanel);

// Add the layers to the maps
// Composite goes to the leftMap
var rgbVis = {min: 0.0, max: 0.3, bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;]};
leftMap.addLayer(composite.clip(geometry), rgbVis, &#39;2020 Composite&#39;);
leftMap.centerObject(geometry);
// Classification foes to the rightMap
rightMap.addLayer(classification.clip(geometry), {}, &#39;WorldCover Classification&#39;);
rightMap.centerObject(geometry);
// Adding a Legend
// The following code creates a legend with class names and colors

// Create the panel for the legend items.
var legend = ui.Panel({
  style: {
    position: &#39;middle-right&#39;,
    padding: &#39;8px 15px&#39;
  }
});

// Create and add the legend title.
var legendTitle = ui.Label({
  value: &#39;ESA WorldCover Classes&#39;,
  style: {
    fontWeight: &#39;bold&#39;,
    fontSize: &#39;18px&#39;,
    margin: &#39;0 0 4px 0&#39;,
    padding: &#39;0&#39;
  }
});
legend.add(legendTitle);

var loading = ui.Label(&#39;Loading legend...&#39;, {margin: &#39;2px 0 4px 0&#39;});
legend.add(loading);

// Creates and styles 1 row of the legend.
var makeRow = function(color, name) {
  // Create the label that is actually the colored box.
  var colorBox = ui.Label({
    style: {
      backgroundColor: &#39;#&#39; + color,
      // Use padding to give the box height and width.
      padding: &#39;8px&#39;,
      margin: &#39;0 0 4px 0&#39;
    }
  });

  // Create the label filled with the description text.
  var description = ui.Label({
    value: name,
    style: {margin: &#39;0 0 4px 6px&#39;}
  });

  return ui.Panel({
    widgets: [colorBox, description],
    layout: ui.Panel.Layout.Flow(&#39;horizontal&#39;)
  });
};

var BAND_NAME = &#39;Map&#39;;
// Get the list of palette colors and class names from the image.
classification.toDictionary().select([BAND_NAME + &#34;.*&#34;]).evaluate(function(result) {
  var palette = result[BAND_NAME + &#34;_class_palette&#34;];
  var names = result[BAND_NAME + &#34;_class_names&#34;];
  loading.style().set(&#39;shown&#39;, false);

  for (var i = 0; i &lt; names.length; i++) {
    legend.add(makeRow(palette[i], names[i]));
  }
});

// Print the panel containing the legend
print(legend);

// Exercise

// Change the filter to select your chosen Admin2 region

// The &#39;legend&#39; varaible above is a panel containing the legend
// for the classification. Add it to the map below

// Hint: UI Widgets can only be shown once in the app. Remove the
//       print statement before adding the legend to the map.
// Hint: Load the legend in the right-hand side map.
</code></pre><h2 id=module-6-google-earth-engine-python-api>Module 6: Google Earth Engine Python API<a hidden class=anchor aria-hidden=true href=#module-6-google-earth-engine-python-api>#</a></h2><h2 id=introduction-to-the-python-api>Introduction to the Python API<a hidden class=anchor aria-hidden=true href=#introduction-to-the-python-api>#</a></h2><p>Till this point in the course, we have used the Earth Engine Javascript API for all our analysis. Earth Engine also provides a Python API. If you are a Python programmer, you may prefer to use the Python API to integrate Earth Engine in your spatial analysis workflow. There are many options for running Python code that uses the Google Earth Engine API. We will use the following two methods in this course.</p><p><a href="https://www.youtube.com/watch?v=34yNkLmEHAI&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=7"><img alt="Watch the Video" loading=lazy src=https://img.youtube.com/vi/34yNkLmEHAI/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=34yNkLmEHAI&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=7">Watch the Video ↗</a></p><h3 id=google-colab>Google Colab<a hidden class=anchor aria-hidden=true href=#google-colab>#</a></h3><p>An easy way to start using the Google Earth Engine Python API is via <a href=https://colab.research.google.com/>Google Colab</a>. Google Colaboratory provides a hosted environment to run Python notebooks without having to install Python locally. It also comes pre-installed with many useful packages - including the Google Earth Engine Python API. You can simply visit <a href=https://colab.research.google.com/>https://colab.research.google.com/</a> and start a new notebook.</p><h3 id=local-development-environment>Local Development Environment<a hidden class=anchor aria-hidden=true href=#local-development-environment>#</a></h3><p>An advantage of Python API is that you can use it in your own development environment - so you get a lot more flexibility to automate as well as combine other analysis and visualization libraries with Earth Engine. This requires installing Python and the Earth Engine Python API on your machine or server. You also need to do a one-time authentication and save the token on the machine. The preferred method for installing the Earth Engine Python API is via Anaconda. Please follow our <a href=https://courses.spatialthoughts.com/install-gee-python-api.html>Google Earth Engine Python API Installation Guide</a> for step-by-step instructions.</p><h2 id=01-python-api-syntax>01. Python API Syntax<a hidden class=anchor aria-hidden=true href=#01-python-api-syntax>#</a></h2><p><a href=https://colab.research.google.com/github/spatialthoughts/courses/blob/master/code/end_to_end_gee/01_python_api_syntax.ipynb>Open in Google Colab ↗</a></p><p>Coming from the programming in Earth Engine through the Code Editor, you will need to slightly adapt your scripts to be able to run in Python. For the bulk of your code, you will be using Earth Engine API’s server-side objects and functions - which will be exactly the same in Python. You only need to make a few syntactical changes.</p><p><a href=https://developers.google.com/earth-engine/python_install#syntax>Here’s the full list</a> of differences.</p><h4 id=initialization>Initialization<a hidden class=anchor aria-hidden=true href=#initialization>#</a></h4><p>First of all, you need to run the following cells to initialize the API and authorize your account. You must have a Google Cloud Project associated with your GEE account. Replace the <code>cloud_project</code> with your own project from <a href=https://console.cloud.google.com/>Google Cloud Console</a>.</p><p>You will be prompted to allow the notebook to access your Google credentials to sign-in to the account and allow access to <em>Google Drive and Google Cloud data</em>. Once you approve, it will proceed to initialize the Earth Engine API. This step needs to be done just once per session.</p><pre tabindex=0><code>cloud_project = &#39;spatialthoughts&#39;

try:
    ee.Initialize(project=cloud_project)
except:
    ee.Authenticate()
    ee.Initialize(project=cloud_project)
</code></pre><h4 id=variables>Variables<a hidden class=anchor aria-hidden=true href=#variables>#</a></h4><p>Python code doesn’t use the ‘var’ keyword</p><p>javascript code:</p><pre tabindex=0><code>var city = &#39;San Fransico&#39;
var state = &#39;California&#39;
print(city, state)

var population = 881549
print(population)
</code></pre><pre tabindex=0><code>city = &#39;San Fransico&#39;
state = &#39;California&#39;
print(city, state)

population = 881549
print(population)
</code></pre><h4 id=earth-engine-objects>Earth Engine Objects<a hidden class=anchor aria-hidden=true href=#earth-engine-objects>#</a></h4><p>You can create Earth Engine objects using the <code>ee</code> functions the same way.</p><pre tabindex=0><code>s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;)
geometry = ee.Geometry.Polygon([[
  [82.60642647743225, 27.16350437805251],
  [82.60984897613525, 27.1618529901377],
  [82.61088967323303, 27.163695288375266],
  [82.60757446289062, 27.16517483230927]
]])
</code></pre><h4 id=line-continuation>Line Continuation<a hidden class=anchor aria-hidden=true href=#line-continuation>#</a></h4><p>Python doesn’t use a semi-colon for line ending. To indicate line-continuation you need to use the \ character</p><p>javascript code:</p><pre tabindex=0><code>var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;);
var filtered = s2.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-02-01&#39;, &#39;2019-03-01&#39;))
  .filter(ee.Filter.bounds(geometry));
</code></pre><pre tabindex=0><code>filtered = s2 \
    .filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30)) \
    .filter(ee.Filter.date(&#39;2019-02-01&#39;, &#39;2019-03-01&#39;)) \
    .filter(ee.Filter.bounds(geometry))
</code></pre><h4 id=functions>Functions<a hidden class=anchor aria-hidden=true href=#functions>#</a></h4><p>Instead of the <code>function</code> keyword, Python uses the <code>def</code> keyword. Also the in-line functions are defined using <code>lambda</code> anonymous functions.</p><p>In the example below, also now the <code>and</code> operator - which is capitalized as <code>And</code> in Python version to avoid conflict with the built-in <code>and</code> operator. The same applies to <code>Or</code> and <code>Not</code> operators. <code>true</code>, <code>false</code>, <code>null</code> in Python are also spelled as <code>True</code>, <code>False</code> and <code>None</code>.</p><p>javascript code:</p><pre tabindex=0><code>function maskS2clouds(image) {
  var qa = image.select(&#39;QA60&#39;)
  var cloudBitMask = 1 &lt;&lt; 10;
  var cirrusBitMask = 1 &lt;&lt; 11;
  var mask = qa.bitwiseAnd(cloudBitMask).eq(0).and(
             qa.bitwiseAnd(cirrusBitMask).eq(0))
  return image.updateMask(mask)//.divide(10000)
      .select(&#34;B.*&#34;)
      .copyProperties(image, [&#34;system:time_start&#34;])
}

function addNDVI(image) {
  var ndvi = image.normalizedDifference([&#39;B8&#39;, &#39;B4&#39;]).rename(&#39;ndvi&#39;);
  return image.addBands(ndvi);
}
</code></pre><pre tabindex=0><code>def maskS2clouds(image):
  qa = image.select(&#39;QA60&#39;)
  cloudBitMask = 1 &lt;&lt; 10
  cirrusBitMask = 1 &lt;&lt; 11
  mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(
             qa.bitwiseAnd(cirrusBitMask).eq(0))
  return image.updateMask(mask) \
      .select(&#34;B.*&#34;) \
      .copyProperties(image, [&#34;system:time_start&#34;])

def addNDVI(image):
  ndvi = image.normalizedDifference([&#39;B8&#39;, &#39;B4&#39;]).rename(&#39;ndvi&#39;)
  return image.addBands(ndvi)

withNdvi = filtered \
    .map(maskS2clouds) \
    .map(addNDVI)
</code></pre><h4 id=function-arguments>Function Arguments<a hidden class=anchor aria-hidden=true href=#function-arguments>#</a></h4><p>Named arguments to Earth Engine functions need to be in quotes. Also when passing the named arguments as a dictionary, it needs to be passed using the <code>**</code> keyword.</p><p>javascript code:</p><pre tabindex=0><code>var composite = withNdvi.median();
var ndvi = composite.select(&#39;ndvi&#39;);

var stats = ndvi.reduceRegion({
    reducer: ee.Reducer.mean(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e10
})    
</code></pre><pre tabindex=0><code>composite = withNdvi.median()
ndvi = composite.select(&#39;ndvi&#39;)

stats = ndvi.reduceRegion(**{
  &#39;reducer&#39;: ee.Reducer.mean(),
  &#39;geometry&#39;: geometry,
  &#39;scale&#39;: 10,
  &#39;maxPixels&#39;: 1e10
  })
</code></pre><h4 id=printing-values>Printing Values<a hidden class=anchor aria-hidden=true href=#printing-values>#</a></h4><p>The <code>print()</code> function syntax is the same. But you must remember that in the Code Editor when you cann <code>print</code>, the value of the server object is fetched and then printed. You must do that explicitely by calling <code>getInfo()</code> on any server-side object.</p><p>javascript code:</p><pre tabindex=0><code>print(stats.get(&#39;ndvi&#39;)
</code></pre><pre tabindex=0><code>print(stats.get(&#39;ndvi&#39;).getInfo())
</code></pre><h4 id=in-line-functions>In-line functions<a hidden class=anchor aria-hidden=true href=#in-line-functions>#</a></h4><p>The syntax for defining in-line functions is also slightly different. You need to use the <code>lambda</code> keyword.</p><p>javascript code:</p><pre tabindex=0><code>var myList = ee.List.sequence(1, 10);
var newList = myList.map(function(number) {
    return ee.Number(number).pow(2);
print(newList);
</code></pre><pre tabindex=0><code>myList = ee.List.sequence(1, 10)
newList = myList.map(lambda number: ee.Number(number).pow(2))
print(newList.getInfo())
</code></pre><h3 id=exercise-22>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-22>#</a></h3><p>Take the Javascript code snippet below and write the equiavalent Python code in the cell below.</p><ul><li><strong>Hint1</strong>: Chaining of filters require the use of line continuation character <code>\</code></li><li><strong>Hint2</strong>: Printing of server-side objects requires calling <code>.getInfo()</code> on the object</li></ul><p>The correct code should print the value <strong>30</strong>.</p><hr><pre tabindex=0><code>var geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241]);

var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;);

var filtered = s2.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry));
  
print(filtered.size());
</code></pre><hr><h2 id=02-automatic-conversion-of-javascript-code-to-python>02. Automatic Conversion of Javascript Code to Python<a hidden class=anchor aria-hidden=true href=#02-automatic-conversion-of-javascript-code-to-python>#</a></h2><p><a href=https://colab.research.google.com/github/spatialthoughts/courses/blob/master/code/end_to_end_gee/02_automatic_conversion_of_scripts.ipynb>Open in Google Colab ↗</a></p><p><img alt="Interactive leaflet map created by geemap" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/automatic_conversion.png></p><p>Interactive leaflet map created by geemap</p><p><a href=https://github.com/giswqs/geemap>geemap</a> is an open-source Python package that comes with many helpful features that help you use Earth Engine effectively in Python.</p><p>It comes with a function that can help you translate your javascript earth engine code to Python automatically.</p><p>The <code>geemap</code> package is pre-installed in Colab.</p><h4 id=initialization-1>Initialization<a hidden class=anchor aria-hidden=true href=#initialization-1>#</a></h4><p>First of all, you need to run the following cells to initialize the API and authorize your account. You must have a Google Cloud Project associated with your GEE account. Replace the <code>cloud_project</code> with your own project from <a href=https://console.cloud.google.com/>Google Cloud Console</a>.</p><pre tabindex=0><code>cloud_project = &#39;spatialthoughts&#39;

try:
    ee.Initialize(project=cloud_project)
except:
    ee.Authenticate()
    ee.Initialize(project=cloud_project)
</code></pre><h4 id=automatic-conversion-using-gui>Automatic Conversion using GUI<a hidden class=anchor aria-hidden=true href=#automatic-conversion-using-gui>#</a></h4><p><code>geemap</code> comes with a user interface that can be used to interactively do code conversion. Let’s try to convert the following Javascript code to Python.</p><pre tabindex=0><code>var geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241]);
var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;);

var rgbVis = {min: 0.0, max: 3000, bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;]};

var filtered = s2.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30))
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry));
  
var medianComposite = filtered.median();

Map.centerObject(geometry, 10);
Map.addLayer(medianComposite, rgbVis, &#39;Median Composite&#39;);
</code></pre><p>Run the cell below to load the map widget. Once the map widget loads, click the <em>Toolbar</em> icon in the top-right corner and select the <em>Convert Earth Engine Javascript to Python</em> tool. Paste your Javascript code and click <em>Convert</em>.</p><pre tabindex=0><code>m = geemap.Map(width=800)
m
</code></pre><p>You will see the auto-converted code displayed. Copy and paste it into a new cell and run it. Your code will be run using the GEE Python API.</p><pre tabindex=0><code>geometry = ee.Geometry.Point([77.60412933051538, 12.952912912328241])
s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;)

rgbVis = {&#39;min&#39;: 0.0, &#39;max&#39;: 3000, &#39;bands&#39;: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;]}

filtered = s2.filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30)) \
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;)) \
  .filter(ee.Filter.bounds(geometry))

medianComposite = filtered.median()

m.centerObject(geometry, 10)
m.addLayer(medianComposite, rgbVis, &#39;Median Composite&#39;)
</code></pre><p>If your code loads any layers, they will be loaded on the map widget. To display it, open a new code cell and just type <code>m</code> to display the widget.</p><h4 id=automatic-conversion-using-code>Automatic Conversion using Code<a hidden class=anchor aria-hidden=true href=#automatic-conversion-using-code>#</a></h4><p><code>geemap</code> offers a function <code>js_snippet_to_py()</code> that can be used to perform the conversion using code. This is useful for batch conversions. To use this, we first create a string with the javascript code.</p><pre tabindex=0><code>javascript_code = &#34;&#34;&#34;
var geometry = ee.Geometry.Point([107.61303468448624, 12.130969369851766]);
Map.centerObject(geometry, 12)
var s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;)
var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
};

var filtered = s2
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;))
  .filter(ee.Filter.bounds(geometry))

// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;);
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = &#39;cs&#39;;
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA);

// Write a function that computes NDVI for an image and adds it as a band
function addNDVI(image) {
  var ndvi = image.normalizedDifference([&#39;B5&#39;, &#39;B4&#39;]).rename(&#39;ndvi&#39;);
  return image.addBands(ndvi);
}

var withNdvi = filteredMasked.map(addNDVI);

var composite = withNdvi.median()
palette = [
  &#39;CE7E45&#39;, &#39;DF923D&#39;, &#39;F1B555&#39;, &#39;FCD163&#39;, &#39;99B718&#39;,
  &#39;74A901&#39;, &#39;66A000&#39;, &#39;529400&#39;, &#39;3E8601&#39;, &#39;207401&#39;, &#39;056201&#39;,
  &#39;004C00&#39;, &#39;023B01&#39;, &#39;012E01&#39;, &#39;011D01&#39;, &#39;011301&#39;];

ndviVis = {min:0, max:0.7, palette: palette }
Map.addLayer(withNdvi.select(&#39;ndvi&#39;), ndviVis, &#39;NDVI Composite&#39;)

&#34;&#34;&#34;
</code></pre><pre tabindex=0><code>lines = geemap.js_snippet_to_py(
    javascript_code, add_new_cell=False,
    import_ee=True, import_geemap=True, show_map=True)
for line in lines:
    print(line.rstrip())
</code></pre><p>The automatic conversion works great. Review it and paste it to the cell below.</p><pre tabindex=0><code>import ee
import geemap

m = geemap.Map()

geometry = ee.Geometry.Point([107.61303468448624, 12.130969369851766])
m.centerObject(geometry, 12)
s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;)
rgbVis = {
  &#39;min&#39;: 0.0,
  &#39;max&#39;: 3000,
  &#39;bands&#39;: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
}

filtered = s2 \
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;)) \
  .filter(ee.Filter.bounds(geometry))

# Load the Cloud Score+ collection
csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;)
csPlusBands = csPlus.first().bandNames()

# We need to add Cloud Score + bands to each Sentinel-2
# image in the collection
# This is done using the linkCollection() function
filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands)

# Function to mask pixels with low CS+ QA scores.
def maskLowQA(image):
  qaBand = &#39;cs&#39;
  clearThreshold = 0.5
  mask = image.select(qaBand).gte(clearThreshold)
  return image.updateMask(mask)

filteredMasked = filteredS2WithCs \
  .map(maskLowQA)

# Write a function that computes NDVI for an image and adds it as a band
def addNDVI(image):
  ndvi = image.normalizedDifference([&#39;B5&#39;, &#39;B4&#39;]).rename(&#39;ndvi&#39;)
  return image.addBands(ndvi)

withNdvi = filteredMasked.map(addNDVI)

composite = withNdvi.median()
palette = [
  &#39;CE7E45&#39;, &#39;DF923D&#39;, &#39;F1B555&#39;, &#39;FCD163&#39;, &#39;99B718&#39;,
  &#39;74A901&#39;, &#39;66A000&#39;, &#39;529400&#39;, &#39;3E8601&#39;, &#39;207401&#39;, &#39;056201&#39;,
  &#39;004C00&#39;, &#39;023B01&#39;, &#39;012E01&#39;, &#39;011D01&#39;, &#39;011301&#39;]

ndviVis = {&#39;min&#39;:0, &#39;max&#39;:0.7, &#39;palette&#39;: palette }
m.addLayer(withNdvi.select(&#39;ndvi&#39;), ndviVis, &#39;NDVI Composite&#39;)

m
</code></pre><h3 id=exercise-23>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-23>#</a></h3><p>Take the Javascript code snippet below and use <code>geemap</code> to automatically convert it to Python.</p><hr><pre tabindex=0><code>var admin2 = ee.FeatureCollection(&#34;FAO/GAUL_SIMPLIFIED_500m/2015/level2&#34;);

var karnataka = admin2.filter(ee.Filter.eq(&#39;ADM1_NAME&#39;, &#39;Karnataka&#39;))

var visParams = {color: &#39;red&#39;}
Map.centerObject(karnataka)
Map.addLayer(karnataka, visParams, &#39;Karnataka Districts&#39;)
</code></pre><hr><h2 id=03-batch-exports>03. Batch Exports<a hidden class=anchor aria-hidden=true href=#03-batch-exports>#</a></h2><p><a href=https://colab.research.google.com/github/spatialthoughts/courses/blob/master/code/end_to_end_gee/03_export_a_collection.ipynb>Open in Google Colab ↗</a></p><p>One of the most commonly asked questions by Earth Engine users is - <em>How do I download all images in a collection</em>? The Earth Engine Python API comes with a <code>ee.batch</code> module that allows you to launch batch exports and manage tasks. The recommended way to do batch exports like this is to use the Python API’s <code>ee.batch.Export</code> functions and use a Python for-loop to iterate and export each image. The <code>ee.batch</code> module also gives you ability to control <em>Tasks</em> - allowing you to automate exports.</p><blockquote><p>You can also export images in a collection using Javascript API in the Code Editor but this requires you to manually start the tasks for each image. This approach is fine for small number of images. You can check out the <a href="https://code.earthengine.google.co.in/?scriptPath=users%2Fujavalgandhi%2FEnd-to-End-GEE%3ASupplement%2FImage_Collections%2FExporting_ImageCollections">recommended script</a>.</p></blockquote><h4 id=initialization-2>Initialization<a hidden class=anchor aria-hidden=true href=#initialization-2>#</a></h4><p>First of all, you need to run the following cells to initialize the API and authorize your account. You must have a Google Cloud Project associated with your GEE account. Replace the <code>cloud_project</code> with your own project from <a href=https://console.cloud.google.com/>Google Cloud Console</a>.</p><pre tabindex=0><code>cloud_project = &#39;spatialthoughts&#39;

try:
    ee.Initialize(project=cloud_project)
except:
    ee.Authenticate()
    ee.Initialize(project=cloud_project)
</code></pre><h4 id=create-a-collection>Create a Collection<a hidden class=anchor aria-hidden=true href=#create-a-collection>#</a></h4><pre tabindex=0><code>geometry = ee.Geometry.Point([107.61303468448624, 12.130969369851766])
s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;)
rgbVis = {
  &#39;min&#39;: 0.0,
  &#39;max&#39;: 3000,
  &#39;bands&#39;: [&#39;B4&#39;, &#39;B3&#39;, &#39;B2&#39;],
}

filtered = s2 \
  .filter(ee.Filter.date(&#39;2019-01-01&#39;, &#39;2020-01-01&#39;)) \
  .filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30)) \
  .filter(ee.Filter.bounds(geometry)) \

# Load the Cloud Score+ collection
csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;)
csPlusBands = csPlus.first().bandNames()

# We need to add Cloud Score + bands to each Sentinel-2
# image in the collection
# This is done using the linkCollection() function
filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands)

# Function to mask pixels with low CS+ QA scores.
def maskLowQA(image):
  qaBand = &#39;cs&#39;
  clearThreshold = 0.5
  mask = image.select(qaBand).gte(clearThreshold)
  return image.updateMask(mask)

filteredMasked = filteredS2WithCs \
  .map(maskLowQA)

# Write a function that computes NDVI for an image and adds it as a band
def addNDVI(image):
  ndvi = image.normalizedDifference([&#39;B5&#39;, &#39;B4&#39;]).rename(&#39;ndvi&#39;)
  return image.addBands(ndvi)

withNdvi = filteredMasked.map(addNDVI)
</code></pre><h4 id=export-all-images>Export All Images<a hidden class=anchor aria-hidden=true href=#export-all-images>#</a></h4><p>Exports are done via the <code>ee.batch</code> module. This module allows you to automatically start an export - making it suitable for batch exports.</p><pre tabindex=0><code>image_ids = withNdvi.aggregate_array(&#39;system:index&#39;).getInfo()
print(&#39;Total images: &#39;, len(image_ids))
</code></pre><pre tabindex=0><code># Export with 100m resolution for this demo
for i, image_id in enumerate(image_ids):
  image = ee.Image(withNdvi.filter(ee.Filter.eq(&#39;system:index&#39;, image_id)).first())
  task = ee.batch.Export.image.toDrive(**{
    &#39;image&#39;: image.select(&#39;ndvi&#39;),
    &#39;description&#39;: &#39;Image Export {}&#39;.format(i+1),
    &#39;fileNamePrefix&#39;: image_id,
    &#39;folder&#39;:&#39;earthengine&#39;,
    &#39;scale&#39;: 100,
    &#39;region&#39;: image.geometry(),
    &#39;maxPixels&#39;: 1e10
  })
  task.start()
  print(&#39;Started Task: &#39;, i+1)
</code></pre><h4 id=manage-runningwaiting-tasks>Manage Running/Waiting Tasks<a hidden class=anchor aria-hidden=true href=#manage-runningwaiting-tasks>#</a></h4><p>You can manage tasks as well. Get a list of tasks and get state information on them</p><pre tabindex=0><code>tasks = ee.batch.Task.list()
for task in tasks:
  task_id = task.status()[&#39;id&#39;]
  task_state = task.status()[&#39;state&#39;]
  print(task_id, task_state)
</code></pre><p>You can cancel tasks as well</p><pre tabindex=0><code>tasks = ee.batch.Task.list()
for task in tasks:
    task_id = task.status()[&#39;id&#39;]
    task_state = task.status()[&#39;state&#39;]
    if task_state == &#39;RUNNING&#39; or task_state == &#39;READY&#39;:
        task.cancel()
        print(&#39;Task {} canceled&#39;.format(task_id))
    else:
        print(&#39;Task {} state is {}&#39;.format(task_id, task_state))
</code></pre><h3 id=exercise-24>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-24>#</a></h3><p>The code below uses the TerraClimate data and creates an ImageCollection with 12 monthly images of maximum temperature. It also extract the geometry for Australia from the LSIB collection. Add the code to start an export task for each image in the collection for australia.</p><ul><li><strong>Hint1</strong>: TerraClimate images have a scale of 4638.3m</li><li><strong>Hint2</strong>: You need to export the image contained in the clippedImage variable</li></ul><pre tabindex=0><code>import ee

lsib = ee.FeatureCollection(&#39;USDOS/LSIB_SIMPLE/2017&#39;)
australia = lsib.filter(ee.Filter.eq(&#39;country_na&#39;, &#39;Australia&#39;))
geometry = australia.geometry()

terraclimate = ee.ImageCollection(&#39;IDAHO_EPSCOR/TERRACLIMATE&#39;)
tmax = terraclimate.select(&#39;tmmx&#39;)

def scale(image):
  return image.multiply(0.1) \
    .copyProperties(image,[&#39;system:time_start&#39;])

tmaxScaled = tmax.map(scale)

filtered = tmaxScaled \
  .filter(ee.Filter.date(&#39;2020-01-01&#39;, &#39;2021-01-01&#39;)) \
  .filter(ee.Filter.bounds(geometry))

image_ids = filtered.aggregate_array(&#39;system:index&#39;).getInfo()
print(&#39;Total images: &#39;, len(image_ids))
</code></pre><p>Replace the comments with your code.</p><pre tabindex=0><code>for i, image_id in enumerate(image_ids):
    exportImage = ee.Image(filtered.filter(ee.Filter.eq(&#39;system:index&#39;, image_id)).first())
    # Clip the image to the region geometry
    clippedImage = exportImage.clip(geometry)

    ## Create the export task using ee.batch.Export.image.toDrive()

    ## Start the task
</code></pre><p><img alt="Launching multiple tasks using the  Python API" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/exporting_a_collection.png></p><p>Launching multiple tasks using the Python API</p><h2 id=04-using-earth-engine-with-xarray>04. Using Earth Engine with XArray<a hidden class=anchor aria-hidden=true href=#04-using-earth-engine-with-xarray>#</a></h2><p><a href=https://colab.research.google.com/github/spatialthoughts/courses/blob/master/code/end_to_end_gee/04_time_series_processing_xee.ipynb>Open in Google Colab ↗</a></p><p><a href=https://github.com/google/Xee>XEE</a> is an python package for working with Google Earth Engine data with <a href=https://docs.xarray.dev/en/stable/>XArray</a>. XEE makes it possible to leverage the strengths of both GEE and the Python ecosystem around XArray.</p><p>We will learn how to use XEE to extract and process a NDVI time-series for a single point location.</p><p>If you want to download processed time-series images as GeoTIFF files, pleasee see <a href=https://courses.spatialthoughts.com/python-remote-sensing.html#processing-time-series>this notebook</a>.</p><h4 id=installation>Installation<a hidden class=anchor aria-hidden=true href=#installation>#</a></h4><p>Let’s install the required packages in the Colab environment.</p><pre tabindex=0><code>%%capture
if &#39;google.colab&#39; in str(get_ipython()):
    !pip install --upgrade xee
</code></pre><pre tabindex=0><code>import ee
import xarray
import matplotlib.pyplot as plt
</code></pre><h4 id=initialization-3>Initialization<a hidden class=anchor aria-hidden=true href=#initialization-3>#</a></h4><p>First of all, you need to run the following cells to initialize the API and authorize your account. You must have a Google Cloud Project associated with your GEE account. Replace the <code>cloud_project</code> with your own project from <a href=https://console.cloud.google.com/>Google Cloud Console</a>.</p><p>We are using the <a href=https://developers.google.com/earth-engine/cloud/highvolume>High-volume Endpoint</a> which supports large number of concurrent requests and is recommended when working with XEE.</p><pre tabindex=0><code>cloud_project = &#39;spatialthoughts&#39;

try:
    ee.Initialize(
        project=cloud_project,
        opt_url=&#39;https://earthengine-highvolume.googleapis.com&#39;
    )
except:
    ee.Authenticate()
    ee.Initialize(
        project=cloud_project,
        opt_url=&#39;https://earthengine-highvolume.googleapis.com&#39;
    )
</code></pre><h4 id=select-a-location>Select a location.<a hidden class=anchor aria-hidden=true href=#select-a-location>#</a></h4><pre tabindex=0><code>geometry = ee.Geometry.Point([82.60759592318209, 27.163481733946846])
</code></pre><h4 id=preprocess-the-data-in-gee>Preprocess the data in GEE<a hidden class=anchor aria-hidden=true href=#preprocess-the-data-in-gee>#</a></h4><p>We start with the Sentinel-2 L1C collection. We pre-process the data by applying cloud masking and pixel scaling.</p><pre tabindex=0><code>s2 = ee.ImageCollection(&#39;COPERNICUS/S2_HARMONIZED&#39;)

filtered = s2 \
  .filter(ee.Filter.date(&#39;2017-01-01&#39;, &#39;2018-01-01&#39;)) \
  .filter(ee.Filter.lt(&#39;CLOUDY_PIXEL_PERCENTAGE&#39;, 30)) \
  .filter(ee.Filter.bounds(geometry))

# Load the Cloud Score+ collection
csPlus = ee.ImageCollection(&#39;GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED&#39;)
csPlusBands = csPlus.first().bandNames()

# We need to add Cloud Score + bands to each Sentinel-2
# image in the collection
# This is done using the linkCollection() function
filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands)

# Function to mask pixels with low CS+ QA scores.
def maskLowQA(image):
  qaBand = &#39;cs&#39;
  clearThreshold = 0.5
  mask = image.select(qaBand).gte(clearThreshold)
  return image.updateMask(mask)

filteredMasked = filteredS2WithCs \
  .map(maskLowQA)

# Write a function that computes NDVI for an image and adds it as a band
# Create a new image to overcome https://github.com/google/Xee/issues/88
def addNDVI(image):
  ndvi = image.normalizedDifference([&#39;B8&#39;, &#39;B4&#39;]).rename(&#39;ndvi&#39;)
  return image.multiply(0.0001).addBands(ndvi)\
    .copyProperties(image, [&#39;system:time_start&#39;])

# Map the function over the collection
withNdvi = filteredMasked.map(addNDVI)
</code></pre><h4 id=load-imagecollection-as-xarray-dataset>Load ImageCollection as XArray Dataset<a hidden class=anchor aria-hidden=true href=#load-imagecollection-as-xarray-dataset>#</a></h4><p>Now we have an ImageCollection that we want to get it as a XArray Dataset. We define the region of interest and extract the ImageCollection using the <code>ee</code> engine.</p><pre tabindex=0><code>ds = xarray.open_dataset(
    withNdvi,
    engine=&#39;ee&#39;,
    crs=&#39;EPSG:3857&#39;,
    scale=10,
    geometry=geometry,
    ee_mask_value=-9999,
)

ds
</code></pre><p>Select the <code>ndvi</code> band.</p><pre tabindex=0><code>ndvi_time_series = ds.ndvi
</code></pre><p>Run <code>compute()</code> to fetch the pixels from Earth Engine. This may take some time depending on the size of the request. This is a time-series at a single pixel, so we also <code>squeeze()</code> to remove the X and Y dimensions and get an array of NDVI values.</p><pre tabindex=0><code>original_time_series = ndvi_time_series.compute()
original_time_series = original_time_series.squeeze()
original_time_series
</code></pre><p>Plot the time-series.</p><pre tabindex=0><code>fig, ax = plt.subplots(1, 1)
fig.set_size_inches(10, 5)
original_time_series.plot.line(
    ax=ax, x=&#39;time&#39;,
    marker=&#39;o&#39;, color=&#39;#66c2a4&#39;, linestyle=&#39;--&#39;, linewidth=1, markersize=4)
plt.show()
</code></pre><h4 id=process-time-series-using-xarray>Process Time-Series using XArray<a hidden class=anchor aria-hidden=true href=#process-time-series-using-xarray>#</a></h4><p>We use XArray’s excellent time-series processing functionality to process the time-series. First, we create a regularly spaced time-series.</p><pre tabindex=0><code>time_series_resampled = original_time_series\
  .resample(time=&#39;5d&#39;).mean(dim=&#39;time&#39;)
time_series_resampled
</code></pre><p>Next we fill the cloud-masked pixels with linearly interpolated values from temporal neighbors.</p><pre tabindex=0><code>time_series_interpolated = time_series_resampled\
  .interpolate_na(&#39;time&#39;, use_coordinate=False)
time_series_interpolated
</code></pre><p>We also apply a moving-window smoothing to remove noise.</p><pre tabindex=0><code>time_series_smooth = time_series_interpolated\
  .rolling(time=3, center=True).mean()
time_series_smooth
</code></pre><p>A moving-window smoothing removed the first and last values of the time-series. We anchor the smoothed time-series with the values from the original time-series.</p><pre tabindex=0><code>time_series_smooth[0] = original_time_series[0]
time_series_smooth[-1] = original_time_series[-1]
time_series_smooth
</code></pre><p>Plot the original and smoothed time-series.</p><pre tabindex=0><code>fig, ax = plt.subplots(1, 1)
fig.set_size_inches(10, 5)
original_time_series.plot.line(
    ax=ax, x=&#39;time&#39;,
    marker=&#39;^&#39;, color=&#39;#66c2a4&#39;, linestyle=&#39;--&#39;, linewidth=1, markersize=2)
time_series_smooth.plot.line(
    ax=ax, x=&#39;time&#39;,
    marker=&#39;o&#39;, color=&#39;#238b45&#39;, linestyle=&#39;-&#39;, linewidth=1, markersize=4)
plt.show()
</code></pre><h4 id=download-the-time-series>Download the Time-Series<a hidden class=anchor aria-hidden=true href=#download-the-time-series>#</a></h4><p>Convert the DataArray to a Pandas DataFrame and save it as a CSV file.</p><pre tabindex=0><code>df = time_series_smooth.to_dataframe(&#39;ndvi&#39;).reset_index()
df
</code></pre><pre tabindex=0><code>output_filename = &#39;smoothed_time_series.csv&#39;
df[[&#39;time&#39;, &#39;ndvi&#39;]].to_csv(output_filename, index=False)
</code></pre><h3 id=exercise-25>Exercise<a hidden class=anchor aria-hidden=true href=#exercise-25>#</a></h3><p>Replace the <code>geometry</code> with the location of your choice. Extract and download the smoothed time-series as a CSV file.</p><h2 id=05-automating-downloads>05. Automating Downloads<a hidden class=anchor aria-hidden=true href=#05-automating-downloads>#</a></h2><p>Another common use of the GEE Python API is to automate data processing and export. You can create a Python script that can be called from a server or launched on a schedule using tools such as <a href=https://medium.com/@roddyjaques/how-to-run-anaconda-programs-with-a-bat-file-5f6dd7675508>Windows Scheduler</a> or <a href=https://donny-son.github.io/posts/cronjob-with-conda/>crontab</a>.</p><p>This script below provides a complete example of automating a download using Google Earth Engine API. It uses the Google Earth Engine API to compute the average soil moisture for the given time period over all districts in a state. The result is then downloaded as a CSV file and saved locally.</p><blockquote><p>Before running the script, please install the Earth Engine Python Client Library and commplete the authentication workflow on your machine using our <a href=https://courses.spatialthoughts.com/#install-gee-python-api.html>step-by-step instructions</a>.</p></blockquote><p>Once you have finished the authentication, follow the steps below to create a script to download data from GEE.</p><ol><li>Create a new file named <code>download_data.py</code> with the content shown below.</li></ol><pre tabindex=0><code>import datetime
import ee
import csv
import os

cloud_project = &#39;spatialthoughts&#39;

try:
    ee.Initialize(project=cloud_project)
except:
    ee.Authenticate()
    ee.Initialize(project=cloud_project)

# Get current date
now = datetime.datetime.now()

# Define the period of past 1-week
end_date = ee.Date(now)
start_date = end_date.advance(-1, &#39;week&#39;)

date_string = end_date.format(&#39;YYYY_MM_dd&#39;)
filename = &#39;ssm_{}.csv&#39;.format(date_string.getInfo())

# Saving to current directory. You can change the path to appropriate location
output_path = os.path.join(filename)

soilmoisture = ee.ImageCollection(&#39;NASA/SMAP/SPL4SMGP/007&#39;)
admin2 = ee.FeatureCollection(&#39;FAO/GAUL_SIMPLIFIED_500m/2015/level2&#39;)

# Filter to a state
karnataka = admin2.filter(ee.Filter.eq(&#39;ADM1_NAME&#39;, &#39;Karnataka&#39;))

# Select the ssm band
ssm  = soilmoisture.select(&#39;sm_surface&#39;)

filtered = ssm .filter(ee.Filter.date(start_date, end_date))

mean = filtered.mean()

stats = mean.reduceRegions(**{
  &#39;collection&#39;: karnataka,
  &#39;reducer&#39;: ee.Reducer.mean().setOutputs([&#39;meanssm&#39;]),
  &#39;scale&#39;: 11000,
  &#39;crs&#39;: &#39;EPSG:32643&#39;
  })

# Select columns to keep and remove geometry to make the result lightweight
# Change column names to match your uploaded shapefile
columns = [&#39;ADM2_NAME&#39;, &#39;meanssm&#39;]
exportCollection = stats.select(**{
    &#39;propertySelectors&#39;: columns,
    &#39;retainGeometry&#39;: False})

features = exportCollection.getInfo()[&#39;features&#39;]

data = []

for f in features:
    data.append(f[&#39;properties&#39;])

field_names = [&#39;ADM2_NAME&#39;, &#39;meanssm&#39;]

with open(output_path, &#39;w&#39;) as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames = field_names)
    writer.writeheader()
    writer.writerows(data)
    print(&#39;Success: File written at&#39;, output_path)
</code></pre><ol start=2><li>From the terminal, navigate to the directory where you have created the file and type the command below to run the script.</li></ol><pre tabindex=0><code>python download_data.py
</code></pre><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/download2.png></p><ol start=3><li>The script will download the data from GEE and save a file to your current directory.</li></ol><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/download3.png></p><h2 id=06-automating-exports>06. Automating Exports<a hidden class=anchor aria-hidden=true href=#06-automating-exports>#</a></h2><p>If you want to automate Earth Engine jobs on a server, it is preferable to use a <a href=https://developers.google.com/earth-engine/guides/service_account>Service Account</a> for authentication. A service account is a virtual account linked to a Google Cloud project. Once you create a service account and give necessary permissions, it can be used to authenticate your Earth Engine account instead of your own account. Each service account is identified by an email address in the form of <code>&lt;account_name>@&lt;project>.iam.gserviceaccount.com</code>. Along with them, the credentials are stored in a separate <code>.json</code> file. You need to keep this <code>.json</code> file safe on the system with appropriate permissions so external users do not have access to it.</p><blockquote><p>Before running the script, please install the Earth Engine Python Client Library on the server using our <a href=https://courses.spatialthoughts.com/#install-gee-python-api.html>step-by-step instructions</a>.</p></blockquote><p>The below code example shows how to authenticate an Earth Engine Export job using a service account. The code snippet assumes that the private key file is in the same directory as the scirpt and saved as a file named <code>.private_key.json</code>.</p><pre tabindex=0><code>import ee
# Replace the service account with your service account email
service_account = &#39;export-data-gee@spatialthoughts.iam.gserviceaccount.com&#39;
# Replace the value with the path to your private key json file
private_key_path = &#39;.private_key.json&#39;
credentials = ee.ServiceAccountCredentials(service_account, private_key_path)
ee.Initialize(credentials)

lsib = ee.FeatureCollection(&#39;USDOS/LSIB_SIMPLE/2017&#39;)
australia = lsib.filter(ee.Filter.eq(&#39;country_na&#39;, &#39;Australia&#39;))
geometry = australia.geometry()

terraclimate = ee.ImageCollection(&#39;IDAHO_EPSCOR/TERRACLIMATE&#39;)
tmax = terraclimate.select(&#39;tmmx&#39;)

def scale(image):
  return image.multiply(0.1) \
    .copyProperties(image,[&#39;system:time_start&#39;])

tmaxScaled = tmax.map(scale)

filtered = tmaxScaled \
  .filter(ee.Filter.date(&#39;2020-01-01&#39;, &#39;2021-01-01&#39;)) \
  .filter(ee.Filter.bounds(geometry))

image_ids = filtered.aggregate_array(&#39;system:index&#39;).getInfo()

for i, image_id in enumerate(image_ids):
    exportImage = ee.Image(filtered.filter(
        ee.Filter.eq(&#39;system:index&#39;, image_id)).first())

    clippedImage = exportImage.clip(geometry)
    
    task = ee.batch.Export.image.toDrive(**{
        &#39;image&#39;: clippedImage,
        &#39;description&#39;: &#39;Terraclimate Image Export {}&#39;.format(i+1),
        &#39;fileNamePrefix&#39;: image_id,
        &#39;folder&#39;:&#39;earthengine&#39;,
        &#39;scale&#39;: 4638.3,
        &#39;region&#39;: geometry,
        &#39;maxPixels&#39;: 1e10
    })
    task.start()
    print(&#39;Started Task: &#39;, i+1)
</code></pre><h2 id=07-using-the-google-earth-engine-qgis-plugin>07. Using the Google Earth Engine QGIS Plugin<a hidden class=anchor aria-hidden=true href=#07-using-the-google-earth-engine-qgis-plugin>#</a></h2><p>The <a href=https://gee-community.github.io/qgis-earthengine-plugin/>QGIS Google Earth Engine plugin</a> allows GEE Python API code to be run from QGIS and visualize the results directly in QGIS. This allows users to integrate QGIS’s rich cartographic features with the cloud data processing capabilities. After installing the plugin, you will be prompted to authenticate to GEE using your credentials. Once authenticated, you are able to run EE Python API code along with other PyQGIS code within QGIS.</p><blockquote><p>If you get an authentication error, <a href=https://courses.spatialthoughts.com/install-gee-python-api.html#authentication>follow these instructions</a> to install the Python API client and run <code>earthengine authenticate</code></p></blockquote><p>We will run a script that processes and visualizes a future climate scenario using the <a href=https://www.carbonbrief.org/cmip6-the-next-generation-of-climate-models-explained/>CMIP6 Climate Models</a>.</p><p>Open the QGIS Python Console from <strong>Plugins → Python Console</strong> and click the <strong>Show Editor</strong> button. Paste the following code and click the <strong>Run</strong> button. Once the code runs, the resulting image computed by Earth Engine and will be streamed to QGIS as a new layer.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/ee_qgis1.png></p><pre tabindex=0><code>import ee
from ee_plugin import Map

# Use the CMIP6 Climate Projections Dataset
cmip6 = ee.ImageCollection(&#39;NASA/GDDP-CMIP6&#39;)

# Select a model and a scenario

model = &#39;ACCESS-CM2&#39;
scenario = &#39;ssp245&#39;

# Select the band
# Here we are using maximum air temperature
band = &#39;tasmax&#39;

# Select the date range
startDate = ee.Date.fromYMD(2030, 3, 1)
endDate = startDate.advance(1, &#39;month&#39;)

filtered = cmip6 \
  .filter(ee.Filter.date(startDate, endDate)) \
  .filter(ee.Filter.eq(&#39;model&#39;, model)) \
  .filter(ee.Filter.eq(&#39;scenario&#39;, scenario)) \
  .select(band)

# Temperature values are in Kelvin
# convert to Celcius

def scaleValues(image):
  return image \
    .subtract(273.15) \
    .copyProperties(image,
      [&#39;system:time_start&#39;, &#39;model&#39;, &#39;scenario&#39;])

scaled = filtered.map(scaleValues)

# Calculate average daily maximum temperature
mean = scaled.mean()

tempVis = {
  &#39;min&#39;: 10,
  &#39;max&#39;: 40,
  &#39;palette&#39;: [&#39;blue&#39;, &#39;purple&#39;, &#39;cyan&#39;, &#39;green&#39;, &#39;yellow&#39;, &#39;red&#39;],
}

Map.addLayer(mean, tempVis, &#39;Average Daily Maximum Air Temperature&#39;)
</code></pre><p>You can now use this layer in your QGIS project or Print Layout. Here’s an example of visualizing the layer on a custom globe using the <a href=https://plugins.qgis.org/plugins/GlobeBuilder/>Globe Builder Plugin</a>.</p><p><img loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/ee_qgis2.png></p><h2 id=supplement>Supplement<a hidden class=anchor aria-hidden=true href=#supplement>#</a></h2><p>We have a large collection of scripts that accompany this course. Visit the <a href=https://courses.spatialthoughts.com/end-to-end-gee-supplement.html>Supplement</a>.</p><h2 id=guided-projects>Guided Projects<a hidden class=anchor aria-hidden=true href=#guided-projects>#</a></h2><p>Below are step-by-step video-based walkthrough of implementing real-world projects using Earth Engine. You can continue their learning journey by implementing these projects for their region of interest after the class.</p><p><a href="https://www.youtube.com/watch?v=uoOvOPK0iro&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=8"><img alt="Watch the Video" loading=lazy src=https://img.youtube.com/vi/uoOvOPK0iro/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=uoOvOPK0iro&amp;list=PLppGmFLhQ1HJuIb7qMiKIv11HiEQhy3ha&amp;index=8">Watch the Video ↗</a></p><h2 id=get-the-code>Get the Code<a hidden class=anchor aria-hidden=true href=#get-the-code>#</a></h2><ol><li><a href="https://code.earthengine.google.co.in/?accept_repo=users/ujavalgandhi/End-to-End-Projects">Click this link</a> to open Google Earth Engine code editor and add the repository to your account.</li><li>If successful, you will have a new repository named <code>users/ujavalgandhi/End-to-End-Projects</code> in the <em>Scripts</em> tab in the <em>Reader</em> section.</li></ol><p><img alt="Code Editor After Adding the Projects Repository" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/projects.png></p><p>Code Editor After Adding the Projects Repository</p><p>If you do not see the repository in the <em>Reader</em> section, click <em>Refresh repository cache</em> button in your <em>Scripts</em> tab and it will show up.</p><p><img alt="Refresh repository cache" loading=lazy src=https://courses.spatialthoughts.com/images/end_to_end_gee/repository_cache.png></p><p>Refresh repository cache</p><h2 id=project-1-calculating-rainfall-deviation>Project 1: Calculating Rainfall Deviation<a hidden class=anchor aria-hidden=true href=#project-1-calculating-rainfall-deviation>#</a></h2><p>Calculating Rainfall Deviation from the 30-year mean using CHIRPS Gridded Rainfall Data</p><p><a href="https://www.youtube.com/watch?v=zHUCM3XLc6k&amp;list=PLppGmFLhQ1HJ5VhW6BZfhPX6spUcTY7SR"><img alt="Watch the Video" loading=lazy src=https://img.youtube.com/vi/zHUCM3XLc6k/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=zHUCM3XLc6k&amp;list=PLppGmFLhQ1HJ5VhW6BZfhPX6spUcTY7SR">Watch the Video ↗</a></p><h2 id=project-2-flood-mapping>Project 2: Flood Mapping<a hidden class=anchor aria-hidden=true href=#project-2-flood-mapping>#</a></h2><p>Rapid mapping of a flood using Sentinel-1 SAR Data.</p><p><a href="https://www.youtube.com/watch?v=jYsK9Y4ICrY&amp;list=PLppGmFLhQ1HJzzKVS_4v8nBiXLYxAu100"><img alt="Watch the Video" loading=lazy src=https://img.youtube.com/vi/jYsK9Y4ICrY/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=jYsK9Y4ICrY&amp;list=PLppGmFLhQ1HJzzKVS_4v8nBiXLYxAu100">Watch the Video ↗</a></p><h2 id=project-4-landcover-analysis>Project 4: LandCover Analysis<a hidden class=anchor aria-hidden=true href=#project-4-landcover-analysis>#</a></h2><p>Use existing land cover products to extract specific classes and compute statistics across many regions.</p><p><a href="https://www.youtube.com/watch?v=B0E_dzO1J4g&amp;list=PLppGmFLhQ1HLl0St2wiOPePr58sKu0Vh1"><img alt="Watch the Video" loading=lazy src=https://img.youtube.com/vi/B0E_dzO1J4g/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=B0E_dzO1J4g&amp;list=PLppGmFLhQ1HLl0St2wiOPePr58sKu0Vh1">Watch the Video ↗</a></p><h2 id=learning-resources>Learning Resources<a hidden class=anchor aria-hidden=true href=#learning-resources>#</a></h2><ul><li><a href=https://www.eefabook.org/>Cloud-Based Remote Sensing with Google Earth Engine: Fundamentals and Applications</a>: A free and open-access book with 55-chapters covering fundamentals and applications of GEE. Also includes YouTube videos summarizing each chapter.</li><li><a href=https://github.com/giswqs/Awesome-GEE>Awesome Earth Engine</a>: A curated list of Google Earth Engine resources.</li><li><a href=https://courses.spatialthoughts.com/gee-water-resources-management.html>Google Earth Engine for Water Resources Management</a>: Application-focused Introduction to Google Earth Engine.</li><li><a href=https://courses.spatialthoughts.com/gee-charts.html>Creating Publication Quality Charts with GEE</a>: A comprehesive guide on creating high-quality data visualizations with Google Earth Engine and Google Charts.</li></ul><h2 id=useful-public-repositories>Useful Public Repositories<a hidden class=anchor aria-hidden=true href=#useful-public-repositories>#</a></h2><p>Please visit <a href=https://github.com/giswqs/Awesome-GEE>Awesome Earth Engine</a> to see a curated list of Google Earth Engine resources.</p><p>We also have a few recommendations of a few selected packages, which have very useful functions to make you productive in Earth Engine.</p><p><strong>General Purpose Packages</strong></p><ul><li><a href=https://github.com/gee-community/ee-packages-py>eepackages</a>: A set of Google Earth Engine utilities by maintained by Gennadii Donchyts for both Javascript and Python API.</li><li><a href=https://github.com/fitoprincipe/geetools-code-editor/wiki>geetools</a>: Tools for cloud masking, batch processing, and more</li><li><a href=https://github.com/gee-community/ee-palettes>ee-palettes</a>: Module for generating color palettes</li><li><a href=https://github.com/awesome-spectral-indices/spectral>spectral</a>: A javascript module that provides ready-to-use curated list of spectral indices for GEE.</li><li><a href=https://github.com/davemlz/eemont>eemont</a>: Python package that provides utility methods to create a more fluid code by being friendly with the Python method chaining.</li></ul><p><strong>Application Specific Packages</strong></p><ul><li><a href=https://github.com/rfernand387/LEAF-Toolbox/wiki>LEAF-Toolbox</a>: Google Earth Engine application that produces various Vegetation Biophysical Products, including Leaf Area Index (LAI).</li><li><a href=https://github.com/seanyx/RivWidthCloudPaper>RivWidthCloud</a>: Package to automate extracting river centerline and width for both Javascript and Python API.</li></ul><h2 id=debugging-errors-and-scaling-your-analysis>Debugging Errors and Scaling Your Analysis<a hidden class=anchor aria-hidden=true href=#debugging-errors-and-scaling-your-analysis>#</a></h2><p>As you start implementing more complex workflows and analyze large regions - you are bound to run into scaling issues and errors such as below:</p><ul><li><em>User memory-limit exceeded</em></li><li><em>Computation timed-out</em></li><li><em>Computed value is too large</em></li></ul><p>These are usually the result of inefficient code and structure of your script. Below are my recommendations for improving your coding style and utilizing the full power of the Earth Engine infrastructure.</p><ul><li>If/else statements and for-loops should be avoided completely and replaced with filter/map/reduce. The former are sequential and will be slow. Refer to the <a href=https://developers.google.com/earth-engine/tutorials/tutorial_js_03>Function Programming Concepts</a> guide on how to restructure your code to utilize the parallel computing infratructure provided by GEE.</li><li>Remove any reprojection or resampling calls fro your script. Barring a few exceptions, you should not be reprojecting or resampling data. Earth Engine is designed to take care of it internally.</li><li>For complex analysis involving large volumes of data, you should break down your workflow into logical steps and export intermediate results. For example, if you are implementing a complex supervised classification workflow - do it in multiple stages. A) Create your composite, add required bands, normalize them and export it as an Asset. B) Import the exported composite into another script and train a classifier. Export the classified image as an Asset. C) Import the exported classified image and do accuracy assessment and visualize the results. You will be able to run your analysis much faster, experiment easily and avoid scaling errors. Refer to the <a href="https://developers.google.com/earth-engine/guides/best_practices?hl=en#export_intermediate_results">Export Intermediate Result</a> guide to learn more.</li><li>You may also break your export region into smaller regions (typically by admin units) and Export each region separately. For example, if you want to export results for an entire country at 30m resolution - rather than a running a large Export - you can export each Admin1 unit in your country separately. This helps with computation timed-out errors and improves overall processing time. You can start as many exports from your account as you want and they will be executed in a queue. But do not split your exports over multiple Earth Engine accounts. This is a <a href=https://developers.google.com/earth-engine/batch-task-restrictions>violation of GEE Terms of Service</a> and may result in your account getting blocked.</li></ul><p>The Earth Engine User Guide also has tips and examples of best practices. You can review the following articles to learn them.</p><ul><li><a href="https://developers.google.com/earth-engine/guides/best_practices?hl=en">Coding Best Practices</a></li><li><a href="https://developers.google.com/earth-engine/guides/debugging?hl=en">Debugging Guide</a></li></ul><p>The following videos are highly recommended and contain good advice on debugging and scaling workflows.</p><p><a href="https://www.youtube.com/watch?v=3AtnpkZTvnk"><img alt="Earth Engine Scaling and Debugging" loading=lazy src=https://img.youtube.com/vi/3AtnpkZTvnk/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=3AtnpkZTvnk">Watch the Video ↗</a></p><p><a href="https://www.youtube.com/watch?v=fsez4HiOc8k"><img alt="Using Earth Engine for Very Large Computations" loading=lazy src=https://img.youtube.com/vi/fsez4HiOc8k/mqdefault.jpg></a></p><p><a href="https://www.youtube.com/watch?v=fsez4HiOc8k">Watch the Video ↗</a></p><h2 id=data-credits>Data Credits<a hidden class=anchor aria-hidden=true href=#data-credits>#</a></h2><ul><li><strong>Sentinel-2 Level-1C, Level-2A</strong> and <strong>Sentinel-1 SAR GRD</strong>: Contains Copernicus Sentinel data.</li><li><strong>TerraClimate: Monthly Climate and Climatic Water Balance for Global Terrestrial Surfaces, University of Idaho</strong>: Abatzoglou, J.T., S.Z. Dobrowski, S.A. Parks, K.C. Hegewisch, 2018, Terraclimate, a high-resolution global dataset of monthly climate and climatic water balance from 1958-2015, Scientific Data 5:170191, <a href=https://courses.spatialthoughts.com/>doi:10.1038/sdata.2017.191</a></li><li><strong>VIIRS Stray Light Corrected Nighttime Day/Night Band Composites Version 1</strong>: C. D. Elvidge, K. E. Baugh, M. Zhizhin, and F.-C. Hsu, “Why VIIRS data are superior to DMSP for mapping nighttime lights,” Asia-Pacific Advanced Network 35, vol. 35, p. 62, 2013.</li><li><strong>FAO GAUL 500m: Global Administrative Unit Layers 2015, Second-Level Administrative Units</strong>: Source of Administrative boundaries: The Global Administrative Unit Layers (GAUL) dataset, implemented by FAO within the CountrySTAT and Agricultural Market Information System (AMIS) projects.</li><li><strong>CHIRPS Pentad: Climate Hazards Group InfraRed Precipitation with Station Data (version 2.0 final)</strong>: Funk, Chris, Pete Peterson, Martin Landsfeld, Diego Pedreros, James Verdin, Shraddhanand Shukla, Gregory Husak, James Rowland, Laura Harrison, Andrew Hoell & Joel Michaelsen. “The climate hazards infrared precipitation with stations—a new environmental record for monitoring extremes”. Scientific Data 2, 150066. <a href=https://courses.spatialthoughts.com/>doi:10.1038/sdata.2015.66</a> 2015.</li><li><strong>MOD13Q1.006 Terra Vegetation Indices 16-Day Global 250m</strong>: Didan, K. (2015). <em>MOD13Q1 MODIS/Terra Vegetation Indices 16-Day L3 Global 250m SIN Grid V006</em> [Data set]. NASA EOSDIS Land Processes DAAC. Accessed 2021-05-06 from <a href=https://doi.org/10.5067/MODIS/MOD13Q1.006>https://doi.org/10.5067/MODIS/MOD13Q1.006</a></li><li><strong>GHS Urban Centre Database 2015 multitemporal and multidimensional attributes R2019A</strong>: Florczyk A., Corbane C,. Schiavina M., Pesaresi M., Maffenini L., Melchiorri, M., Politis P., Sabo F., Freire S., Ehrlich D., Kemper T., Tommasi P., Airaghi D., Zanchetta L. (2019) European Commission, Joint Research Centre (JRC) <a href=https://data.jrc.ec.europa.eu/dataset/53473144-b88c-44bc-b4a3-4583ed1f547e>PID</a></li><li><strong>ESA WorldCover v100</strong>: Zanaga, D., Van De Kerchove, R., De Keersmaecker, W., Souverijns, N., Brockmann, C., Quast, R., Wevers, J., Grosu, A., Paccini, A., Vergnaud, S., Cartus, O., Santoro, M., Fritz, S., Georgieva, I., Lesiv, M., Carter, S., Herold, M., Li, Linlin, Tsendbazar, N.E., Ramoino, F., Arino, O., 2021. ESA WorldCover 10 m 2020 v100. <a href=https://doi.org/10.5281/zenodo.5571936>doi:10.5281/zenodo.5571936</a></li></ul><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><h2 id=composites>Composites<a hidden class=anchor aria-hidden=true href=#composites>#</a></h2><ul><li>Phan, T.N.; Kuch, V.; Lehnert, L.W. Land Cover Classification using Google Earth Engine and Random Forest Classifier—The Role of Image Composition. Remote Sens. 2020, 12, 2411. <a href=https://doi.org/10.3390/rs12152411>https://doi.org/10.3390/rs12152411</a></li><li>D. Simonetti, U. Pimple, A. Langner, A. Marelli, Pan-tropical Sentinel-2 cloud-free annual composite datasets, Data in Brief, Volume 39, 2021, 107488, ISSN 2352-3409,<a href=https://doi.org/10.1016/j.dib.2021.107488>https://doi.org/10.1016/j.dib.2021.107488</a>.</li></ul><h2 id=supervised-classification>Supervised Classification<a hidden class=anchor aria-hidden=true href=#supervised-classification>#</a></h2><ul><li>Shetty, S.; Gupta, P.K.; Belgiu, M.; Srivastav, S.K. Assessing the Effect of Training Sampling Design on the Performance of Machine Learning Classifiers for Land Cover Mapping Using Multi-Temporal Remote Sensing Data and Google Earth Engine. Remote Sens. 2021, 13, 1433. <a href=https://doi.org/10.3390/rs13081433>https://doi.org/10.3390/rs13081433</a></li><li>Kelley, L.C.; Pitcher, L.; Bacon, C. Using Google Earth Engine to Map Complex Shade-Grown Coffee Landscapes in Northern Nicaragua. Remote Sens. 2018, 10, 952. <a href=https://doi.org/10.3390/rs10060952>https://doi.org/10.3390/rs10060952</a></li><li>Arsalan Ghorbanian, Mohammad Kakooei, Meisam Amani, Sahel Mahdavi, Ali Mohammadzadeh, Mahdi Hasanlou, Improved land cover map of Iran using Sentinel imagery within Google Earth Engine and a novel automatic workflow for land cover classification using migrated training samples, ISPRS Journal of Photogrammetry and Remote Sensing, Volume 167, 2020, <a href=https://doi.org/10.1016/j.isprsjprs.2020.07.013>https://doi.org/10.1016/j.isprsjprs.2020.07.013</a></li><li>Tassi, A.; Vizzari, M. Object-Oriented LULC Classification in Google Earth Engine Combining SNIC, GLCM, and Machine Learning Algorithms. Remote Sens. 2020, 12, 3776. <a href=https://doi.org/10.3390/rs12223776>https://doi.org/10.3390/rs12223776</a></li><li>Cristina Gómez, Joanne C. White, Michael A. Wulder, Optical remotely sensed time series data for land cover classification: A review, ISPRS Journal of Photogrammetry and Remote Sensing, Volume 116, 2016, Pages 55-72, ISSN 0924-2716, <a href=https://doi.org/10.1016/j.isprsjprs.2016.03.008>https://doi.org/10.1016/j.isprsjprs.2016.03.008</a></li><li>Sherrie Wang, George Azzari, David B. Lobell, Crop type mapping without field-level labels: Random forest transfer and unsupervised clustering techniques, Remote Sensing of Environment, Volume 222, 2019, Pages 303-317, ISSN 0034-4257, <a href=https://doi.org/10.1016/j.rse.2018.12.026>https://doi.org/10.1016/j.rse.2018.12.026</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/clippings/>Clippings</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/blog/blog_1/><span class=title>« Prev</span><br><span></span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share End-to-End Google Earth Engine (Full Course) on x" href="https://x.com/intent/tweet/?text=End-to-End%20Google%20Earth%20Engine%20%28Full%20Course%29&amp;url=http%3a%2f%2flocalhost%3a1313%2fblog%2fend-to-end-google-earth-engine-full-course%2f&amp;hashtags=clippings"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End-to-End Google Earth Engine (Full Course) on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fblog%2fend-to-end-google-earth-engine-full-course%2f&amp;title=End-to-End%20Google%20Earth%20Engine%20%28Full%20Course%29&amp;summary=End-to-End%20Google%20Earth%20Engine%20%28Full%20Course%29&amp;source=http%3a%2f%2flocalhost%3a1313%2fblog%2fend-to-end-google-earth-engine-full-course%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End-to-End Google Earth Engine (Full Course) on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fblog%2fend-to-end-google-earth-engine-full-course%2f&title=End-to-End%20Google%20Earth%20Engine%20%28Full%20Course%29"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End-to-End Google Earth Engine (Full Course) on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fblog%2fend-to-end-google-earth-engine-full-course%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End-to-End Google Earth Engine (Full Course) on whatsapp" href="https://api.whatsapp.com/send?text=End-to-End%20Google%20Earth%20Engine%20%28Full%20Course%29%20-%20http%3a%2f%2flocalhost%3a1313%2fblog%2fend-to-end-google-earth-engine-full-course%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End-to-End Google Earth Engine (Full Course) on telegram" href="https://telegram.me/share/url?text=End-to-End%20Google%20Earth%20Engine%20%28Full%20Course%29&amp;url=http%3a%2f%2flocalhost%3a1313%2fblog%2fend-to-end-google-earth-engine-full-course%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End-to-End Google Earth Engine (Full Course) on ycombinator" href="https://news.ycombinator.com/submitlink?t=End-to-End%20Google%20Earth%20Engine%20%28Full%20Course%29&u=http%3a%2f%2flocalhost%3a1313%2fblog%2fend-to-end-google-earth-engine-full-course%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>ExampleSite</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>